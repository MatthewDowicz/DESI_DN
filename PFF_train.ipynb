{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c410e13-f0b2-4982-8c1e-cc7ef5865c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#import PT_files.save_load as sl\n",
    "import loader\n",
    "import time \n",
    "from collections import OrderedDict\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fb0325-08dd-4de8-91ad-a42717c6fdc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loading data/dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a9abc-4026-4180-b5d0-364106145bba",
   "metadata": {},
   "source": [
    "Below are our 2 datasets we'll be working with. Aptly named, `train_data` is the larger of the datasets due to this set being what the model is trained on. `test_data` is the smaller dataset used to see how well our model is doing. Do to the small dataset nature we only have a training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105c0518-5fa3-44f1-87f7-94c2dbd35413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set= (2, 610, 1, 2000, 2000)\n"
     ]
    }
   ],
   "source": [
    "#Load the actual data that we're working on & print the shape of this data\n",
    "train_data = loader.load('training_data610-2000.npy')\n",
    "test_data = loader.load('test_data200-2000.npy')\n",
    "print('Shape of train set=', train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459ced2-80fc-4ef8-b6f0-c3f3b287fed2",
   "metadata": {},
   "source": [
    "Converting training/test data to be RGB instead of grayscale because the model expects the data to be RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5964b743-4198-48dd-a9e8-9de588347f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noise_rgb = np.concatenate((train_data[0],)*3, axis=1)\n",
    "train_clean_rgb = np.concatenate((train_data[1],)*3, axis=1)\n",
    "\n",
    "test_noise_rgb = np.concatenate((test_data[0],)*3, axis=1)\n",
    "test_clean_rgb = np.concatenate((test_data[1],)*3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5515d1-dd0e-412d-9cc2-7f60a4c7222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_rgb = np.empty((2, 610, 3, 2000, 2000), np.float32)\n",
    "train_data_rgb[0, :, :, :, :] = train_noise_rgb\n",
    "train_data_rgb[1, :, :, :, :] = train_clean_rgb\n",
    "\n",
    "test_data_rgb = np.empty((2, 200, 3, 2000, 2000), np.float32)\n",
    "test_data_rgb[0, :, :, :, :] = test_noise_rgb\n",
    "test_data_rgb[1, :, :, :, :] = test_clean_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d354073-8eb2-4566-9e9a-466285d6377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data(data, sample_id, height, width):\n",
    "    \n",
    "    noise = data[0]\n",
    "    label = data[1]\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(24,20))\n",
    "    vmin, vmax = np.percentile(noise[sample_id], (1,99))\n",
    "\n",
    "\n",
    "    ax[0, 0].imshow(noise[sample_id][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[0, 0].set_title('Noisy Full Image', fontsize=30)\n",
    "    ax[0, 0].axis('off')\n",
    "    ax[0, 1].imshow(noise[sample_id][0][height:height+200, width:width+200], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[0, 1].set_title('Noisy Sub-Image', fontsize=30)\n",
    "    ax[0, 1].axis('off')\n",
    "    ax[1, 0].imshow(label[sample_id][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[1, 0].set_title('Clean Full Image', fontsize=30)\n",
    "    ax[1, 0].axis('off')\n",
    "    ax[1, 1].imshow(label[sample_id][0][height:height+200, width:width+200], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[1, 1].set_title('Clean Sub-Image', fontsize=30)\n",
    "    ax[1, 1].axis('off')\n",
    "\n",
    "display_data(data=train_data_rgb, sample_id=0, height=100, width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d1cf3-ff42-4bb2-916e-e0154d2e83b3",
   "metadata": {},
   "source": [
    "Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity. PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples. [Source of this blurb and more info on PyTorch Dataset and Dataloaders found here.](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "This is our unique class to put our data, which in Numpy arrays, into the PyTorch primitive,`Dataset`. This will then be used in the other PyTorch primitive `Dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6799f85-bcad-4d0c-b59a-c6260ca057af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img_Dataset(Dataset):\n",
    "    def __init__(self, data_set, patch_size, width, height, seed=1234):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data: np.ndarray\n",
    "            Array that contains image/label pairs ie. corrupted image/clean image.\n",
    "            Shape = (P, N, C, H, W):\n",
    "                P = corrupted/uncorrupted image pair \n",
    "                N = number of samples\n",
    "                C = number of channels\n",
    "                H = image height\n",
    "                W = image width\n",
    "        patch_size: int\n",
    "            Size of randomly chosen image patch the model uses for training\n",
    "        width: int\n",
    "            Width of the chosen sample.\n",
    "            NOTE: It's a parameter because you can input a larger image and choose\n",
    "                  to look at only portions of said image for more training samples.\n",
    "        height: int\n",
    "            Height of the chosen sample.\n",
    "        seed: int \n",
    "            Randomized seed used for the random slicing used to create the image patch.\n",
    "        \"\"\"\n",
    "        self.data_set = data_set\n",
    "        self.patch_size = patch_size\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.seed = seed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_set[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Function that returns the PyTorch Dataloader compatible dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        idx: var\n",
    "            Variable used in PyTorch Dataloader to be able to sample from the dataset\n",
    "            to create minibatches of the data for us automatically.\n",
    "        \"\"\"\n",
    "        # Loading the dataset and then slicing the image/label pairs \n",
    "        # ie. corrupted/uncorrupted images. \n",
    "        # Note the use of the idx in the image/label variables. This allows the\n",
    "        # PyTorch Dataloader to get all the important data info eg. (N, C, H, W)\n",
    "        data = self.data_set\n",
    "        image = data[0, idx]\n",
    "        label = data[1, idx]\n",
    "        \n",
    "        # Setting the patch size and the randomized seed for the image patch\n",
    "        patch_size = self.patch_size\n",
    "        seed = self.seed\n",
    "        rng = np.random.RandomState(seed)\n",
    "\n",
    "        img_width = self.width\n",
    "        img_height = self.height\n",
    "        \n",
    "        #randomly crop patch from training set\n",
    "        x1 = rng.randint(img_width - patch_size)\n",
    "        y1 = rng.randint(img_height - patch_size)\n",
    "        S = (slice(y1, y1 + patch_size), slice(x1, x1 + patch_size))\n",
    "        \n",
    "        # create new arrays for training patchs\n",
    "        image_patch = image[0][S]\n",
    "        label_patch = label[0][S]\n",
    "        \n",
    "\n",
    "        image_patch = image_patch[np.newaxis, :, :]\n",
    "        label_patch = label_patch[np.newaxis, :, :]\n",
    "        \n",
    "        # Turning our image/label to a PyTorch Tensor with dtype = float \n",
    "        # and then putting it onto the GPU for faster training/inference\n",
    "        image = torch.from_numpy(image_patch).float().cuda(device)\n",
    "        label = torch.from_numpy(label_patch).float().cuda(device)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7f6d6d-dcc0-4b28-85a4-94b6246efbe6",
   "metadata": {},
   "source": [
    "# **LOOK HERE PATRICK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa7bd7a-95ef-41c3-901a-6342516b5066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 1, 2000, 2000)\n",
      "Patch = (1, 0, 64, 2000)\n"
     ]
    }
   ],
   "source": [
    "data=train_data\n",
    "\n",
    "image = data[0, :]\n",
    "label = data[1, :]\n",
    "print(image.shape)\n",
    "\n",
    "# Setting the patch size and the randomized seed for the image patch\n",
    "patch_size = 64\n",
    "seed = 234\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "img_width = 2000\n",
    "img_height = 2000\n",
    "\n",
    "#randomly crop patch from training set\n",
    "x1 = rng.randint(img_width - patch_size)\n",
    "y1 = rng.randint(img_height - patch_size)\n",
    "S = (slice(y1, y1 + patch_size), slice(x1, x1 + patch_size))\n",
    "# print('Slice = ',S)\n",
    "# create new arrays for training patchs\n",
    "image_patch = image[0][S]\n",
    "label_patch = label[0][S]\n",
    "\n",
    "\n",
    "image_patch = image_patch[np.newaxis, :, :]\n",
    "label_patch = label_patch[np.newaxis, :, :]\n",
    "\n",
    "# # Turning our image/label to a PyTorch Tensor with dtype = float \n",
    "# # and then putting it onto the GPU for faster training/inference\n",
    "# image = torch.from_numpy(image_patch).float().cuda(device)\n",
    "# label = torch.from_numpy(label_patch).float().cuda(device)\n",
    "\n",
    "print('Patch =', image_patch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78739149-b30b-4772-9aad-974bec9006c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Img_Dataset(data_set=train_data_rgb,\n",
    "                       patch_size=64,\n",
    "                       height=2000,\n",
    "                       width=2000)\n",
    "\n",
    "test_ds = Img_Dataset(data_set=test_data_rgb,\n",
    "                       patch_size=64,\n",
    "                       height=2000,\n",
    "                       width=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6826d2-b4b2-4b95-8a95-7f10ba28b87e",
   "metadata": {},
   "source": [
    "Output of the `dataloader` is channel of 1, when the model wants it to be 3. If you scroll all the way to the bottom you'll see the error saying `Given groups=1, weight of size [64, 3, 7, 7], expected input[56, 1, 64, 64] to have 3 channels, but got 1 channels instead`.\n",
    "\n",
    "I think once it's the correct channel size it should be working.\n",
    "\n",
    "Also, just so you know I had to make the data rgb instead of grayscale, so the above cells have that code, but I don't think it changes anything really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dedddac-5588-4f50-aada-ec3ad9563343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([56, 1, 64, 64])\n",
      "Labels batch shape: torch.Size([56, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=56, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5f2d36-69d1-4786-802d-c9377c8525fa",
   "metadata": {},
   "source": [
    "What the training pair looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33eaf678-11c4-4750-9833-1514e159fb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_training_pair(dataloader, sample_id):\n",
    "    \n",
    "    images, labels = next(iter(dataloader))    \n",
    "    images = images.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24,20))\n",
    "    vmin, vmax = np.percentile(images[sample_id][0], (1,99))\n",
    "\n",
    "\n",
    "    ax[0].imshow(images[sample_id][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[0].set_title('Noisy Patch', fontsize=30)\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(labels[sample_id][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[1].set_title('Clean Patch', fontsize=30)\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "display_training_pair(dataloader=train_dataloader, sample_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2bf56b-da15-444a-bfe1-af814cf3c584",
   "metadata": {},
   "source": [
    "PFF uses the model titled `PixelEmbedModelResNet18` \n",
    "\n",
    "The model the paper describes using is the model titled `PixelEmbedModelResNet18` on Github under, unsurprisingly, the directory titled `pixel_embedding_model.py`. \n",
    "- The down-sampling first stream for PFF uses a tweaked pretrained ResNet18 architecture.\n",
    "- The shallow full-resolution second stream is titled `self.streamTwo_feats` (I believe)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb352214-6cc9-42ab-80f1-781567c46d09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Trying to get the papers code working for our FVC images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd6a77-4ca5-4848-83a5-f15cd65d8412",
   "metadata": {},
   "source": [
    "Config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1298408a-86bb-4dff-9914-7c9a20be9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 # small batch size for demonstration; using larger batch size (like 56 and 64) for training\n",
    "\n",
    "embedding_dim = 16 # dimension of the learned embedding space\n",
    "kernel_size = 17 # the kernel size in the filter flow\n",
    "cropSize = [64, 64] # patch size for training the model\n",
    "sigmaMin=0.5\n",
    "sigmaMax=2\n",
    "\n",
    "lambda_norm = 0.1\n",
    "total_epoch_num = 500 # total number of epoch in training\n",
    "base_lr = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e245f03-96aa-43b1-8422-3b9fbcf95ef8",
   "metadata": {},
   "source": [
    "Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c7a73c4-a9f1-4d8b-9b8f-321b0c17239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelEmbedModelResNet18(nn.Module):\n",
    "    def __init__(self, emb_dimension=128, pretrained=True):\n",
    "        super(PixelEmbedModelResNet18, self).__init__()\n",
    "        self.emb_dimension = emb_dimension        \n",
    "        \n",
    "        resnet = models.resnet18(pretrained=pretrained)\n",
    "        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)\n",
    "        self.layer1, self.layer2, self.layer3, self.layer4 = resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
    "        \n",
    "                \n",
    "        # tweak resnet backbone to output features 8x smaller than input image\n",
    "        for n, m in self.layer3.named_modules():\n",
    "            if 'conv1' in n:\n",
    "                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
    "            elif 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "                \n",
    "        for n, m in self.layer4.named_modules():\n",
    "            if 'conv1' in n:\n",
    "                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
    "            elif 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "                \n",
    "        \n",
    "        self.streamTwo_feats = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=2, dilation=2, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=2, dilation=2, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "                \n",
    "        self.block5_dimRed = nn.Sequential(\n",
    "            nn.Conv2d(resnet.layer4[-1].conv2.out_channels, emb_dimension, \n",
    "                      kernel_size=1, stride=1, padding=0, dilation=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(emb_dimension)\n",
    "        )            \n",
    "        self.block5_feats = nn.Sequential(\n",
    "            nn.Conv2d(emb_dimension, emb_dimension, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(emb_dimension),\n",
    "            \n",
    "            nn.Conv2d(emb_dimension, emb_dimension, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(emb_dimension)\n",
    "        )\n",
    "        \n",
    "                \n",
    "        self.layer1_dimRed = nn.Sequential(\n",
    "            nn.Conv2d(resnet.layer1[-1].conv2.out_channels, int(emb_dimension/2), \n",
    "                      kernel_size=1, stride=1, padding=0, dilation=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(int(emb_dimension/2))\n",
    "        )\n",
    "        self.layer1_feats = nn.Sequential(\n",
    "            nn.Conv2d(int(emb_dimension/2), int(emb_dimension/2), kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(int(emb_dimension/2)),\n",
    "            \n",
    "            nn.Conv2d(int(emb_dimension/2), int(emb_dimension/2), kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(int(emb_dimension/2))\n",
    "        )\n",
    "                        \n",
    "                \n",
    "        self.layer2_dimRed = nn.Sequential(\n",
    "            nn.Conv2d(resnet.layer2[-1].conv2.out_channels, int(emb_dimension/2), \n",
    "                      kernel_size=1, stride=1, padding=0, dilation=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(int(emb_dimension/2))\n",
    "        )\n",
    "        self.layer2_feats = nn.Sequential(\n",
    "            nn.Conv2d(int(emb_dimension/2), int(emb_dimension/2), kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(int(emb_dimension/2)),\n",
    "            \n",
    "            nn.Conv2d(int(emb_dimension/2), int(emb_dimension/2), kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(int(emb_dimension/2))\n",
    "        )\n",
    "                \n",
    "\n",
    "        self.layer3_dimRed = nn.Sequential(\n",
    "            nn.Conv2d(resnet.layer3[-1].conv2.out_channels, int(emb_dimension/2), \n",
    "                      kernel_size=1, stride=1, padding=0, dilation=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(int(emb_dimension/2))\n",
    "        )\n",
    "        self.layer3_feats = nn.Sequential(\n",
    "            nn.Conv2d(int(emb_dimension/2), int(emb_dimension/2), kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(int(emb_dimension/2)),\n",
    "            \n",
    "            nn.Conv2d(int(emb_dimension/2), int(emb_dimension/2), kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(int(emb_dimension/2))\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.emb = nn.Sequential(\n",
    "            nn.Conv2d(int(emb_dimension*2.5+32), emb_dimension, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(emb_dimension),\n",
    "            \n",
    "            nn.Conv2d(emb_dimension, emb_dimension, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(emb_dimension)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.interp_x4 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)  \n",
    "        self.interp_x8 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)  \n",
    "        \n",
    "        input_size = inputs.size()\n",
    "        \n",
    "        out = self.layer0(inputs)\n",
    "        out_stream2 = self.streamTwo_feats(inputs)        \n",
    "        \n",
    "        out = self.layer1(out)        \n",
    "        out_layer1 = self.layer1_dimRed(out)        \n",
    "        out_layer1 = self.interp_x4(out_layer1)\n",
    "        out_layer1 = self.layer2_feats(out_layer1)\n",
    "        \n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        out_layer2 = self.layer2_dimRed(out)        \n",
    "        out_layer2 = self.interp_x8(out_layer2)\n",
    "        out_layer2 = self.layer2_feats(out_layer2)\n",
    "        \n",
    "        \n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        out_layer3 = self.layer3_dimRed(out)        \n",
    "        out_layer3 = self.interp_x8(out_layer3)\n",
    "        out_layer3 = self.layer3_feats(out_layer3)\n",
    "        \n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.block5_dimRed(out)\n",
    "        self.interp = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)        \n",
    "        out = self.interp(out)        \n",
    "        out = self.block5_feats(out)\n",
    "            \n",
    "     \n",
    "        out = torch.cat([out_stream2, out_layer1, out_layer2, out_layer3, out], 1)\n",
    "        out=self.emb(out)\n",
    "                \n",
    "        return out      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fcdbc65-5787-4031-9b7e-763489cb3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiamesePixelEmbed(nn.Module):\n",
    "    def __init__(self, emb_dimension=64, filterSize=11, device='cuda', pretrained=False):\n",
    "        super(SiamesePixelEmbed, self).__init__()\n",
    "        self.device = device\n",
    "        self.emb_dimension = emb_dimension  \n",
    "        self.PEMbase = PixelEmbedModelResNet18(emb_dimension=self.emb_dimension, pretrained=pretrained)  \n",
    "        self.rawEmbFeature1 = 0\n",
    "        self.rawEmbFeature2 = 0        \n",
    "        self.embFeature1_to_2 = 0\n",
    "        self.embFeature1_to_2 = 0\n",
    "        self.filterSize = filterSize\n",
    "        self.filterSize2Channel = self.filterSize**2\n",
    "                \n",
    "        self.ordered_embedding = nn.Sequential(            \n",
    "            nn.Conv2d(self.emb_dimension, self.filterSize2Channel, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(self.filterSize2Channel),     \n",
    "            nn.Conv2d(self.filterSize2Channel, self.filterSize2Channel, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(self.filterSize2Channel),            \n",
    "            nn.Conv2d(self.filterSize2Channel, self.filterSize2Channel, kernel_size=3, padding=1, bias=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs1, inputs2):        \n",
    "        self.rawEmbFeature1 = self.PEMbase.forward(inputs1)\n",
    "        \n",
    "        self.embFeature1_to_2 = self.ordered_embedding(self.rawEmbFeature1)        \n",
    "        self.embFeature1_to_2 = F.softmax(self.embFeature1_to_2, 1)\n",
    "        \n",
    "        return self.embFeature1_to_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7323ad-116c-4e57-8d07-37b9cb4a7be9",
   "metadata": {},
   "source": [
    "Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45e22de-3812-415c-9e8a-ea4c3d8109fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossOrderedPairReconstruction(nn.Module):\n",
    "    def __init__(self, device='cuda', filterSize=11):\n",
    "        super(LossOrderedPairReconstruction, self).__init__()\n",
    "        self.device = device\n",
    "        self.filterSize = filterSize        \n",
    "        self.filterSize2Channel = self.filterSize**2\n",
    "        self.reconstructImage = 0\n",
    "        \n",
    "    def forward(self, image1, image2, filters_img1_to_img2):\n",
    "        N,C,H,W = image1.size()\n",
    "        self.reconstructImage = self.rgbImageFilterFlow(image1, filters_img1_to_img2)\n",
    "        diff = self.reconstructImage - image2               \n",
    "        diff = torch.abs(diff)       \n",
    "        totloss = torch.sum(torch.sum(torch.sum(torch.sum(diff))))        \n",
    "        return totloss/(N*C*H*W)\n",
    "    \n",
    "    \n",
    "    def rgbImageFilterFlow(self, img, filters):                \n",
    "        inputChannelSize = 1\n",
    "        outputChannelSize = 1\n",
    "        N = img.size(0)\n",
    "        paddingFunc = nn.ZeroPad2d(int(self.filterSize/2))\n",
    "        img = paddingFunc(img)        \n",
    "        imgSize = [img.size(2),img.size(3)]\n",
    "        \n",
    "        out_R = F.unfold(img[:,0,:,:].unsqueeze(1), (self.filterSize, self.filterSize))\n",
    "        out_R = out_R.view(N, out_R.size(1), imgSize[0]-self.filterSize+1, imgSize[1]-self.filterSize+1)    \n",
    "        #out_R = paddingFunc(out_R)\n",
    "        out_R = torch.mul(out_R, filters)\n",
    "        out_R = torch.sum(out_R, dim=1).unsqueeze(1)\n",
    "\n",
    "        out_G = F.unfold(img[:,1,:,:].unsqueeze(1), (self.filterSize, self.filterSize))\n",
    "        out_G = out_G.view(N, out_G.size(1), imgSize[0]-self.filterSize+1, imgSize[1]-self.filterSize+1)    \n",
    "        #out_G = paddingFunc(out_G)\n",
    "        out_G = torch.mul(out_G, filters)\n",
    "        out_G = torch.sum(out_G, dim=1).unsqueeze(1)\n",
    "\n",
    "        out_B = F.unfold(img[:,2,:,:].unsqueeze(1), (self.filterSize, self.filterSize))\n",
    "        out_B = out_B.view(N, out_B.size(1), imgSize[0]-self.filterSize+1, imgSize[1]-self.filterSize+1)    \n",
    "        #out_B = paddingFunc(out_B)\n",
    "        out_B = torch.mul(out_B, filters)\n",
    "        out_B = torch.sum(out_B, dim=1).unsqueeze(1)\n",
    "        return torch.cat([out_R, out_G, out_B], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9bcd46-8650-437b-b3c2-ed5c70032a22",
   "metadata": {},
   "source": [
    "Trying to get their training demo work for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c44d773-82d4-4d6f-ae0b-0bd43790c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## init model ###################\n",
    "initModel = SiamesePixelEmbed(emb_dimension=embedding_dim, \n",
    "                              filterSize=kernel_size,\n",
    "                              device=device, pretrained=False)\n",
    "\n",
    "# initModel.load_state_dict(torch.load(os.path.join(exp_dir,'epoch-445.paramOnly')))\n",
    "initModel.to(device);\n",
    "\n",
    "\n",
    "# decreasing the momentum in batch normalization, as the default is too large for this work.\n",
    "allLayer_dict = initModel.state_dict()\n",
    "child_counter = 0\n",
    "for child in initModel.PEMbase.children():\n",
    "    for i in range(len(child)):        \n",
    "        if 'BatchNorm2d' in str(type(child[i])): \n",
    "            child[i].momentum=0.001\n",
    "            #print(child[i])            \n",
    "\n",
    "for i in range(len(initModel.ordered_embedding)):    \n",
    "    if 'BatchNorm2d' in str(type(initModel.ordered_embedding[i])): \n",
    "            initModel.ordered_embedding[i].momentum=0.001\n",
    "            #print(initModel.ordered_embedding[i])\n",
    "            \n",
    "child_counter = 0\n",
    "for child in initModel.children():\n",
    "    #print(\" child\", child_counter, \"is:\")\n",
    "    #print(child)\n",
    "    child_counter += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5ee5d-8e0f-4f1f-88df-7892c6a3e7c8",
   "metadata": {},
   "source": [
    "Path for this training_log to be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16cb3ce7-32ce-46a4-bb53-b88b9d46af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444c10ae-d3ee-42c8-9db3-518f01fa6ab5",
   "metadata": {},
   "source": [
    "Create training loop function for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b670f-7358-407f-aa0b-d375e8f8daf6",
   "metadata": {},
   "source": [
    "**NOTE:** If running this on your laptop and you haven't downloaded the requisite packages for training on your GPU, set `device='cpu'` to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e92b57d2-1ed5-448a-ad23-a78f032945bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, loss_1_to_2, optimizer, scheduler, \n",
    "                num_epochs=25, work_dir='./', device='cuda'):\n",
    "    \n",
    "    log_filename = os.path.join(work_dir,'train.log')    \n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):        \n",
    "        print('\\nEpoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        fn = open(log_filename,'a') # 'a' stands for append \n",
    "        fn.write('\\nEpoch {}/{}\\n'.format(epoch+1, num_epochs))\n",
    "        fn.write('--'*5+'\\n')\n",
    "        fn.close()\n",
    "\n",
    "        \n",
    "        scheduler.step() # Moves the \n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterate over data.\n",
    "        iterCount, sampleCount = 0, 0\n",
    "        for sample in dataloaders:\n",
    "            noisy_samples, clean_samples = sample\n",
    "            noise_samples = noisy_samples.to(device) # Putting images onto GPU\n",
    "            clean_samples = clean_samples.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            # Want to do this b/c pytorch tracks gradients and if you don't\n",
    "            # zero them out you'll have the new grads you learned added to \n",
    "            # previous layer gradients, which reduces effectivity of learning\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass (ie. run data thru model then update params via\n",
    "            # backpropogation, which is what this torch.set_grad_enabled(True)'\n",
    "            # does. It allows for the gradients to be remembered in the \n",
    "            # computation graph, which is how PyTorch relates each nodes input \n",
    "            # and output together. (Ask me if this literally makes no sense)\n",
    "            with torch.set_grad_enabled(True):\n",
    "                model.train() # Need to set this b/c model layers might act diff\n",
    "                embFeature1_to_2 = model(noisy_samples, clean_samples)\n",
    "                loss = loss_1_to_2(noisy_samples, clean_samples, embFeature1_to_2)\n",
    "                loss.backward() # Calcs the gradients of loss wrt every param w/ \n",
    "                                # requires_grad=True. If confused just google.\n",
    "                                # PyTorch documentation is lit.\n",
    "        \n",
    "\n",
    "\n",
    "                # statistics  \n",
    "                iterCount += 1\n",
    "                sampleCount += noisy_samples.size(0)                                \n",
    "                running_loss += loss.item() * noisy_samples.size(0)                                \n",
    "                print2screen_avgLoss = running_loss/sampleCount\n",
    "                                               \n",
    "                if iterCount%50==0:\n",
    "                    print('\\t{}/{} loss: {:.6f}'.format(iterCount, len(dataloaders), print2screen_avgLoss))\n",
    "                    fn = open(log_filename,'a')        \n",
    "                    fn.write('\\t{}/{} loss: {:.6f}\\n'.format(iterCount, len(dataloaders), print2screen_avgLoss))\n",
    "                    fn.close()\n",
    "  \n",
    "            epoch_loss = running_loss / dataset_sizes\n",
    "                                \n",
    "            print('\\tloss: {:.6f}'.format(epoch_loss))\n",
    "            fn = open(log_filename,'a')\n",
    "            fn.write('\\tloss: {:.6f}\\n'.format(epoch_loss))\n",
    "            fn.close()\n",
    "                    \n",
    "                \n",
    "            # deep copy the model\n",
    "            cur_model_wts = copy.deepcopy(model.state_dict())\n",
    "            path_to_save_paramOnly = os.path.join(work_dir, 'epoch-{}.paramOnly'.format(epoch+1))\n",
    "            torch.save(cur_model_wts, path_to_save_paramOnly)\n",
    "            \n",
    "        \n",
    "                \n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    fn = open(log_filename,'a')\n",
    "    fn.write('Training complete in {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    fn.close()\n",
    "   \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c1415c6-9239-4466-befb-c0467b424f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/500\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[56, 1, 64, 64] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113042/1954856536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m model_ft = train_model(initModel, train_dataloader, len(train_ds), \n\u001b[0m\u001b[1;32m     33\u001b[0m                        \u001b[0mloss_1_to_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                        \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_113042/1233067968.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, dataset_sizes, loss_1_to_2, optimizer, scheduler, num_epochs, work_dir, device)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Need to set this b/c model layers might act diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0membFeature1_to_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_1_to_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membFeature1_to_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calcs the gradients of loss wrt every param w/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_113042/3923453459.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs1, inputs2)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawEmbFeature1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPEMbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membFeature1_to_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordered_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawEmbFeature1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_113042/2649455789.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mout_stream2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamTwo_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[56, 1, 64, 64] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "################## loss function ###################\n",
    "loss_1_to_2 = LossOrderedPairReconstruction(device=device, filterSize=kernel_size)\n",
    "\n",
    "loss_l1norm = nn.L1Loss(size_average=True)\n",
    "\n",
    "optimizer_ft = optim.Adam([{'params': initModel.PEMbase.parameters()},\n",
    "                           {'params': initModel.ordered_embedding.parameters(), 'lr': base_lr},                           \n",
    "                         ], lr=base_lr)\n",
    "\n",
    "\n",
    "# Decay LR by a factor of 0.5 every int(total_epoch_num/5) epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=int(total_epoch_num/5), gamma=0.5)\n",
    "\n",
    "################## start training ###################\n",
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "\n",
    "save_dir = DATA\n",
    "log_filename = os.path.join(save_dir, 'PFF_train.log')\n",
    "\n",
    "\n",
    "fn = open(log_filename,'w')\n",
    "fn.write(log_filename+'\\t'+device+'\\n\\n')\n",
    "#fn.write(path.basename(__file__)+'\\n\\n')\n",
    "fn.close()\n",
    "file_to_note_bestModel = os.path.join(save_dir,'note_bestModel.log')\n",
    "fn = open(file_to_note_bestModel, 'w')\n",
    "fn.write('Record of best models on the way.\\n')\n",
    "fn.close()\n",
    "\n",
    "model_ft = train_model(initModel, train_dataloader, len(train_ds), \n",
    "                       loss_1_to_2, \n",
    "                       optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=total_epoch_num, \n",
    "                       work_dir=save_dir, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292cec41-d8af-4bb8-b8e0-4e7f6d1fa1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd113a47-fcb7-4115-8c29-86c0ce64b62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5565b-1a93-42b4-98cc-f7cc75b3e1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
