{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3871364-2a1d-4e99-be06-74e28ba34301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# import save_load as sl\n",
    "# import preprocess_data as ppd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "# from model import DnCNN\n",
    "# from Dataset import Img_Dataset\n",
    "import numpy as np \n",
    "import pathlib\n",
    "\n",
    "# Importing utitility functions for training\n",
    "from PT_files.model import DnCNN, DnCNN_B\n",
    "from PT_files.Dataset import Img_Dataset, Large_Img_Dataset\n",
    "import PT_files.preprocess_data as ppd\n",
    "import PT_files.save_load as sl\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552475b-d13f-4721-a404-1183b0135fba",
   "metadata": {},
   "source": [
    "# 0. Upload raw focal plane image pairs of (noisy/clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18824355-91fc-4857-b70b-ade161fe5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data naming notation is dataXXX-XXXX\n",
    "# XXX - number of samples\n",
    "# XXXX - size of img ie. 2000x2000 for this code block\n",
    "#raw_data = sl.NERSC_load('data1500-3000.npy')\n",
    "raw_data = sl.NERSC_load('data270-6000.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a9e61a-46dd-4fc4-81e1-6fd20f8f792c",
   "metadata": {},
   "source": [
    "# 1. Now create training and test sets from the raw data, still containing pairs of (noisy/clean) samples\n",
    "\n",
    "NOTE: These training & test sets are automatically saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23705f8d-0534-49d4-bcf1-720fbdccb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd.create_data_sets(data=raw_data,\n",
    "                     train_size=250,\n",
    "                     test_size=20,\n",
    "                     training_set_name='training_data250-6000.npy',\n",
    "                     test_set_name='test_data20-6000.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be140936-48f1-4cdd-8e3f-508cb7b1a59d",
   "metadata": {},
   "source": [
    "# 2. Check these newly created sets & thus reload them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed81cd-408b-484e-95e3-83ad3e3eb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = sl.NERSC_load('training_data250-6000.npy')\n",
    "test_data = sl.NERSC_load('test_data20-6000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03b923-9274-4983-b172-830290d27c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d347f-e759-4c4e-af6e-d71c3dbd88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48c34d-359c-4021-a635-c39d32e4df04",
   "metadata": {},
   "source": [
    "# 3. Put training samples into a Pytorch Dataloader object to allow easy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e096d-c82f-451a-8be4-21bdd368c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = Large_Img_Dataset(data_set=training_data,\n",
    "#                                   num_patchs=30,\n",
    "#                                   patch_size=50,\n",
    "#                                   width=6000,\n",
    "#                                   height=6000)\n",
    "\n",
    "train_dataset = Img_Dataset(data_set=training_data,\n",
    "                                  patch_size=200,\n",
    "                                  width=6000,\n",
    "                                  height=6000)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a21c30-8e5b-491c-90cb-7b9434dcd339",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b33100-2406-4eda-885d-a0f4cf290259",
   "metadata": {},
   "source": [
    "# 4. Run the training loop below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0e277-dcb1-4f66-94ae-392ab0aa1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put .to(device) to put the model parameters onto the GPU.\n",
    "# The data is already put on the GPU, so to be able to train the\n",
    "# parameters must be compatible with the data\n",
    "\n",
    "# model = DnCNN().to(device)\n",
    "model = DnCNN_B().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5376c3bb-1db4-4af1-b940-ef3de7ef4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)#, momentum=0.9)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.cuda(device), y.cuda(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y) /(2*len(X))\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss, batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44ce24-8b7d-4fae-a637-2484f3f2254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6dcd5c-095c-4c3e-a629-2a817a997a0d",
   "metadata": {},
   "source": [
    "# 5. Save model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020b925-e736-4e99-acb9-c73d6b8fee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving Models\n",
    "# current_dir = pathlib.Path().resolve()\n",
    "# model_params_path = current_dir / 'Model_params'\n",
    "# assert model_params_path.exists()\n",
    "# name = \"6k_model_bs16_e500_ps150.pth\"\n",
    "# path = model_params_path / name\n",
    "# torch.save(model.state_dict(), path)\n",
    "# print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9d255-810a-499a-b77a-4b6cd3df520b",
   "metadata": {},
   "source": [
    "Check to see if we can load pytorch model params via `np.load` or `sl.NERSC_load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb225d7-58ca-4a6f-88d6-8b69269f34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"/pscratch/sd/m/mdowicz/DESI_dn/Model_params/2k_model_bs64_e200.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05b338-fca3-491e-a152-70aa23928edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ad893-bc77-48a1-a646-b9a3839610b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl.NERSC_load(\"2k_model_bs64_e200.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d96694-ad4c-4b44-a79b-8ef1704886cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e0bc6-0d80-4a5b-80fa-3a40e63cb5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
