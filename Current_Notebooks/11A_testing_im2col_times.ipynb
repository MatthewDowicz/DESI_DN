{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3247419b-0c93-4514-8fdb-f24eb5598741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu, np_BatchNorm2d\n",
    "\n",
    "import time \n",
    "from collections import OrderedDict\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be335bc-c65f-40db-ba66-07b2ddd4d072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "# name = '6k_model_wb_e800_lys20_58feat.pth'\n",
    "name = '2k_model_bs64_e800_ps50_Adam.pth'\n",
    "# weights = np.load(DATA / name)\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)\n",
    "\n",
    "samp = sample[0][0][1000:3000, 1000:3000]\n",
    "samp = samp.reshape((1, 1, 2000, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e80dd57-f96b-4c13-a328-729123fb8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    get_indices_start = time.perf_counter()\n",
    "\n",
    "    # Get input size\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Calculations for the output H and W dimensions\n",
    "    height_out = ((height + (2*padding) - (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "    \n",
    "    \n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(kernel_size[0]), kernel_size[1])\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(height_out), width_out)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(kernel_size[1]), kernel_size[0])\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(width_out), height_out)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(input_channels), kernel_size[0] * kernel_size[1]).reshape(-1, 1)\n",
    "    \n",
    "    get_indices_end = time.perf_counter()\n",
    "    print('get_indices takes:', get_indices_end-get_indices_start, 'seconds')\n",
    "    \n",
    "    return i, j, d\n",
    "\n",
    "def im2col(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        - X: input image.\n",
    "        - HF: filter height.\n",
    "        - WF: filter width.\n",
    "        - stride: stride value.\n",
    "        - pad: padding value.\n",
    "\n",
    "        Returns:\n",
    "        -cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = input_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols\n",
    "\n",
    "def np_Conv2d(input_data, weights_dict, prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "575ee191-f69e-4169-bac0-d8c67a561265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.0936635509970074 seconds\n",
      "\n",
      "get_indices takes: 0.09243214500020258 seconds\n",
      "Im2col takes: 0.27699330099858344 seconds\n",
      "\n",
      "get_indices takes: 0.09232533899921691 seconds\n",
      "Im2col takes: 0.3036277600003814 seconds\n",
      "Conv takes: 0.6068648460022814 seconds\n"
     ]
    }
   ],
   "source": [
    "# First layer convolution\n",
    "\n",
    "# Note: The time for im2col is the time for im2col as well as get_indices\n",
    "# due to im2col calling get_indices\n",
    "\n",
    "# Note: This is the same for conv, except it calls im2col, which then calls\n",
    "# get_indices, thus you need to subtract the time of the previous function\n",
    "# against the current function to get the correct time\n",
    "get_indices(input_data=samp, weights_dict=weights, prefix='layers.0.0.');\n",
    "print()\n",
    "im2col(input_data=samp, weights_dict=weights, prefix='layers.0.0.');\n",
    "print()\n",
    "out = np_Conv2d(input_data=samp, weights_dict=weights, prefix='layers.0.0.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408930ce-60ec-4908-a8ae-cfe14dc96c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 4.5244469749995915 seconds\n",
      "\n",
      "get_indices takes: 4.50654714799748 seconds\n",
      "Im2col takes: 15.913829680997878 seconds\n",
      "\n",
      "get_indices takes: 4.469645105997188 seconds\n",
      "Im2col takes: 15.874881094001466 seconds\n",
      "Conv takes: 17.774021723998885 seconds\n"
     ]
    }
   ],
   "source": [
    "# Second layer convolution\n",
    "get_indices(input_data=out, weights_dict=weights, prefix='layers.1.0.');\n",
    "print()\n",
    "im2col(input_data=out, weights_dict=weights, prefix='layers.1.0.');\n",
    "print()\n",
    "out2 = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.1.0.');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6045217-0954-453e-b7e6-6c1b090de80c",
   "metadata": {},
   "source": [
    "Testing to find the bottleneck.\n",
    "\n",
    "THe bottleneck is in the slicing of the multi-dimensional arrays indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd71a065-b7b8-4bf0-b1fb-41873576bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_testing(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        - X: input image.\n",
    "        - HF: filter height.\n",
    "        - WF: filter width.\n",
    "        - stride: stride value.\n",
    "        - pad: padding value.\n",
    "\n",
    "        Returns:\n",
    "        -cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "    \n",
    "    padding_start = time.perf_counter()\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "\n",
    "    padding_end = time.perf_counter()\n",
    "    print('Im2col padding takes:', padding_end-padding_start, 'seconds')\n",
    "    print('This includes get_indices')\n",
    "    print()\n",
    "    \n",
    "    array_indexing_start = time.perf_counter()\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    array_padding_start = time.perf_counter()\n",
    "    cols = input_padded[:, d, i, j] # BOTTLENECK IS HERE\n",
    "    array_padding_end = time.perf_counter()\n",
    "    print('Im2col array padding takes:', array_padding_end-array_padding_start, 'seconds')\n",
    "    print()\n",
    "    \n",
    "    col_concat_start = time.perf_counter()\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    col_concat_end = time.perf_counter()\n",
    "    print('Im2col array column concatenation takes:', col_concat_end-col_concat_start, 'seconds')\n",
    "    print()\n",
    "    \n",
    "    array_indexing_end = time.perf_counter()\n",
    "    print('Im2col array indexing takes:', array_indexing_end-array_indexing_start, 'seconds')\n",
    "    print()\n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fe2a7c-6fd4-4a48-8c8a-b3cf59dcd182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 4.626220476999151 seconds\n",
      "Im2col padding takes: 4.756974407999223 seconds\n",
      "This includes get_indices\n",
      "\n",
      "Im2col array padding takes: 10.207006034001097 seconds\n",
      "\n",
      "Im2col array column concatenation takes: 1.0699494200016488 seconds\n",
      "\n",
      "Im2col array indexing takes: 11.277642648998153 seconds\n",
      "\n",
      "Im2col takes: 16.034689907999564 seconds\n"
     ]
    }
   ],
   "source": [
    "im2col_testing(input_data=out, weights_dict=weights, prefix='layers.1.0.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5d6b6b-6f60-45dc-9c62-d5e59f3390f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_testing(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        - X: input image.\n",
    "        - HF: filter height.\n",
    "        - WF: filter width.\n",
    "        - stride: stride value.\n",
    "        - pad: padding value.\n",
    "\n",
    "        Returns:\n",
    "        -cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "    \n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    \n",
    "    array_indexing_start = time.perf_counter()\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    array_slicing_start = time.perf_counter()\n",
    "    transposed_input_padded = input_padded.T\n",
    "    cols = transposed_input_padded[:, d, i, j].T\n",
    "    array_slicing_end = time.perf_counter()\n",
    "    print('Im2col array slicing takes:', array_slicing_end-array_slicing_start, 'seconds')\n",
    "    print()    \n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fdf94a4-e630-4496-9867-c8c3f81244e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 4.650804878998315 seconds\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 64 is out of bounds for axis 2 with size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50226/1070598401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim2col_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'layers.1.0.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_50226/570221654.py\u001b[0m in \u001b[0;36mim2col_testing\u001b[0;34m(input_data, weights_dict, prefix, stride, padding)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0marray_slicing_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtransposed_input_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransposed_input_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0marray_slicing_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Im2col array slicing takes:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_slicing_end\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0marray_slicing_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 64 is out of bounds for axis 2 with size 64"
     ]
    }
   ],
   "source": [
    "im2col_testing(input_data=out, weights_dict=weights, prefix='layers.1.0.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521dd4e6-b5e4-49a7-9445-f402ea71db51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e348379e-25d9-4b61-8c36-a69258094eb0",
   "metadata": {},
   "source": [
    "# Testing to see how many times 'get_indices' will be called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5220c19e-0644-4b82-b114-955a833ad248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_testing(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    get_indices_start = time.perf_counter()\n",
    "\n",
    "    # Get input size\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Calculations for the output H and W dimensions\n",
    "    height_out = ((height + (2*padding) - (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "    \n",
    "    mati_start = time.perf_counter()\n",
    "\n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(kernel_size[0]), kernel_size[1])\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(height_out), width_out)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "    \n",
    "    mati_end = time.perf_counter()\n",
    "    print('get_indices matrix i computation takes:', mati_end-mati_start, 'seconds')\n",
    "\n",
    "    matj_start = time.perf_counter()\n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(kernel_size[1]), kernel_size[0])\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(width_out), height_out)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "    \n",
    "    matj_end = time.perf_counter()\n",
    "    print('get_indices matrix j computation takes:', matj_end-matj_start, 'seconds')\n",
    "\n",
    "    matd_start = time.perf_counter()\n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(input_channels), kernel_size[0] * kernel_size[1]).reshape(-1, 1)\n",
    "    \n",
    "    matd_end = time.perf_counter()\n",
    "    print('get_indices matrix d computation takes:', matd_end-matd_start, 'seconds')\n",
    "    print()\n",
    "    \n",
    "    get_indices_end = time.perf_counter()\n",
    "    print('get_indices takes:', get_indices_end-get_indices_start, 'seconds')\n",
    "    \n",
    "    return i, j, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95fdba80-0415-4e37-830e-555ba03c6c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 4.493157625001913 seconds\n",
      "Im2col takes: 15.974034223996568 seconds\n",
      "Conv takes: 17.68410379800116 seconds\n"
     ]
    }
   ],
   "source": [
    "last = np_Conv2d(input_data=out2, weights_dict=weights, prefix='layers.18.0.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c620ec85-9b87-4c1c-bbda-ce9f8a488d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.09129129400025704 seconds\n",
      "get_indices takes: 4.535640594000142 seconds\n",
      "get_indices takes: 4.608535564002523 seconds\n"
     ]
    }
   ],
   "source": [
    "i,j,d = get_indices(input_data=samp, weights_dict=weights, prefix='layers.0.0.');\n",
    "i1, j1, d1=get_indices(input_data=out, weights_dict=weights, prefix='layers.1.0.');\n",
    "i2, j2, d2=get_indices(input_data=out2, weights_dict=weights, prefix='layers.2.0.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "027dfdb1-042a-4c4f-92d6-797b19d13483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 4.304084053001134 seconds\n"
     ]
    }
   ],
   "source": [
    "ilast, jlast, dlast = get_indices(input_data=last, weights_dict=weights, prefix='layers.19.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a3a3df7-6100-4007-b7e5-98882083fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# print(np.allclose(i,i1))\n",
    "print(np.allclose(i1,i2))\n",
    "\n",
    "# print(np.allclose(j,j1))\n",
    "print(np.allclose(j1,j2))\n",
    "\n",
    "# print(np.allclose(d,d1))\n",
    "print(np.allclose(d1,d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15948564-a7ec-4b51-b24b-ae32cf50fb15",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (9,4000000) (576,4000000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_99777/3029745580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \"\"\"\n\u001b[0;32m-> 2256\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mequal_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2363\u001b[0m     \u001b[0myfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m         \u001b[0mfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxfin\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0myfin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mwithin_tol\u001b[0;34m(x, y, atol, rtol)\u001b[0m\n\u001b[1;32m   2344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2346\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mless_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrtol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (9,4000000) (576,4000000) "
     ]
    }
   ],
   "source": [
    "np.allclose(i,i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70a00ec-3b16-4cce-84eb-e33563fa7b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 2000, 2000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0729a305-caa9-41b0-8b86-9a4d4668d967",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (9,4000000) (576,4000000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_99777/657274354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0milast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \"\"\"\n\u001b[0;32m-> 2256\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mequal_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2363\u001b[0m     \u001b[0myfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m         \u001b[0mfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxfin\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0myfin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mwithin_tol\u001b[0;34m(x, y, atol, rtol)\u001b[0m\n\u001b[1;32m   2344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2346\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mless_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrtol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (9,4000000) (576,4000000) "
     ]
    }
   ],
   "source": [
    "np.allclose(i, ilast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf6519-85d3-4c13-98cc-f49953f66fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
