{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a84f965-799a-42d0-ae2b-35c2d4e7279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu, np_Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56153889-1976-4a17-875c-581209d0f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_numpy_comparison(input_data,\n",
    "                             pytorch_output,\n",
    "                             numpy_output,\n",
    "                             sample_idx):\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(24,20))\n",
    "    vmin, vmax = np.percentile(input_data[sample_idx], (1,99))\n",
    "    # vmin, vmax = np.percentile(pytorch_output[sample][feature_map], (1,99))\n",
    "\n",
    "\n",
    "    ax[0].imshow(pytorch_output[sample_idx][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Pytorch BatchNorm', fontsize=30)\n",
    "    ax[1].imshow(input_data[sample_idx][0],vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Input Sample', fontsize=30)\n",
    "    ax[2].imshow(numpy_output[sample_idx][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[2].axis('off')\n",
    "    ax[2].set_title('Numpy BatchNorm', fontsize=30)\n",
    "    \n",
    "def np_BatchNorm2d(x, weights_dict, prefix, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Computes the batch normalized version of the input.\n",
    "    \n",
    "    This function implements a BatchNorm2d from PyTorch. A caveat to\n",
    "    remember is that this implementation is equivalent to nn.BatchNorm2d\n",
    "    in `model.eval()` mode. Batch normalization renormalizes the input \n",
    "    to the layer to a more parsable data range.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: numpy.ndarray\n",
    "        Input image data.\n",
    "    mean: numpy.ndarray\n",
    "        Running mean of the dataset, computed during training.\n",
    "    var: numpy.ndarray\n",
    "        Running variance of the dataset, computed during training.\n",
    "    beta: numpy.ndarray\n",
    "        Offset value added to the normalized output.\n",
    "        (These are the biases from the model parameter dictionary).\n",
    "    gamma: numpy.ndarray\n",
    "        Scale value to rescale the normalzied output.\n",
    "        (These are the weights from the model parameter dictionary).\n",
    "    epsilon: float\n",
    "        Small constant for numerical stability. \n",
    "        Default = 1e-5.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Output of the batch normalization.\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    The operation implemented in this function is:\n",
    "    \n",
    "    .. math:: \\\\frac{\\gamma (x - \\mu)}{\\sigma + \\epsilon} + \\\\beta\n",
    "    \n",
    "    where :math:`\\mu` is the running mean of the dataset and :math:`\\sigma` is\n",
    "    the running variance of the dataset, both of which are computed during\n",
    "    training.\n",
    "    \n",
    "    For more details and documentation on the PyTorch BatchNorm2d function\n",
    "    that this function mimics can be found at \n",
    "    https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n",
    "    \"\"\"\n",
    "    gamma = weights_dict[str(prefix) + 'weight'].detach().numpy().reshape(-1, 1, 1)\n",
    "    beta = weights_dict[str(prefix) + 'bias'].detach().numpy().reshape(-1, 1, 1)\n",
    "    mean = weights_dict[str(prefix) + 'running_mean'].detach().numpy().reshape(-1, 1, 1)\n",
    "    var = weights_dict[str(prefix) + 'running_var'].detach().numpy().reshape(-1, 1, 1)\n",
    "        \n",
    "        \n",
    "    output = ((x - mean) / np.sqrt(var + epsilon)) * gamma + beta\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79d6f8d-a2e8-4f00-80ef-a2c21baff8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n",
      "PyTorch Conv shape output = torch.Size([3, 58, 200, 200])\n",
      "PyTorch Batch shape output = torch.Size([3, 58, 200, 200])\n",
      "Numpy Conv output = (3, 58, 200, 200)\n",
      "Numpy Batch output = (3, 58, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)\n",
    "\n",
    "# Create a minibatch of size 3 and cut the samples into 200x200 patch_sizes\n",
    "# as well as converting it to pytorch for it to be used in the pytorch model\n",
    "sample = sample[0:3, :, 1400:1600, 1400:1600]\n",
    "sample_torch = torch.from_numpy(sample)\n",
    "\n",
    "# Create the first layer of DnCNN from pytorch \n",
    "# & get the pytorch dictionary that is created to be used in the numpy version of Conv2d\n",
    "# & get the output of the first layer\n",
    "model = nn.Conv2d(in_channels=1, out_channels=58, kernel_size=3, stride=1, padding='same') # 1 input channel, 1 output channels, kernelsize=3, stride=1, padding=0\n",
    "params = model.state_dict()\n",
    "pytorch_conv_output = model(sample_torch)\n",
    "# print the output shape\n",
    "print('PyTorch Conv shape output =', pytorch_conv_output.shape)\n",
    "\n",
    "model = nn.BatchNorm2d(num_features=58)#, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) # 1 output channels (everything after num features is default)\n",
    "batch_params = model.state_dict()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pytorch_batch_output = model(pytorch_conv_output)\n",
    "\n",
    "print('PyTorch Batch shape output =', pytorch_batch_output.shape)\n",
    "\n",
    "# Lastly let's visualize the first samples first feature map\n",
    "# plt.imshow(output[0][0].detach().numpy(), origin='lower')\n",
    "\n",
    "# Numpy version using the pytorchs weights \n",
    "numpy_conv_output = np_Conv2d(input_data=sample,\n",
    "                         weights_dict=params,\n",
    "                         padding='same')\n",
    "print('Numpy Conv output =',numpy_conv_output.shape)\n",
    "\n",
    "\n",
    "# Numpy version using the pytorchs weights \n",
    "numpy_batch_output = np_BatchNorm2d(x=numpy_conv_output,\n",
    "                         weights_dict=batch_params)\n",
    "print('Numpy Batch output =',numpy_batch_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c31747-5332-406b-902f-4c002d1d88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.isclose(numpy_conv_output, pytorch_conv_output.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5e59c-a49c-4848-aa9b-9f625301ceaf",
   "metadata": {},
   "source": [
    "**Note for np.allclose**\n",
    "\n",
    "If the following equation is element-wise True, then allclose returns True.\n",
    "\n",
    "`np.allclose(a,b)`\n",
    "\n",
    "`absolute(a - b) <= (atol + rtol * absolute(b))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae4ef6d-a315-4b75-8025-004abe7c2248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 1.49011612e-08 1.49011612e-08 0.00000000e+00\n",
      " 1.49011612e-08 1.49011612e-08 1.49011612e-08 1.49011612e-08\n",
      " 1.49011612e-08 1.49011612e-08]\n",
      "[1.3108317e-06 1.5506392e-06 1.6083989e-06 1.7209094e-06 1.8190431e-06\n",
      " 1.8757454e-06 1.9428971e-06 1.9566774e-06 1.9642291e-06 1.9737972e-06]\n"
     ]
    }
   ],
   "source": [
    "atol = 1e-07\n",
    "rtol = 1e-05\n",
    "# print(np.abs(numpy_conv_output - pytorch_conv_output.detach().cpu().numpy()) <= (atol + rtol * np.abs(pytorch_conv_output.detach().cpu().numpy())))\n",
    "print(np.abs(numpy_conv_output - pytorch_conv_output.detach().cpu().numpy())[0, 0, 0, :10])\n",
    "print((atol + rtol * np.abs(pytorch_conv_output.detach().cpu().numpy()))[0, 0, 0, :10])\n",
    "                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00704e30-3aaf-4f01-b38b-53f50ef72a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(numpy_conv_output, pytorch_conv_output.detach().cpu(), rtol=1e-05, atol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1956d38c-40a8-4295-a5d3-1393ae627b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(numpy_conv_output, pytorch_conv_output.detach().cpu(), rtol=1e-05, atol=0.71e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7f981f-da5d-418a-8cd1-2e03cb203266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(numpy_batch_output, pytorch_batch_output.detach().cpu(), rtol=1e-05, atol=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5f7880-bb22-4d30-a395-33ad8b789f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.12108318,  0.14506395,  0.15083991, ...,  0.13537174,\n",
       "          0.13633195,  0.14160129],\n",
       "        [ 0.10593177,  0.25874233,  0.3043707 , ...,  0.22633338,\n",
       "          0.21385492,  0.34497994],\n",
       "        [ 0.11713965,  0.28264287,  0.3246758 , ...,  0.23837422,\n",
       "          0.24536915,  0.34443921],\n",
       "        ...,\n",
       "        [ 0.16251622,  0.37535477,  0.36967564, ...,  0.1648812 ,\n",
       "          0.12990579,  0.24573709],\n",
       "        [ 0.16811386,  0.39523226,  0.3938899 , ...,  0.15333824,\n",
       "          0.20289654,  0.23135443],\n",
       "        [ 0.18527606,  0.32578528,  0.3317979 , ...,  0.16770712,\n",
       "          0.12977284,  0.1615704 ]],\n",
       "\n",
       "       [[-0.08950314, -0.00235143,  0.0086441 , ...,  0.06907723,\n",
       "          0.05905644,  0.19233812],\n",
       "        [-0.193326  , -0.05886739, -0.05855225, ...,  0.03289407,\n",
       "          0.0086733 ,  0.28571102],\n",
       "        [-0.22521693, -0.07597569, -0.08498289, ...,  0.01893511,\n",
       "          0.01440035,  0.29060641],\n",
       "        ...,\n",
       "        [-0.25254905, -0.01496804, -0.02354488, ...,  0.05374864,\n",
       "          0.0154833 ,  0.20267794],\n",
       "        [-0.26919365, -0.02185448, -0.02369706, ...,  0.04859388,\n",
       "          0.06733986,  0.19114898],\n",
       "        [-0.21194851, -0.10826081, -0.10847694, ...,  0.03644351,\n",
       "          0.02017248,  0.12130284]],\n",
       "\n",
       "       [[ 0.28340441,  0.55214792,  0.66217107, ...,  0.36189592,\n",
       "          0.37182283,  0.23061879],\n",
       "        [ 0.25472951,  0.56084061,  0.66590482, ...,  0.29376715,\n",
       "          0.31377995,  0.22384419],\n",
       "        [ 0.297997  ,  0.64944607,  0.74611866, ...,  0.29536009,\n",
       "          0.35252994,  0.2610274 ],\n",
       "        ...,\n",
       "        [ 0.35739082,  0.75406009,  0.75536466, ...,  0.13351712,\n",
       "          0.12773003,  0.08163542],\n",
       "        [ 0.36197323,  0.76482141,  0.7692914 , ...,  0.12907816,\n",
       "          0.13809687,  0.08479023],\n",
       "        [ 0.05915035,  0.29476947,  0.29810947, ...,  0.02641112,\n",
       "          0.0085871 , -0.01415907]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.42045113,  0.42965549,  0.44219825, ...,  0.37438983,\n",
       "          0.3795296 ,  0.30733913],\n",
       "        [ 0.4428784 ,  0.49999708,  0.53505695, ...,  0.43958417,\n",
       "          0.43075603,  0.38638437],\n",
       "        [ 0.47710034,  0.53029442,  0.56708002, ...,  0.43908438,\n",
       "          0.43880349,  0.39009511],\n",
       "        ...,\n",
       "        [ 0.53669149,  0.56920373,  0.56893957, ...,  0.36220786,\n",
       "          0.36618382,  0.35894519],\n",
       "        [ 0.54426444,  0.58721578,  0.59083891, ...,  0.36671817,\n",
       "          0.36538491,  0.35261834],\n",
       "        [ 0.53956741,  0.64643645,  0.6493153 , ...,  0.38342005,\n",
       "          0.37657142,  0.38451475]],\n",
       "\n",
       "       [[-0.12843014, -0.25637484, -0.29870227, ..., -0.24786384,\n",
       "         -0.26152474, -0.2594344 ],\n",
       "        [ 0.05757025, -0.03610237, -0.03620352, ..., -0.07829471,\n",
       "         -0.06344119, -0.18215831],\n",
       "        [ 0.09060916, -0.03027866, -0.01417841, ..., -0.04857678,\n",
       "         -0.08230869, -0.18986848],\n",
       "        ...,\n",
       "        [ 0.1568433 , -0.04372512, -0.03266486, ..., -0.10987432,\n",
       "         -0.08040161, -0.15198728],\n",
       "        [ 0.17950138, -0.01770924, -0.01573083, ..., -0.09708147,\n",
       "         -0.10549413, -0.15162915],\n",
       "        [ 0.18557897,  0.06852128,  0.06920031, ..., -0.09674108,\n",
       "         -0.07235163, -0.11683786]],\n",
       "\n",
       "       [[ 0.12680256,  0.11506628,  0.11332656, ...,  0.12535243,\n",
       "          0.12083328,  0.173631  ],\n",
       "        [ 0.25996298,  0.30990639,  0.34170708, ...,  0.25975305,\n",
       "          0.26418054,  0.26751575],\n",
       "        [ 0.27470231,  0.33723715,  0.37167063, ...,  0.25937766,\n",
       "          0.27146223,  0.26345998],\n",
       "        ...,\n",
       "        [ 0.32034099,  0.39022091,  0.3966637 , ...,  0.19849882,\n",
       "          0.21063605,  0.21243906],\n",
       "        [ 0.33953461,  0.41259751,  0.41321847, ...,  0.20354165,\n",
       "          0.22717208,  0.19807777],\n",
       "        [ 0.29551739,  0.37002081,  0.37255764, ...,  0.19423978,\n",
       "          0.19605383,  0.15851329]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_conv_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b06f11ee-e998-4ff5-a27f-6a725df77b28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (200,200) (58,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80994/2610888875.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumpy_conv_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (200,200) (58,) "
     ]
    }
   ],
   "source": [
    "numpy_conv_output[-1][-2] * batch_params['weight'].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b0131-f9b6-4dc5-9ea7-0cf6cfe48c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_conv_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575bcbf-2925-4c97-8853-a2d10f41fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_numpy_comparison(input_data=sample,\n",
    "                             pytorch_output=pytorch_conv_output,\n",
    "                             numpy_outputnumpy_conv_output,\n",
    "                             sample_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566099c1-b221-4d7f-8353-85daf766d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_numpy_comparison(input_data=sample,\n",
    "                             pytorch_output=pytorch_batch_output,\n",
    "                             numpy_output=numpy_batch_output,\n",
    "                             sample_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed2e850-ddde-47ba-82a9-e880f8a67d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
