{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2af089-3fd0-476e-905a-da5ab8f4e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "import torch\n",
    "# from torch import nn\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu#, np_BatchNorm2d, np_Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c18ad9c-cde3-4e79-9555-7d39a1866b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_numpy_comparison(input_data,\n",
    "                             pytorch_output,\n",
    "                             numpy_output,\n",
    "                             sample_idx):\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(24,20))\n",
    "    vmin, vmax = np.percentile(input_data[sample_idx], (1,99))\n",
    "    # vmin, vmax = np.percentile(pytorch_output[sample][feature_map], (1,99))\n",
    "\n",
    "\n",
    "    ax[0].imshow(pytorch_output[sample_idx][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Pytorch BatchNorm', fontsize=30)\n",
    "    ax[1].imshow(input_data[sample_idx][0],vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Input Sample', fontsize=30)\n",
    "    ax[2].imshow(numpy_output[sample_idx][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "    ax[2].axis('off')\n",
    "    ax[2].set_title('Numpy BatchNorm', fontsize=30)\n",
    "    \n",
    "    \n",
    "def full_grid_pass_window(dataset, model, model_params, samp_idx):\n",
    "    \n",
    "    full = np.empty((1, 1, 6000,6000))\n",
    "    count = np.empty((1, 1, 6000,6000))\n",
    "    \n",
    "    noise_data = dataset[0]\n",
    "    param_name = model_params\n",
    "    print('pass 1')\n",
    "    \n",
    "    current_dir = pathlib.Path().resolve()\n",
    "    model_params_path = current_dir / 'Model_params'\n",
    "    assert model_params_path.exists()\n",
    "    model_path = model_params_path / param_name\n",
    "    print('pass 2')\n",
    "    \n",
    "    model = model()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(str(model_path)))\n",
    "    model.eval();\n",
    "    print('pass 3')\n",
    "    # telling pytorch this is for inference and not learning, so keeps the weights unchanged\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        print('pass 4')\n",
    "        torch.cuda.empty_cache()\n",
    "        test_noise = torch.as_tensor(noise_data[samp_idx:samp_idx+1,:,:, :])\n",
    "        test_noise = test_noise.to(device)\n",
    "\n",
    "        print('pass 5')\n",
    "        output = model(test_noise)\n",
    "        print('pass 6')\n",
    "        resid_img = output.detach().cpu().numpy()\n",
    "        print('pass 7')\n",
    "\n",
    "        full[:, :, :, :] += resid_img\n",
    "\n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43273a8f-4130-4f26-a07c-9c4db85c5cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "name = '6k_model_wb_e800_lys20_58feat.pth'\n",
    "\n",
    "# weights = np.load(DATA / name)\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe156740-2c42-4a02-b5aa-1be0d1904153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def np_Conv2d(input_data, weights_dict, prefix, stride=1, padding=\"same\", dilation=1):\n",
    "    \n",
    "#     batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "#     kernel_size = weights_dict[str(prefix) + 'weight'][0][0].shape\n",
    "#     output_channels = len(weights_dict[str(prefix) + 'weight'])\n",
    "    \n",
    "#     # Convert string padding into numerical padding\n",
    "#     # Using strings allow for one variable to account for padding & mode (see signal.correlated2d)\n",
    "#     mode = padding\n",
    "#     if mode == \"same\":\n",
    "#         padding = 1\n",
    "#     elif mode == \"valid\":\n",
    "#         padding = 0\n",
    "    \n",
    "#     height_out = ((height + (2*padding) - dilation * (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "#     height_out = int(height_out)\n",
    "#     width_out = ((width + (2*padding) - dilation * (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "#     width_out = int(width_out)\n",
    "\n",
    "#     output = np.empty((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "#     for i in range(batch_size):\n",
    "#         for j in range(output_channels):\n",
    "#             output[i, j, :, :] = weights_dict[str(prefix) + 'bias'][j].detach().cpu().numpy() + signal.correlate2d(input_data[i][0], weights_dict[str(prefix) + 'weight'][j][0].detach().cpu().numpy(), mode=mode)\n",
    "               \n",
    "#     return output\n",
    "\n",
    "def np_Conv2d(input_data, weights_dict, prefix, stride=1, padding=\"same\", dilation=1):\n",
    "    \n",
    "    batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "    \n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    \n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Convert string padding into numerical padding\n",
    "    # Using strings allow for one variable to account for padding & mode (see signal.correlated2d)\n",
    "    mode = padding\n",
    "    if mode == \"same\":\n",
    "        padding = 1\n",
    "    elif mode == \"valid\":\n",
    "        padding = 0\n",
    "    \n",
    "    height_out = ((height + (2*padding) - dilation * (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - dilation * (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "\n",
    "    output = np.empty((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        for j in range(output_channels):\n",
    "            output[i, j, :, :] = weight[j].detach().cpu().numpy() + signal.correlate2d(input_data[i][0], bias[j][0].detach().cpu().numpy(), mode=mode)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def np_BatchNorm2d(input_data, prefix, weights_dict, epsilon=1e-5):\n",
    "    \n",
    "    x = input_data\n",
    "    \n",
    "    gamma = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    beta = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    mean = weights_dict[str(prefix) + 'running_mean'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    var = weights_dict[str(prefix) + 'running_var'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "        \n",
    "        \n",
    "    output = ((x - mean) / np.sqrt(var + epsilon)) * gamma + beta\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e81bb5-9dd8-4517-bbf9-70f055abd19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(data, prefix, weights_dict):\n",
    "    \n",
    "    if type(prefix) != str:\n",
    "        raise Exception(\"The prefix must be a string!\")\n",
    "                        \n",
    "    if prefix.endswith('0.'):\n",
    "        conv_layer_output = np_Conv2d(input_data=data,\n",
    "                                      weights_dict=weights_dict,\n",
    "                                      prefix=prefix)\n",
    "        return conv_layer_output\n",
    "    \n",
    "    elif prefix.endswith('1.'):\n",
    "        batch_layer_output = np_BatchNorm2d(x=data,\n",
    "                                            prefix=prefix,\n",
    "                                            weights_dict=weights_dict)\n",
    "        return batch_layer_output\n",
    "    \n",
    "    elif prefix.endswith('19.'):\n",
    "        conv_layer_output = np_Conv2d(input_data=data,\n",
    "                                      weights_dict=weights_dict,\n",
    "                                      prefix=prefix)\n",
    "        return conv_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c20a06-c16e-493f-916a-89595a40ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def np_Conv2d(input_data, weights_dict, prefix, stride=1, padding=\"same\", dilation=1):\n",
    "    \n",
    "#     batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "#     kernel_size = weights_dict[str(prefix) + 'weight'][0][0].shape\n",
    "#     output_channels = len(weights_dict[str(prefix) + 'weight'])\n",
    "    \n",
    "#     # Convert string padding into numerical padding\n",
    "#     # Using strings allow for one variable to account for padding & mode (see signal.correlated2d)\n",
    "#     mode = padding\n",
    "#     if mode == \"same\":\n",
    "#         padding = 1\n",
    "#     elif mode == \"valid\":\n",
    "#         padding = 0\n",
    "    \n",
    "#     height_out = ((height + (2*padding) - dilation * (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "#     height_out = int(height_out)\n",
    "#     width_out = ((width + (2*padding) - dilation * (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "#     width_out = int(width_out)\n",
    "\n",
    "#     output = np.empty((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "#     for i in range(batch_size):\n",
    "#         for j in range(output_channels):\n",
    "#             output[i, j, :, :] = weights_dict[str(prefix) + 'bias'][j].detach().cpu().numpy() + signal.correlate2d(input_data[i][0], weights_dict[str(prefix) + 'weight'][j][0].detach().cpu().numpy(), mode=mode)\n",
    "    \n",
    "#     return output\n",
    "\n",
    "\n",
    "# prefix_str = 'layers.0.0.'\n",
    "\n",
    "# %timeit conv_layer_output = np_Conv2d(input_data=sample[:0], weights_dict=weights, prefix=prefix_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2467780-c498-460b-aea9-4dab465b8552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 µs ± 120 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def np_BatchNorm2d(input_data, prefix, weights_dict, epsilon=1e-5):\n",
    "    \n",
    "    x = input_data\n",
    "    \n",
    "    gamma = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    beta = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    mean = weights_dict[str(prefix) + 'running_mean'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    var = weights_dict[str(prefix) + 'running_var'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "        \n",
    "        \n",
    "    output = ((x - mean) / np.sqrt(var + epsilon)) * gamma + beta\n",
    "    return output\n",
    "\n",
    "\n",
    "prefix_str = 'layers.1.1.'\n",
    "\n",
    "%timeit batch_layer_output = np_BatchNorm2d(input_data=sample[:0], weights_dict=weights, prefix=prefix_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac84d9c3-d977-42f3-aa01-45f9efb31b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_BatchNorm2d(input_data, prefix, weights_dict, epsilon=1e-5):\n",
    "    \n",
    "    x = input_data\n",
    "    \n",
    "    gamma = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    beta = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    mean = weights_dict[str(prefix) + 'running_mean'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    var = weights_dict[str(prefix) + 'running_var'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "        \n",
    "        \n",
    "    output = ((x - mean) / np.sqrt(var + epsilon)) * gamma + beta\n",
    "    return output\n",
    "\n",
    "\n",
    "prefix_str = 'layers.1.1.'\n",
    "\n",
    "# %timeit conv_layer_output = np_Conv2d(input_data=sample[:0], weights_dict=weights, prefix=prefix_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e34902c-0143-475e-9977-b2f6bb6b2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class np_DnCNN():\n",
    "#     \"\"\"\n",
    "#     A np_DnCNN model object. The model holds all of the relevant layer\n",
    "#     information, including layer names, weights, and definitions.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     weights: OrderedDict\n",
    "#         Ordered dictionary that maps layers names to layer weights.\n",
    "#     nlayers: int, optional\n",
    "#         Number of layers this model was trained for. Defaults to 20.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, weights, nlayers=20):\n",
    "#         # Store the weights to access later.\n",
    "#         self.weights = weights\n",
    "#         self.nlayers = nlayers\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4093f786-d62b-4ac7-8d0d-869b3b2268c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['layers.0.0.', 'layers.1.0.', 'layers.1.1.', 'layers.2.0.', 'layers.2.1.', 'layers.3.0.', 'layers.3.1.', 'layers.4.0.', 'layers.4.1.', 'layers.5.0.', 'layers.5.1.', 'layers.6.0.', 'layers.6.1.', 'layers.7.0.', 'layers.7.1.', 'layers.8.0.', 'layers.8.1.', 'layers.9.0.', 'layers.9.1.', 'layers.10.0.', 'layers.10.1.', 'layers.11.0.', 'layers.11.1.', 'layers.12.0.', 'layers.12.1.', 'layers.13.0.', 'layers.13.1.', 'layers.14.0.', 'layers.14.1.', 'layers.15.0.', 'layers.15.1.', 'layers.16.0.', 'layers.16.1.', 'layers.17.0.', 'layers.17.1.', 'layers.18.0.', 'layers.18.1.', 'layers.19.']\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Replace the last part of the key that describes what layer it is\n",
    "# part of and replaces it with empty space\n",
    "layers_list = [x.replace('weight', '').replace('bias', '').replace('running_mean', '').replace('running_var', '').replace('num_batches_tracked', '') for x in weights.keys()]\n",
    "# Convert this list which has duplicated elements due to removing\n",
    "# identifying elements ie. for the first conv layer we had\n",
    "# layers.0.0.weight & layers.0.0.bias, but now after removing them we\n",
    "# have layers.0.0 & layers.0.0\n",
    "# The code below deletes the duplicated elements\n",
    "layers_list = list(OrderedDict.fromkeys(layers_list))\n",
    "print(layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60d6a52-1b0a-4fa5-a9e6-4f5ae57c45cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_196381/2497449358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output = model_flow(input_data=sample[:2], weights_dict=weights, prefix_list=layers_list)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m# pdb.pm()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2346\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2348\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2349\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_196381/2497449358.py\u001b[0m in \u001b[0;36mmodel_flow\u001b[0;34m(input_data, weights_dict, prefix_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     output = np_Conv2d(input_data=input_data,\n\u001b[0m\u001b[1;32m      4\u001b[0m                    \u001b[0mweights_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    prefix=prefix_list[0])\n",
      "\u001b[0;32m/tmp/ipykernel_196381/2862027591.py\u001b[0m in \u001b[0;36mnp_Conv2d\u001b[0;34m(input_data, weights_dict, prefix, stride, padding, dilation)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "def model_flow(input_data, weights_dict, prefix_list):\n",
    "    \n",
    "    output = np_Conv2d(input_data=input_data,\n",
    "                   weights_dict=weights_dict,\n",
    "                   prefix=prefix_list[0])\n",
    "\n",
    "\n",
    "    for i in range(len(prefix_list)-2):\n",
    "        print(prefix_list[i+1])\n",
    "\n",
    "        if prefix_list[i+1].endswith('0.'):\n",
    "\n",
    "            output = np_Conv2d(input_data=output,\n",
    "                               weights_dict=weights_dict,\n",
    "                               prefix=prefix_list[i+1])\n",
    "\n",
    "        elif layers_list[i+1].endswith('1.'):\n",
    "            output = np_BatchNorm2d(input_data=output,\n",
    "                                    weights_dict=weights_dict,\n",
    "                                    prefix=prefix_list[i+1])\n",
    "\n",
    "    output = np_Conv2d(input_data=output,\n",
    "                       weights_dict=weights_dict,\n",
    "                       prefix=prefix_list[-1])\n",
    "    \n",
    "    return output\n",
    "\n",
    "%timeit output = model_flow(input_data=sample[:2], weights_dict=weights, prefix_list=layers_list)\n",
    "# pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "285fff0c-e438-4bf4-8a12-d2703ccfef0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.1.0.\n",
      "layers.1.1.\n",
      "layers.2.0.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_181621/4143310760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayers_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         output = np_Conv2d(input_data=output,\n\u001b[0m\u001b[1;32m     13\u001b[0m                            \u001b[0mweights_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                            prefix=layers_list[i+1])\n",
      "\u001b[0;32m/tmp/ipykernel_181621/2175636635.py\u001b[0m in \u001b[0;36mnp_Conv2d\u001b[0;34m(input_data, weights_dict, prefix, stride, padding, dilation)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36mcorrelate2d\u001b[0;34m(in1, in2, mode, boundary, fillvalue)\u001b[0m\n\u001b[1;32m   1784\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_valfrommode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m     \u001b[0mbval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bvalfromboundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboundary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1786\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolve2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mswapped_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1st layer\n",
    "output = np_Conv2d(input_data=sample[:1],\n",
    "                   weights_dict=weights,\n",
    "                   prefix=layers_list[0])\n",
    "\n",
    "\n",
    "for i in range(len(layers_list)-2):\n",
    "    print(layers_list[i+1])\n",
    "    \n",
    "    if layers_list[i+1].endswith('0.'):\n",
    "        \n",
    "        output = np_Conv2d(input_data=output,\n",
    "                           weights_dict=weights,\n",
    "                           prefix=layers_list[i+1])\n",
    "        \n",
    "    elif layers_list[i+1].endswith('1.'):\n",
    "        output = np_BatchNorm2d(input_data=output,\n",
    "                                weights_dict=weights,\n",
    "                                prefix=layers_list[i+1])\n",
    "        \n",
    "output = np_Conv2d(input_data=output,\n",
    "                   weights_dict=weights,\n",
    "                   prefix=layers_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e03064-004c-4614-9399-21e915623d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe07f5de-5177-4511-926f-cfe48ec4eab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'layers.19.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e8c83bc5-437d-4fe2-8cb1-ded6b153a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_list[0].endswith('0.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "271344e6-b537-4049-9288-a76ea411b62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.1.0.\n",
      "layers.1.1.\n",
      "layers.2.0.\n",
      "layers.2.1.\n",
      "layers.3.0.\n",
      "layers.3.1.\n",
      "layers.4.0.\n",
      "layers.4.1.\n",
      "layers.5.0.\n",
      "layers.5.1.\n",
      "layers.6.0.\n",
      "layers.6.1.\n",
      "layers.7.0.\n",
      "layers.7.1.\n",
      "layers.8.0.\n",
      "layers.8.1.\n",
      "layers.9.0.\n",
      "layers.9.1.\n",
      "layers.10.0.\n",
      "layers.10.1.\n",
      "layers.11.0.\n",
      "layers.11.1.\n",
      "layers.12.0.\n",
      "layers.12.1.\n",
      "layers.13.0.\n",
      "layers.13.1.\n",
      "layers.14.0.\n",
      "layers.14.1.\n",
      "layers.15.0.\n",
      "layers.15.1.\n",
      "layers.16.0.\n",
      "layers.16.1.\n",
      "layers.17.0.\n",
      "layers.17.1.\n",
      "layers.18.0.\n",
      "layers.18.1.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(layers_list)-2): # -2 to account for not looping through 1st & last layer\n",
    "    print(layers_list[i+1]) # +1 to start the loop after the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3cb7ccaa-86e4-4bba-bdcf-19d14e908c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 49s ± 94.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "prefix_str = 'layers.0.0.'\n",
    "\n",
    "%timeit conv_layer_output = np_Conv2d(input_data=sample[:2], weights_dict=weights, prefix=prefix_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1363727-0c14-49bb-8232-b0b8c46e6675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['layers.0.0.weight', 'layers.0.0.bias', 'layers.1.0.weight', 'layers.1.0.bias', 'layers.1.1.weight', 'layers.1.1.bias', 'layers.1.1.running_mean', 'layers.1.1.running_var', 'layers.1.1.num_batches_tracked', 'layers.2.0.weight', 'layers.2.0.bias', 'layers.2.1.weight', 'layers.2.1.bias', 'layers.2.1.running_mean', 'layers.2.1.running_var', 'layers.2.1.num_batches_tracked', 'layers.3.0.weight', 'layers.3.0.bias', 'layers.3.1.weight', 'layers.3.1.bias', 'layers.3.1.running_mean', 'layers.3.1.running_var', 'layers.3.1.num_batches_tracked', 'layers.4.0.weight', 'layers.4.0.bias', 'layers.4.1.weight', 'layers.4.1.bias', 'layers.4.1.running_mean', 'layers.4.1.running_var', 'layers.4.1.num_batches_tracked', 'layers.5.0.weight', 'layers.5.0.bias', 'layers.5.1.weight', 'layers.5.1.bias', 'layers.5.1.running_mean', 'layers.5.1.running_var', 'layers.5.1.num_batches_tracked', 'layers.6.0.weight', 'layers.6.0.bias', 'layers.6.1.weight', 'layers.6.1.bias', 'layers.6.1.running_mean', 'layers.6.1.running_var', 'layers.6.1.num_batches_tracked', 'layers.7.0.weight', 'layers.7.0.bias', 'layers.7.1.weight', 'layers.7.1.bias', 'layers.7.1.running_mean', 'layers.7.1.running_var', 'layers.7.1.num_batches_tracked', 'layers.8.0.weight', 'layers.8.0.bias', 'layers.8.1.weight', 'layers.8.1.bias', 'layers.8.1.running_mean', 'layers.8.1.running_var', 'layers.8.1.num_batches_tracked', 'layers.9.0.weight', 'layers.9.0.bias', 'layers.9.1.weight', 'layers.9.1.bias', 'layers.9.1.running_mean', 'layers.9.1.running_var', 'layers.9.1.num_batches_tracked', 'layers.10.0.weight', 'layers.10.0.bias', 'layers.10.1.weight', 'layers.10.1.bias', 'layers.10.1.running_mean', 'layers.10.1.running_var', 'layers.10.1.num_batches_tracked', 'layers.11.0.weight', 'layers.11.0.bias', 'layers.11.1.weight', 'layers.11.1.bias', 'layers.11.1.running_mean', 'layers.11.1.running_var', 'layers.11.1.num_batches_tracked', 'layers.12.0.weight', 'layers.12.0.bias', 'layers.12.1.weight', 'layers.12.1.bias', 'layers.12.1.running_mean', 'layers.12.1.running_var', 'layers.12.1.num_batches_tracked', 'layers.13.0.weight', 'layers.13.0.bias', 'layers.13.1.weight', 'layers.13.1.bias', 'layers.13.1.running_mean', 'layers.13.1.running_var', 'layers.13.1.num_batches_tracked', 'layers.14.0.weight', 'layers.14.0.bias', 'layers.14.1.weight', 'layers.14.1.bias', 'layers.14.1.running_mean', 'layers.14.1.running_var', 'layers.14.1.num_batches_tracked', 'layers.15.0.weight', 'layers.15.0.bias', 'layers.15.1.weight', 'layers.15.1.bias', 'layers.15.1.running_mean', 'layers.15.1.running_var', 'layers.15.1.num_batches_tracked', 'layers.16.0.weight', 'layers.16.0.bias', 'layers.16.1.weight', 'layers.16.1.bias', 'layers.16.1.running_mean', 'layers.16.1.running_var', 'layers.16.1.num_batches_tracked', 'layers.17.0.weight', 'layers.17.0.bias', 'layers.17.1.weight', 'layers.17.1.bias', 'layers.17.1.running_mean', 'layers.17.1.running_var', 'layers.17.1.num_batches_tracked', 'layers.18.0.weight', 'layers.18.0.bias', 'layers.18.1.weight', 'layers.18.1.bias', 'layers.18.1.running_mean', 'layers.18.1.running_var', 'layers.18.1.num_batches_tracked', 'layers.19.weight', 'layers.19.bias'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_output = np_Conv2d(input_data=sample[0],\n",
    "                              weights_dict=weights,\n",
    "                              prefix=prefix_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50cf9c19-6667-4362-aad3-9397e4c1827a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([58, 1, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'layers.0.0.'\n",
    "end = 'weight'\n",
    "\n",
    "# print(prefix + end)\n",
    "\n",
    "weights[prefix + end].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24be593c-458d-43b2-9bb3-21a35668d057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['layers.0.0.weight', 'layers.0.0.bias', 'layers.1.0.weight', 'layers.1.0.bias', 'layers.1.1.weight', 'layers.1.1.bias', 'layers.1.1.running_mean', 'layers.1.1.running_var', 'layers.1.1.num_batches_tracked', 'layers.2.0.weight', 'layers.2.0.bias', 'layers.2.1.weight', 'layers.2.1.bias', 'layers.2.1.running_mean', 'layers.2.1.running_var', 'layers.2.1.num_batches_tracked', 'layers.3.0.weight', 'layers.3.0.bias', 'layers.3.1.weight', 'layers.3.1.bias', 'layers.3.1.running_mean', 'layers.3.1.running_var', 'layers.3.1.num_batches_tracked', 'layers.4.0.weight', 'layers.4.0.bias', 'layers.4.1.weight', 'layers.4.1.bias', 'layers.4.1.running_mean', 'layers.4.1.running_var', 'layers.4.1.num_batches_tracked', 'layers.5.0.weight', 'layers.5.0.bias', 'layers.5.1.weight', 'layers.5.1.bias', 'layers.5.1.running_mean', 'layers.5.1.running_var', 'layers.5.1.num_batches_tracked', 'layers.6.0.weight', 'layers.6.0.bias', 'layers.6.1.weight', 'layers.6.1.bias', 'layers.6.1.running_mean', 'layers.6.1.running_var', 'layers.6.1.num_batches_tracked', 'layers.7.0.weight', 'layers.7.0.bias', 'layers.7.1.weight', 'layers.7.1.bias', 'layers.7.1.running_mean', 'layers.7.1.running_var', 'layers.7.1.num_batches_tracked', 'layers.8.0.weight', 'layers.8.0.bias', 'layers.8.1.weight', 'layers.8.1.bias', 'layers.8.1.running_mean', 'layers.8.1.running_var', 'layers.8.1.num_batches_tracked', 'layers.9.0.weight', 'layers.9.0.bias', 'layers.9.1.weight', 'layers.9.1.bias', 'layers.9.1.running_mean', 'layers.9.1.running_var', 'layers.9.1.num_batches_tracked', 'layers.10.0.weight', 'layers.10.0.bias', 'layers.10.1.weight', 'layers.10.1.bias', 'layers.10.1.running_mean', 'layers.10.1.running_var', 'layers.10.1.num_batches_tracked', 'layers.11.0.weight', 'layers.11.0.bias', 'layers.11.1.weight', 'layers.11.1.bias', 'layers.11.1.running_mean', 'layers.11.1.running_var', 'layers.11.1.num_batches_tracked', 'layers.12.0.weight', 'layers.12.0.bias', 'layers.12.1.weight', 'layers.12.1.bias', 'layers.12.1.running_mean', 'layers.12.1.running_var', 'layers.12.1.num_batches_tracked', 'layers.13.0.weight', 'layers.13.0.bias', 'layers.13.1.weight', 'layers.13.1.bias', 'layers.13.1.running_mean', 'layers.13.1.running_var', 'layers.13.1.num_batches_tracked', 'layers.14.0.weight', 'layers.14.0.bias', 'layers.14.1.weight', 'layers.14.1.bias', 'layers.14.1.running_mean', 'layers.14.1.running_var', 'layers.14.1.num_batches_tracked', 'layers.15.0.weight', 'layers.15.0.bias', 'layers.15.1.weight', 'layers.15.1.bias', 'layers.15.1.running_mean', 'layers.15.1.running_var', 'layers.15.1.num_batches_tracked', 'layers.16.0.weight', 'layers.16.0.bias', 'layers.16.1.weight', 'layers.16.1.bias', 'layers.16.1.running_mean', 'layers.16.1.running_var', 'layers.16.1.num_batches_tracked', 'layers.17.0.weight', 'layers.17.0.bias', 'layers.17.1.weight', 'layers.17.1.bias', 'layers.17.1.running_mean', 'layers.17.1.running_var', 'layers.17.1.num_batches_tracked', 'layers.18.0.weight', 'layers.18.0.bias', 'layers.18.1.weight', 'layers.18.1.bias', 'layers.18.1.running_mean', 'layers.18.1.running_var', 'layers.18.1.num_batches_tracked', 'layers.19.weight', 'layers.19.bias'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8449e64-b0de-4fe0-8097-4d44c9a500e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'layers.1.1.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_list = [x.replace('weight', '').replace('bias', '').replace('running_mean', '').replace('running_var', '').replace('num_batches_tracked', '') for x in weights.keys()]\n",
    "layers_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "29f7d942-421a-47d2-a701-833719782362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers.0.0.',\n",
       " 'layers.1.0.',\n",
       " 'layers.1.1.',\n",
       " 'layers.2.0.',\n",
       " 'layers.2.1.',\n",
       " 'layers.3.0.',\n",
       " 'layers.3.1.',\n",
       " 'layers.4.0.',\n",
       " 'layers.4.1.',\n",
       " 'layers.5.0.',\n",
       " 'layers.5.1.',\n",
       " 'layers.6.0.',\n",
       " 'layers.6.1.',\n",
       " 'layers.7.0.',\n",
       " 'layers.7.1.',\n",
       " 'layers.8.0.',\n",
       " 'layers.8.1.',\n",
       " 'layers.9.0.',\n",
       " 'layers.9.1.',\n",
       " 'layers.10.0.',\n",
       " 'layers.10.1.',\n",
       " 'layers.11.0.',\n",
       " 'layers.11.1.',\n",
       " 'layers.12.0.',\n",
       " 'layers.12.1.',\n",
       " 'layers.13.0.',\n",
       " 'layers.13.1.',\n",
       " 'layers.14.0.',\n",
       " 'layers.14.1.',\n",
       " 'layers.15.0.',\n",
       " 'layers.15.1.',\n",
       " 'layers.16.0.',\n",
       " 'layers.16.1.',\n",
       " 'layers.17.0.',\n",
       " 'layers.17.1.',\n",
       " 'layers.18.0.',\n",
       " 'layers.18.1.',\n",
       " 'layers.19.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9dd7fa6b-56d3-428f-bc46-00b3420761bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers.6.0.', 'layers.6.1.', 'layers.0.0.', 'layers.2.0.', 'layers.7.0.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [i for n, i in enumerate(layers_list) if i not in layers_list[:n]]\n",
    "res[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef383fcb-cf64-4dbb-930d-280f55e10bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers.6.0.',\n",
       " 'layers.6.1.',\n",
       " 'layers.0.0.',\n",
       " 'layers.2.0.',\n",
       " 'layers.7.0.',\n",
       " 'layers.11.0.',\n",
       " 'layers.12.0.',\n",
       " 'layers.3.1.',\n",
       " 'layers.8.0.',\n",
       " 'layers.15.0.',\n",
       " 'layers.5.0.',\n",
       " 'layers.1.1.',\n",
       " 'layers.13.1.',\n",
       " 'layers.17.0.',\n",
       " 'layers.19.',\n",
       " 'layers.8.1.',\n",
       " 'layers.4.1.',\n",
       " 'layers.9.0.',\n",
       " 'layers.10.0.',\n",
       " 'layers.10.1.',\n",
       " 'layers.17.1.',\n",
       " 'layers.18.1.',\n",
       " 'layers.16.1.',\n",
       " 'layers.13.0.',\n",
       " 'layers.15.1.',\n",
       " 'layers.5.1.',\n",
       " 'layers.18.0.',\n",
       " 'layers.4.0.',\n",
       " 'layers.9.1.',\n",
       " 'layers.11.1.',\n",
       " 'layers.14.0.',\n",
       " 'layers.12.1.',\n",
       " 'layers.2.1.',\n",
       " 'layers.3.0.',\n",
       " 'layers.16.0.',\n",
       " 'layers.7.1.',\n",
       " 'layers.14.1.',\n",
       " 'layers.1.0.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_list = list(set(layers_list))\n",
    "layers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df79dd17-9f78-4160-a3c3-3da7722224eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function str.find>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'queen'.find("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc086c6-18b9-4015-bd02-3b0a4f6db02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function str.find>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'queen'.find"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc5a5a-b8ab-4148-9fe1-35f200090a15",
   "metadata": {},
   "source": [
    "Some good [string methods](https://docs.python.org/2.5/lib/string-methods.html)\n",
    "\n",
    "or these [Python 3 versions](https://docs.python.org/3/library/stdtypes.html#string-methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4978c23-7564-4ab8-b595-5b71fd63bea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['layers.0.0.weight', 'layers.0.0.bias', 'layers.1.0.weight', 'layers.1.0.bias', 'layers.1.1.weight', 'layers.1.1.bias', 'layers.1.1.running_mean', 'layers.1.1.running_var', 'layers.1.1.num_batches_tracked', 'layers.2.0.weight', 'layers.2.0.bias', 'layers.2.1.weight', 'layers.2.1.bias', 'layers.2.1.running_mean', 'layers.2.1.running_var', 'layers.2.1.num_batches_tracked', 'layers.3.0.weight', 'layers.3.0.bias', 'layers.3.1.weight', 'layers.3.1.bias', 'layers.3.1.running_mean', 'layers.3.1.running_var', 'layers.3.1.num_batches_tracked', 'layers.4.0.weight', 'layers.4.0.bias', 'layers.4.1.weight', 'layers.4.1.bias', 'layers.4.1.running_mean', 'layers.4.1.running_var', 'layers.4.1.num_batches_tracked', 'layers.5.0.weight', 'layers.5.0.bias', 'layers.5.1.weight', 'layers.5.1.bias', 'layers.5.1.running_mean', 'layers.5.1.running_var', 'layers.5.1.num_batches_tracked', 'layers.6.0.weight', 'layers.6.0.bias', 'layers.6.1.weight', 'layers.6.1.bias', 'layers.6.1.running_mean', 'layers.6.1.running_var', 'layers.6.1.num_batches_tracked', 'layers.7.0.weight', 'layers.7.0.bias', 'layers.7.1.weight', 'layers.7.1.bias', 'layers.7.1.running_mean', 'layers.7.1.running_var', 'layers.7.1.num_batches_tracked', 'layers.8.0.weight', 'layers.8.0.bias', 'layers.8.1.weight', 'layers.8.1.bias', 'layers.8.1.running_mean', 'layers.8.1.running_var', 'layers.8.1.num_batches_tracked', 'layers.9.0.weight', 'layers.9.0.bias', 'layers.9.1.weight', 'layers.9.1.bias', 'layers.9.1.running_mean', 'layers.9.1.running_var', 'layers.9.1.num_batches_tracked', 'layers.10.0.weight', 'layers.10.0.bias', 'layers.10.1.weight', 'layers.10.1.bias', 'layers.10.1.running_mean', 'layers.10.1.running_var', 'layers.10.1.num_batches_tracked', 'layers.11.0.weight', 'layers.11.0.bias', 'layers.11.1.weight', 'layers.11.1.bias', 'layers.11.1.running_mean', 'layers.11.1.running_var', 'layers.11.1.num_batches_tracked', 'layers.12.0.weight', 'layers.12.0.bias', 'layers.12.1.weight', 'layers.12.1.bias', 'layers.12.1.running_mean', 'layers.12.1.running_var', 'layers.12.1.num_batches_tracked', 'layers.13.0.weight', 'layers.13.0.bias', 'layers.13.1.weight', 'layers.13.1.bias', 'layers.13.1.running_mean', 'layers.13.1.running_var', 'layers.13.1.num_batches_tracked', 'layers.14.0.weight', 'layers.14.0.bias', 'layers.14.1.weight', 'layers.14.1.bias', 'layers.14.1.running_mean', 'layers.14.1.running_var', 'layers.14.1.num_batches_tracked', 'layers.15.0.weight', 'layers.15.0.bias', 'layers.15.1.weight', 'layers.15.1.bias', 'layers.15.1.running_mean', 'layers.15.1.running_var', 'layers.15.1.num_batches_tracked', 'layers.16.0.weight', 'layers.16.0.bias', 'layers.16.1.weight', 'layers.16.1.bias', 'layers.16.1.running_mean', 'layers.16.1.running_var', 'layers.16.1.num_batches_tracked', 'layers.17.0.weight', 'layers.17.0.bias', 'layers.17.1.weight', 'layers.17.1.bias', 'layers.17.1.running_mean', 'layers.17.1.running_var', 'layers.17.1.num_batches_tracked', 'layers.18.0.weight', 'layers.18.0.bias', 'layers.18.1.weight', 'layers.18.1.bias', 'layers.18.1.running_mean', 'layers.18.1.running_var', 'layers.18.1.num_batches_tracked', 'layers.19.weight', 'layers.19.bias'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2a793f-b937-4c6d-bc78-5358927bfb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers.19.weight', 'layers.19.bias']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    layers = [k for k in weights.keys() if k.startswith(\"layers.\"+str(i))]\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f259aafc-c6a5-4122-819a-6a2eb15481be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bi'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    for k in weights.keys():\n",
    "        layers = k.strip(\"layers.\"+str(i))\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40819041-83b2-45cb-a4ee-65ce2c724904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers.1.0.weight',\n",
       " 'layers.1.0.bias',\n",
       " 'layers.1.1.weight',\n",
       " 'layers.1.1.bias',\n",
       " 'layers.1.1.running_mean',\n",
       " 'layers.1.1.running_var',\n",
       " 'layers.1.1.num_batches_tracked']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for i in weights.keys():\n",
    "    if 'layers.1.' in i:\n",
    "        y.append(i)\n",
    "        \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6199c368-4b42-471e-9361-08894ef405de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers.1.0.weight',\n",
       " 'layers.1.0.bias',\n",
       " 'layers.1.1.weight',\n",
       " 'layers.1.1.bias',\n",
       " 'layers.1.1.running_mean',\n",
       " 'layers.1.1.running_var',\n",
       " 'layers.1.1.num_batches_tracked']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87caf120-a923-410b-8b30-d099302a5dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weight', 'bi', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi', 'weight', 'bi', 'unning_mean', 'unning_v', 'num_batches_tracked', 'weight', 'bi']\n"
     ]
    }
   ],
   "source": [
    "lys = []\n",
    "for i in weights.keys():\n",
    "    # str.lstrip: Return a copy of the string with trailing characters removed.\n",
    "    #The chars argument is a string specifying the set of characters to be removed.\n",
    "    #If omitted or None, the chars argument defaults to removing whitespace.\n",
    "    #The chars argument is not a suffix; rather, all combinations of its values are stripped:\n",
    "    lys.append(i.strip('layers.0123456789'))\n",
    "    \n",
    "print(lys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5adab212-1edb-4902-872a-87216559784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0.weight', '0.0.bias', '1.0.weight', '1.0.bias', '1.1.weight', '1.1.bias', '1.1.running_mean', '1.1.running_var', '1.1.num_batches_tracked', '2.0.weight', '2.0.bias', '2.1.weight', '2.1.bias', '2.1.running_mean', '2.1.running_var', '2.1.num_batches_tracked', '3.0.weight', '3.0.bias', '3.1.weight', '3.1.bias', '3.1.running_mean', '3.1.running_var', '3.1.num_batches_tracked', '4.0.weight', '4.0.bias', '4.1.weight', '4.1.bias', '4.1.running_mean', '4.1.running_var', '4.1.num_batches_tracked', '5.0.weight', '5.0.bias', '5.1.weight', '5.1.bias', '5.1.running_mean', '5.1.running_var', '5.1.num_batches_tracked', '6.0.weight', '6.0.bias', '6.1.weight', '6.1.bias', '6.1.running_mean', '6.1.running_var', '6.1.num_batches_tracked', '7.0.weight', '7.0.bias', '7.1.weight', '7.1.bias', '7.1.running_mean', '7.1.running_var', '7.1.num_batches_tracked', '8.0.weight', '8.0.bias', '8.1.weight', '8.1.bias', '8.1.running_mean', '8.1.running_var', '8.1.num_batches_tracked', '9.0.weight', '9.0.bias', '9.1.weight', '9.1.bias', '9.1.running_mean', '9.1.running_var', '9.1.num_batches_tracked', '10.0.weight', '10.0.bias', '10.1.weight', '10.1.bias', '10.1.running_mean', '10.1.running_var', '10.1.num_batches_tracked', '11.0.weight', '11.0.bias', '11.1.weight', '11.1.bias', '11.1.running_mean', '11.1.running_var', '11.1.num_batches_tracked', '12.0.weight', '12.0.bias', '12.1.weight', '12.1.bias', '12.1.running_mean', '12.1.running_var', '12.1.num_batches_tracked', '13.0.weight', '13.0.bias', '13.1.weight', '13.1.bias', '13.1.running_mean', '13.1.running_var', '13.1.num_batches_tracked', '14.0.weight', '14.0.bias', '14.1.weight', '14.1.bias', '14.1.running_mean', '14.1.running_var', '14.1.num_batches_tracked', '15.0.weight', '15.0.bias', '15.1.weight', '15.1.bias', '15.1.running_mean', '15.1.running_var', '15.1.num_batches_tracked', '16.0.weight', '16.0.bias', '16.1.weight', '16.1.bias', '16.1.running_mean', '16.1.running_var', '16.1.num_batches_tracked', '17.0.weight', '17.0.bias', '17.1.weight', '17.1.bias', '17.1.running_mean', '17.1.running_var', '17.1.num_batches_tracked', '18.0.weight', '18.0.bias', '18.1.weight', '18.1.bias', '18.1.running_mean', '18.1.running_var', '18.1.num_batches_tracked', '19.weight', '19.bias']\n"
     ]
    }
   ],
   "source": [
    "lys = []\n",
    "for i in weights.keys():\n",
    "    # str.lstrip: Return a copy of the string with trailing characters removed.\n",
    "    #The chars argument is a string specifying the set of characters to be removed.\n",
    "    #If omitted or None, the chars argument defaults to removing whitespace.\n",
    "    #The chars argument is not a suffix; rather, all combinations of its values are stripped:\n",
    "    lys.append(i.lstrip('layers.'))\n",
    "    \n",
    "print(lys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b13671-765c-4b18-9978-6229ab978730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lys)):\n",
    "    if 'bias' in lys[i]:\n",
    "        print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c593f91c-c4cf-468c-af46-ea4473efc065",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (1302659768.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67058/1302659768.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    ly1.append(\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ly1 = []\n",
    "\n",
    "if lys[0].startswith('0') == True:\n",
    "    ly1.append("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb02c3-a62f-446e-8065-9fdcdce14538",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    lys.startswith("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d827340-9507-4778-9abb-f20052c6f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    layers = {'layer'+str(i): lys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64bc20-99e0-46a1-b7fb-9bb7bb724d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lys = []\n",
    "for i in weights.keys():\n",
    "    # str.lstrip: Return a copy of the string with trailing characters removed.\n",
    "    #The chars argument is a string specifying the set of characters to be removed.\n",
    "    #If omitted or None, the chars argument defaults to removing whitespace.\n",
    "    #The chars argument is not a suffix; rather, all combinations of its values are stripped:\n",
    "    lys.append(i.removeprefix('layers.0123456789'))\n",
    "    \n",
    "print(lys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52104b-9467-48c8-a495-fa6ee86034b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0_weights = np.asarray(weights['layers.0.0.weight'].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c077e2-66a0-441a-b913-f083e1948dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv0_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43931d-50b9-43d9-9903-b99d5caebb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = sl.NERSC_load('training_data_60%_6000.npy')        \n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "\n",
    "sample = test_data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a91c6c-3d06-4dbf-832b-5a0066a5cf29",
   "metadata": {},
   "source": [
    "```python\n",
    "# Indices of the data that will be given to the numpy DnCNN model\n",
    "print(test_data.shape) \n",
    ">>>(2, 108, 1, 6000, 6000)\n",
    "-> (noisy/clean pair, num of samps, num of channels, height, width)\n",
    "\n",
    "print(test_data[0].shape) # noisy sample chosen. test_data[1]==clean\n",
    ">>>(108, 1, 6000, 6000)\n",
    "-> (num of samps, num of channels, height, width)\n",
    "\n",
    "print(test_data[0][0].shape) # first noisy image of noisy sample chosen\n",
    ">>>(1, 6000, 6000)\n",
    "-> (num of channels, height, width)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee6499-aeef-432e-a378-7143b76ee8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a853e-c661-4800-9874-888bf2b57465",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx=2000\n",
    "end_idx=2200\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,10))\n",
    "vmin, vmax = np.percentile(sample[0][start_idx:end_idx,start_idx:end_idx], (1,99))\n",
    "\n",
    "\n",
    "ax.imshow(sample[0][start_idx:end_idx,start_idx:end_idx],\n",
    "             vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "ax.axis('off')\n",
    "ax.set_title('Noisy Sample', fontsize=30)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,10))\n",
    "vmin, vmax = np.percentile(sample[0][start_idx:end_idx,start_idx:end_idx], (1,99))\n",
    "\n",
    "\n",
    "ax.imshow(sample[0][0:6000,0:2000],\n",
    "             vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "ax.axis('off')\n",
    "ax.set_title('Noisy Sample', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e0ad4-da34-4112-bec4-25c583bcaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape # one channel, 6000 pixel height, by 6000 pixel width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34533f12-44ad-4d37-9488-77c51edbd939",
   "metadata": {},
   "source": [
    "# for conv2d in pytorch padding=1 is ~ padding=\"same\"\n",
    "\n",
    "Good discussion found [here](https://stackoverflow.com/questions/62166719/padding-same-conversion-to-pytorch-padding#:~:text=In%20PyTorch%20you%20can%20directly,~%20%22same%22%20in%20keras.)\n",
    "\n",
    "Difference of keras/tf `batch_normalization` and pytorch's `batch_norm2d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad9992-cf27-4498-a252-58bc19516c4e",
   "metadata": {},
   "source": [
    "DnCNN uses `Conv2D`, `BatchNorm2d`, and `ReLU` layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96138a8-774f-477a-92a1-4dc6f30353dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the nunmpy conv layer vid\n",
    "# input-shape = (depth, height, width)\n",
    "# kernel_size = size of each matrix inside each kernel\n",
    "# depth = num of kernels we want and hence the depth of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce596799-a162-441c-a273-1cddc4599eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# batchnorm weights\n",
    "'layers.1.1.weight', \n",
    "'layers.1.1.bias', \n",
    "'layers.1.1.running_mean', \n",
    "'layers.1.1.running_var', \n",
    "'layers.1.1.num_batches_tracked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc877fa5-4017-4ddf-b571-144a7e85c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weights =', weights['layers.1.1.weight'])\n",
    "print('Biases =', weights['layers.1.1.bias'])\n",
    "print('Mean =', weights['layers.1.1.running_mean'])\n",
    "print('var =', weights['layers.1.1.running_var'])\n",
    "print('num_batches_tracked(?) =', weights['layers.1.1.num_batches_tracked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c22579-6311-430a-8cb8-7a49d6e4eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a25f4-8a49-4ac4-9088-529abf7eb55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activations\n",
    "relu = lambda x: np.maximum(0, x)\n",
    "\n",
    "# Required Layers\n",
    "\n",
    "def BatchNorm2d(x, mean, var, beta, gamma, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Computes the batch normalized version of the input.\n",
    "    \n",
    "    This function implements a batch normalization layer. Batch normalization\n",
    "    renormalizes the input to the layer to a more parsable data range.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: numpy.ndarray\n",
    "        Input image data.\n",
    "    mean: numpy.ndarray\n",
    "        Running mean of the dataset, computed during training.\n",
    "    var: numpy.ndarray\n",
    "        Running variance of the dataset, computed during training.\n",
    "    beta: numpy.ndarray\n",
    "        Offset value added to the normalized output.\n",
    "        (These are the biases from the model parameter dictionary).\n",
    "    gamma: numpy.ndarray\n",
    "        Scale value to rescale the normalzied output.\n",
    "        (These are the weights from the model parameter dictionary).\n",
    "    epsilon: float\n",
    "        Small constant for numerical stability. \n",
    "        Default = 1e-5.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Output of the batch normalization.\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    The operation implemented in this function is:\n",
    "    \n",
    "    .. math:: \\\\frac{\\gamma (x - \\mu)}{\\sigma + \\epsilon} + \\\\beta\n",
    "    \n",
    "    where :math:`\\mu` is the running mean of the dataset and :math:`\\sigma` is\n",
    "    the running variance of the dataset, both of which are computed during\n",
    "    training.\n",
    "    \n",
    "    For more details and documentation on the PyTorch BatchNorm2d function\n",
    "    that this function mimics can be found at \n",
    "    https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n",
    "    \"\"\"\n",
    "    return ((x - mean) / np.sqrt(var + epsilon)) * gamma + beta\n",
    "\n",
    "\n",
    "def Conv2d():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54c65c-aed8-4689-8328-11d9c16003ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data[0].shape)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925fb30-396d-4d9f-90f5-2234b227fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights['layers.1.1.weight'])\n",
    "print('Biases =', weights['layers.1.1.bias'])\n",
    "print('Mean =', weights['layers.1.1.running_mean'])\n",
    "print('var =', weights['layers.1.1.running_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268a475-0d8f-4bd0-a300-cfcd5c62122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchNorm2d(x=sample,\n",
    "            mean=weights['layers.1.1.running_mean'].detach().cpu().numpy(),\n",
    "            var=weights['layers.1.1.running_var'].detach().cpu().numpy(),\n",
    "            gamma=weights['layers.1.1.weight'].detach().cpu().numpy(),\n",
    "            beta=weights['layers.1.1.bias'].detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
