{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970379a9-6168-4b9c-89fe-beb140dd83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu\n",
    "\n",
    "import time \n",
    "from collections import OrderedDict\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730649b-3e67-47ed-b4f2-f755a98857ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Testing the `im2col` MATLAB function. Want to see if it's faster and then see if the results are any better...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3afc16-98b3-4a18-a10d-7294463e0f85",
   "metadata": {},
   "source": [
    "Might be interesting to look at the [numpy-ml package](https://github.com/ddbourgin/numpy-ml/blob/master/numpy_ml/neural_nets/utils/utils.py) to see how they create a 2D Convolution layer.\n",
    "\n",
    "- They take inspiration from Andrej Karpathy's `im2col.py` file which can be found in these [slides here](http://cs231n.stanford.edu/slides/2016/winter1516_lecture11.pdf). \n",
    "\n",
    "- An article that I believe talks about the speed of `im2col.py` is [linked here](https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/). Need to read.\n",
    "\n",
    "- Lastly, there's a nice package that implements convolutions in a slow (ie. nested for loops) and a fast way (ie. uses im2col idea). Seems like it's fast? That's linked [here](https://github.com/3outeille/CNNumpy/blob/master/src/slow/layers.py)\n",
    "    - [Blog post](https://hackmd.io/@machine-learning/blog-post-cnnumpy-slow) discussing the `slow` version \n",
    "    - [Blog post](https://hackmd.io/@machine-learning/blog-post-cnnumpy-fast) discussing the `fast` version that uses im2col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e68b2e-b2a9-4773-b066-13677f4e9cfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0. Checking where the change in numpy DnCNN and PyTorch DnCNN comes into play.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b0bb5a-0a7b-4fa5-a132-23d543845d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "name = '2k_model_bs64_e800_ps50_Adam.pth'\n",
    "\n",
    "# weights = np.load(DATA / name)\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7cb528c-d272-422e-a5bf-828eaa432afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \n",
    "    # Get input size\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Calculations for the output H and W dimensions\n",
    "    height_out = ((height + (2*padding) - (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "    \n",
    "    \n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(kernel_size[0]), kernel_size[1])\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(height_out), width_out)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(kernel_size[1]), kernel_size[0])\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(width_out), height_out)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(input_channels), kernel_size[0] * kernel_size[1]).reshape(-1, 1)\n",
    "    \n",
    "    return i, j, d\n",
    "\n",
    "def im2col(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        - X: input image.\n",
    "        - HF: filter height.\n",
    "        - WF: filter width.\n",
    "        - stride: stride value.\n",
    "        - pad: padding value.\n",
    "\n",
    "        Returns:\n",
    "        -cols: output matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = input_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    return cols\n",
    "\n",
    "def np_Conv2d(input_data, weights_dict, prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282e0cf6-8e31-4abb-8e62-d896ac4ccefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv takes 0.6308269230066799 seconds\n"
     ]
    }
   ],
   "source": [
    "samp = sample[0][0][1000:3000, 1000:3000]\n",
    "samp = samp.reshape((1, 1, 2000, 2000))\n",
    "conv_out = np_Conv2d(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "# conv_out = np_Conv2d(input_data=conv_out, weights_dict=weights, prefix='layers.1.0.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d468a873-d45d-4276-9cdc-609de97616fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "test_sample = samp\n",
    "test_sample = torch.as_tensor(test_sample)\n",
    "test_sample = test_sample.to(device)\n",
    "# sample_torch = torch.from_numpy(sample)\n",
    "# params = OrderedDict({'weight': weights['layers.0.0.weight'], 'bias': weights['layers.0.0.bias']})\n",
    "params = OrderedDict({'0.weight': weights['layers.0.0.weight'], '0.bias': weights['layers.0.0.bias']})#, '2.weight': weights['layers.1.0.weight'], '2.bias': weights['layers.1.0.bias']})\n",
    "\n",
    "# model = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding='same') # 1 input channel, 1 output channels, kernelsize=3, stride=1, padding=0\n",
    "model = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1))#,\n",
    "                                        #nn.ReLU(inplace=True))#,\n",
    "                      # nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "# params = model.state_dict()\n",
    "# print(params.keys())\n",
    "model.to(device)\n",
    "model.load_state_dict(params)\n",
    "pytorch_conv_out = model(test_sample)\n",
    "pytorch_conv_out = pytorch_conv_out.detach().cpu().numpy()\n",
    "\n",
    "print(np.allclose(conv_out, pytorch_conv_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5350a539-5733-4dcd-9d00-2087dc834430",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28894/4256400877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \"\"\"\n\u001b[0;32m-> 2256\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mequal_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mless_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrtol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2348\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2349\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asanyarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "np.allclose(test_sample, samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff1540-d9ba-4f43-b8bd-ead51e90e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \n",
    "    # Get input size\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Calculations for the output H and W dimensions\n",
    "    height_out = ((height + (2*padding) - (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "    \n",
    "    \n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(kernel_size[0]), kernel_size[1])\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(height_out), width_out)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(kernel_size[1]), kernel_size[0])\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(width_out), height_out)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(input_channels), kernel_size[0] * kernel_size[1]).reshape(-1, 1)\n",
    "    \n",
    "    return i, j, d\n",
    "\n",
    "def im2col(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        - X: input image.\n",
    "        - HF: filter height.\n",
    "        - WF: filter width.\n",
    "        - stride: stride value.\n",
    "        - pad: padding value.\n",
    "\n",
    "        Returns:\n",
    "        -cols: output matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = input_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    return cols\n",
    "\n",
    "def np_Conv2d(input_data, weights_dict, prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    return out\n",
    "\n",
    "def np_BatchNorm2d(input_data, prefix, weights_dict, epsilon=1e-5):\n",
    "    \n",
    "    x = input_data\n",
    "    \n",
    "    gamma = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    beta = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    mean = weights_dict[str(prefix) + 'running_mean'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    var = weights_dict[str(prefix) + 'running_var'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "        \n",
    "        \n",
    "    output = ((x - mean) / np.sqrt(var + epsilon)) * gamma + beta\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562721f-a7a5-4846-babd-f84f35084250",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "name = '2k_model_bs64_e800_ps50_Adam.pth'\n",
    "\n",
    "# weights = np.load(DATA / name)\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208de1c4-0da0-4c4d-996b-56c3f6547561",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = sample[0][0][1000:3000, 1000:3000]\n",
    "samp = samp.reshape((1, 1, 2000, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37864ee-374e-4b19-818f-61a9a0ea2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DnCNN Model\n",
    "\n",
    "# 1st layer block\n",
    "conv_out = np_Conv2d(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "print(1)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=conv_out, weights_dict=weights, prefix='layers.1.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.1.1.')\n",
    "out = relu(batch_out)\n",
    "print(2)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.2.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.2.1.')\n",
    "out = relu(batch_out)\n",
    "print(3)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.3.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.3.1.')\n",
    "out = relu(batch_out)\n",
    "print(4)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.4.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.4.1.')\n",
    "out = relu(batch_out)\n",
    "print(5)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.5.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.5.1.')\n",
    "out = relu(batch_out)\n",
    "print(6)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.6.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.6.1.')\n",
    "out = relu(batch_out)\n",
    "print(7)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.7.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.7.1.')\n",
    "out = relu(batch_out)\n",
    "print(8)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.8.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.8.1.')\n",
    "out = relu(batch_out)\n",
    "print(9)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.9.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.9.1.')\n",
    "out = relu(batch_out)\n",
    "print(10)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.10.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.10.1.')\n",
    "out = relu(batch_out)\n",
    "print(11)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.11.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.11.1.')\n",
    "out = relu(batch_out)\n",
    "print(12)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.12.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.12.1.')\n",
    "out = relu(batch_out)\n",
    "print(13)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.13.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.13.1.')\n",
    "out = relu(batch_out)\n",
    "print(14)\n",
    "\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.14.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.14.1.')\n",
    "out = relu(batch_out)\n",
    "print(15)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.15.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.15.1.')\n",
    "out = relu(batch_out)\n",
    "print(16)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.16.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.16.1.')\n",
    "out = relu(batch_out)\n",
    "print(17)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.17.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.17.1.')\n",
    "out = relu(batch_out)\n",
    "print(18)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.18.0.')\n",
    "batch_out = np_BatchNorm2d(input_data=conv_out, weights_dict=weights, prefix='layers.18.1.')\n",
    "out = relu(batch_out)\n",
    "print(19)\n",
    "\n",
    "# Last layer\n",
    "conv_out = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.19.')\n",
    "print(20)\n",
    "\n",
    "resid_img = samp - conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea9b76-26a0-476a-b2be-ebec46216920",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(30, 26))\n",
    "vmin, vmax = np.percentile(samp[0][0], (1,99))\n",
    "\n",
    "axes[0].imshow(samp[0][0], vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[0].set_title('Input Noisy Image', fontsize=20)\n",
    "axes[1].imshow(resid_img[0][0],vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[1].set_title('Numpy Denoised Image', fontsize=20)\n",
    "axes[2].imshow(samp[0][0][1000:1200,1000:1200], vmin=vmin, vmax=vmax,origin='lower')\n",
    "axes[2].set_title('Numpy Noisy Image', fontsize=20)\n",
    "axes[3].imshow(resid_img[0][0][1000:1200,1000:1200], vmin=vmin, vmax=vmax,origin='lower')\n",
    "axes[3].set_title('Numpy Denoised Image', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1c98e-78cd-462f-b59a-a5907e2bddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_window(dataset,\n",
    "                model,\n",
    "                model_params,\n",
    "                samp_idx,\n",
    "                h_start,\n",
    "                h_end,\n",
    "                w_start,\n",
    "                w_end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to calculate a specified sized inference window.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset: np.array\n",
    "        Dataset of coupled noisy & clean images of full 6k images\n",
    "    model: Pytorch model\n",
    "        DnCNN\n",
    "    model_params: str\n",
    "        Models parameters for the 2k image trained model\n",
    "    samp_idx: int\n",
    "        Sample index to select which of the test images to be used for \n",
    "        inference\n",
    "    h_start: int\n",
    "        The height starting index of the inference window.\n",
    "        E.g. It would be the origin for the y-coord in a 2-D plot\n",
    "    h_end: int\n",
    "        The height ending index of the inference window.\n",
    "        E.g. It would be the end of the y-axis for the y-coord \n",
    "        in a 2-D plot\n",
    "    w_start: int\n",
    "        The horizontal starting index of the inference window.\n",
    "        E.g. It would be the origin for the x-coord in a 2-D plot\n",
    "    w_end: int\n",
    "        The horizontal ending index of the inference window.\n",
    "        E.g. It would be the end of the x-axis for the x-coord \n",
    "        in a 2-D plot\n",
    "   \n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    full: np.array\n",
    "        Array of the models output over the window region.\n",
    "    count: np.array\n",
    "        Array of 1's that keeps track of which pixels have had\n",
    "        inferenced done upon them. This is so later on averaging can\n",
    "        be done for pixels that had overlapping inference window\n",
    "        calculations.\n",
    "    \"\"\"\n",
    "    \n",
    "    full = np.empty((1, 1, 6000, 6000))\n",
    "    count = np.empty((1, 1, 6000, 6000))\n",
    "    \n",
    "    noise_data = dataset[0]\n",
    "    params_name = model_params\n",
    "    \n",
    "    current_dir = pathlib.Path().resolve()\n",
    "    model_params_path = current_dir / 'Model_params'\n",
    "    assert model_params_path.exists()\n",
    "    model_path = model_params_path / params_name\n",
    "    print('Check pt 1')\n",
    "    \n",
    "    model = model()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(str(model_path)))\n",
    "    model.eval()\n",
    "    print('Check pt 2')\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "                \n",
    "        torch.cuda.empty_cache()\n",
    "        test_noise = torch.as_tensor(noise_data[samp_idx:samp_idx+1, :, h_start:h_end, w_start:w_end])\n",
    "        test_noise = test_noise.to(device)\n",
    "        print('Check pt 3')\n",
    "\n",
    "        \n",
    "        output = model(test_noise)\n",
    "        resid_img = output.detach().cpu().numpy()\n",
    "        print('Check pt 4')\n",
    "        \n",
    "        test_noise.detach().cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "        del test_noise\n",
    "        \n",
    "        full[:, :, h_start:h_end, w_start:w_end] += resid_img\n",
    "        count[:, :, h_start:h_end, w_start:w_end] += 1\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        del resid_img\n",
    "        print('Run finished')\n",
    "        \n",
    "        \n",
    "    return full, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c51a71-7003-4790-914a-efd2f28fb125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PT_files.model import DnCNN\n",
    "\n",
    "full_c1, count_c1 = grid_window(dataset=test_data,\n",
    "                                        model=DnCNN,\n",
    "                                        model_params=\"2k_model_bs64_e800_ps50_Adam.pth\",\n",
    "                                        samp_idx=0,\n",
    "                                        h_start=1000,\n",
    "                                        h_end=3000,\n",
    "                                        w_start=1000,\n",
    "                                        w_end=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cef54c-8555-496e-8502-985e9ec8e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch = full_c1[0][0][1000:3000, 1000:3000]\n",
    "pytorch_out = np.reshape(pytorch, (1, 1, 2000, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803d443-1207-4e82-8964-f22584a2ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(30, 26))\n",
    "vmin, vmax = np.percentile(samp[0][0], (1,99))\n",
    "\n",
    "axes[0,0].imshow(samp[0][0], vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[0,0].set_title('Input Noisy Image', fontsize=20)\n",
    "axes[0,1].imshow(resid_img[0][0],vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[0,1].set_title('Numpy Denoised Image', fontsize=20)\n",
    "axes[0,2].imshow(samp[0][0][1000:1200,1000:1200], vmin=vmin, vmax=vmax,origin='lower')\n",
    "axes[0,2].set_title('Numpy Noisy Image', fontsize=20)\n",
    "axes[0,3].imshow(resid_img[0][0][1000:1200,1000:1200], vmin=vmin, vmax=vmax,origin='lower')\n",
    "axes[0,3].set_title('Numpy Denoised Image', fontsize=20)\n",
    "\n",
    "axes[1,0].imshow(samp[0][0], vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[1,0].set_title('Input Noisy Image', fontsize=20)\n",
    "axes[1,1].imshow(pytorch_out[0][0],vmin=vmin, vmax=vmax, origin='lower')\n",
    "axes[1,1].set_title('Pyotrch Denoised Image', fontsize=20)\n",
    "axes[1,2].imshow(samp[0][0][1000:1200,1000:1200], vmin=vmin, vmax=vmax,origin='lower')\n",
    "axes[1,2].set_title('Noisy Image', fontsize=20)\n",
    "axes[1,3].imshow(pytorch_out[0][0][1000:1200,1000:1200], vmin=vmin, vmax=vmax,origin='lower')\n",
    "axes[1,3].set_title('Pytorch Denoised Image', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e51bea-6a61-4b0d-9ee7-fcf6863f0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pytorch_out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e498811-f7ec-4153-93e5-8b9adbf82562",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(full_c1, resid_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d7911-9b41-43a8-960a-52e1ccf9af7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
