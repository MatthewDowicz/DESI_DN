{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3247419b-0c93-4514-8fdb-f24eb5598741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu, np_BatchNorm2d\n",
    "\n",
    "import time \n",
    "from collections import OrderedDict\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb22a33-0f69-4d54-8a7c-2a0a2977872f",
   "metadata": {},
   "source": [
    "**The goal of this notebook is to see how we can optimize the code for `np.Conv2d`.** \n",
    "\n",
    "**`get_indices` work:**\n",
    "\n",
    "We know we can increase the speed of `get_indices` because we just have to call it three times and then save the results and just load them in when needed. That way it doesn't have to be run every single time and take up ~4 seconds (when in the middle of the model).\n",
    "\n",
    "- This is possible because `get_indices` is just getting the correct indices for the 2d array indexing used to convert our multi-dimensional image and weight objects into large 2d arrays to allow for matrix matrix multiplication.\n",
    "\n",
    "- We have to call it three times for the 3 different shape transformations that take place within the model ie.\n",
    "    1. Transforming input image data into multiple filters ie. 1 channel -> 64 channels\n",
    "    2. Transforming input data into same size ie. 64 channels -> 64 channels\n",
    "    3. Transforming input data into original size ie. 64 channels -> 1 channel\n",
    "- Doing it this way we save ~ 75 seconds ie. 8.5X faster than current implementation of calling `get_indices` every time we call `np.Conv2d`\n",
    "\n",
    "**`im2col` work:**\n",
    "\n",
    "We know the bottleneck in `im2col` is from the array slicing we do to convert our image to columns. We also know the next line with the `np.concatenate` is fairly fast (~ 1 second)\n",
    "\n",
    "- The bottleneck in the array slicing is potentially due to the hardware running into latency-bound computations\n",
    "    - Meaning due to the conversion of images to columns the data is no longer row-major (the default way data is stored in Python) and thus there must be more calls by the GPU to fetch the requested data\n",
    "    - This could be fixed by transposing the data array (ie. the data is now back into the hardware friendly row-major form) and this would allow for the GPU to fetch the requested data as well as take advantage of the cache-ing that hardware does (ie. tries to antipicate what data will be loaded next, by not just loading the data you requested, but loading in the left/right neighbors of the data requested)\n",
    "    - [This](https://stackoverflow.com/questions/67826377/efficient-numpy-slicing-of-a-large-3d-array) stack overeflow page explains it better with some example code\n",
    "    \n",
    "- Another area to explore would be instead of doing normal array slicing using `np.take`. \n",
    "    - Haven't looked at it thoroughly, but from [this](https://stackoverflow.com/questions/62205777/speed-up-numpy-indexing-of-large-array) stackoverflow there does seem to be a speed-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be335bc-c65f-40db-ba66-07b2ddd4d072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "# name = '6k_model_wb_e800_lys20_58feat.pth'\n",
    "name = '2k_model_bs64_e800_ps50_Adam.pth'\n",
    "# weights = np.load(DATA / name)\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)\n",
    "\n",
    "samp = sample[0][0][1000:3000, 1000:3000]\n",
    "samp = samp.reshape((1, 1, 2000, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e80dd57-f96b-4c13-a328-729123fb8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    get_indices_start = time.perf_counter()\n",
    "\n",
    "    # Get input size\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Calculations for the output H and W dimensions.\n",
    "    height_out = ((height + (2*padding) - (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "    \n",
    "    \n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(kernel_size[0]), kernel_size[1])\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(height_out), width_out)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(kernel_size[1]), kernel_size[0])\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(width_out), height_out)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(input_channels), kernel_size[0] * kernel_size[1]).reshape(-1, 1)\n",
    "    \n",
    "    get_indices_end = time.perf_counter()\n",
    "    print('get_indices takes:', get_indices_end-get_indices_start, 'seconds')\n",
    "    \n",
    "    return i, j, d\n",
    "\n",
    "def im2col(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = input_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols\n",
    "\n",
    "def np_Conv2d(input_data, weights_dict, prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575ee191-f69e-4169-bac0-d8c67a561265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.09291511698393151 seconds\n",
      "i shape = (9, 4000000)\n",
      "j shape = (9, 4000000)\n",
      "d shape = (9, 1)\n",
      "\n",
      "get_indices takes: 0.09246833799988963 seconds\n",
      "Im2col takes: 0.27658326100208797 seconds\n",
      "\n",
      "get_indices takes: 0.09049165199394338 seconds\n",
      "Im2col takes: 0.26960439400863834 seconds\n",
      "Conv takes: 0.5580244529992342 seconds\n"
     ]
    }
   ],
   "source": [
    "# First layer convolution\n",
    "\n",
    "# Note: The time for im2col is the time for im2col as well as get_indices\n",
    "# due to im2col calling get_indices\n",
    "\n",
    "# Note: This is the same for conv, except it calls im2col, which then calls\n",
    "# get_indices, thus you need to subtract the time of the previous function\n",
    "# against the current function to get the correct time\n",
    "i, j, d = get_indices(input_data=samp, weights_dict=weights, prefix='layers.0.0.');\n",
    "print('i shape =', i.shape)\n",
    "print('j shape =',j.shape)\n",
    "print('d shape =',d.shape)\n",
    "print()\n",
    "im2col(input_data=samp, weights_dict=weights, prefix='layers.0.0.');\n",
    "print()\n",
    "out = np_Conv2d(input_data=samp, weights_dict=weights, prefix='layers.0.0.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408930ce-60ec-4908-a8ae-cfe14dc96c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 4.693190552003216 seconds\n",
      "\n",
      "get_indices takes: 4.649339191004401 seconds\n",
      "Im2col takes: 16.331543762004003 seconds\n",
      "\n",
      "get_indices takes: 4.535428042989224 seconds\n",
      "Im2col takes: 16.293198670988204 seconds\n",
      "Conv takes: 18.492726391006727 seconds\n"
     ]
    }
   ],
   "source": [
    "# Second layer convolution\n",
    "get_indices(input_data=out, weights_dict=weights, prefix='layers.1.0.');\n",
    "print()\n",
    "im2col(input_data=out, weights_dict=weights, prefix='layers.1.0.');\n",
    "print()\n",
    "out2 = np_Conv2d(input_data=out, weights_dict=weights, prefix='layers.1.0.');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba347890-fecd-46d6-a34f-8a11e6f37e47",
   "metadata": {},
   "source": [
    "# 0. Experimenting on how to optimize the bottleneck found in im2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c5d6b6b-6f60-45dc-9c62-d5e59f3390f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def im2col_testing(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "#     \"\"\"\n",
    "#         Transforms our input image into a matrix.\n",
    "\n",
    "#         Parameters:\n",
    "#         - X: input image.\n",
    "#         - HF: filter height.\n",
    "#         - WF: filter width.\n",
    "#         - stride: stride value.\n",
    "#         - pad: padding value.\n",
    "\n",
    "#         Returns:\n",
    "#         -cols: output matrix.\n",
    "#     \"\"\"\n",
    "#     im2col_start = time.perf_counter()\n",
    "\n",
    "#     if len(input_data.shape) == 4:\n",
    "    \n",
    "#         batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "#     elif len(input_data.shape) == 3:\n",
    "        \n",
    "#         input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "#         batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "    \n",
    "#     # Padding\n",
    "#     input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "#     i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    \n",
    "#     array_indexing_start = time.perf_counter()\n",
    "#     # Multi-dimensional arrays indexing.\n",
    "#     array_slicing_start = time.perf_counter()\n",
    "#     iT, jT, dT = i.T, j.T, d.T\n",
    "#     transposed_input_padded = input_padded.T\n",
    "#     cols = transposed_input_padded[:, iT, jT, dT].T\n",
    "#     array_slicing_end = time.perf_counter()\n",
    "#     print('Im2col array slicing takes:', array_slicing_end-array_slicing_start, 'seconds')\n",
    "#     print()    \n",
    "#     cols = np.concatenate(cols, axis=-1)\n",
    "    \n",
    "#     im2col_end = time.perf_counter()\n",
    "#     print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "#     return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d2a583-e07d-463e-8924-6e5828ceb1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 4.696664950984996 seconds\n",
      "Total Im2col takes: 16.13210764498217 seconds\n"
     ]
    }
   ],
   "source": [
    "input_data=out\n",
    "weights_dict = weights\n",
    "prefix = 'layers.1.0.'\n",
    "padding=1\n",
    "stride=1\n",
    "\n",
    "im2col_start = time.perf_counter()\n",
    "if len(input_data.shape) == 4:\n",
    "    \n",
    "    batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "elif len(input_data.shape) == 3:\n",
    "\n",
    "    input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "    batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "# Padding\n",
    "input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "# Multi-dimensional arrays indexing.\n",
    "cols = input_padded[:, d, i, j]\n",
    "cols = np.concatenate(cols, axis=-1)\n",
    "\n",
    "im2col_end = time.perf_counter()\n",
    "print('Total Im2col takes:', im2col_end-im2col_start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2799dfd3-d23e-4b16-9239-7e498003b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.ravel_multi_index(([0], d, i, j), input_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2004eea-8da3-4811-ad45-9ed1785c2369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 4000000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91cc9c14-c396-47ac-87f3-aee0bf53f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2 = input_padded.reshape(-1)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2a07ab4-2188-44db-9179-dade87451b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(cols2, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f41079-b570-42d8-8095-1085f2e69e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i shape = (576, 4000000)\n",
      "j shape = (576, 4000000)\n",
      "d shape = (576, 1)\n",
      "input_padded shape = (1, 64, 2002, 2002)\n",
      "cols shape before concatenation = (1, 576, 4000000)\n",
      "cols shape = (576, 4000000)\n"
     ]
    }
   ],
   "source": [
    "print('i shape =', i.shape)\n",
    "print('j shape =',j.shape)\n",
    "print('d shape =',d.shape)\n",
    "print('input_padded shape =',input_padded.shape)\n",
    "print('cols shape before concatenation =', input_padded[:, d, i, j].shape)\n",
    "print('cols shape =', cols.shape) # cols = np.concatenate(cols, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c88cbe-9d82-48ec-99be-0a1a50924f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('d[:20] =', d[:20])\n",
    "# print('i[:10, :40] =', i[:10, :40])\n",
    "# i[:10, :20]\n",
    "i[:10, 33998:34002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85082933-6445-4103-9f5a-04c4e2f9b77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1999,    0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[0, 1999:2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cea10413-d6f3-490f-a73d-29a660d571df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "\n",
    "# row i\n",
    "row_i = i\n",
    "\n",
    "# column j \n",
    "col_j = j\n",
    "\n",
    "# channel delimiter d\n",
    "delim_d = d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02652617-44a0-435c-a16a-4a857e09c7dd",
   "metadata": {},
   "source": [
    "Trying the `.ravel()` option provided in this [SO thread](https://stackoverflow.com/questions/14386822/fast-numpy-fancy-indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d6b5b5f-1c7f-40b6-bc06-02d323985baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3218, 6)\n",
      "(2000, 4)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(3218, 6)\n",
    "print(a.shape)\n",
    "\n",
    "rows = np.random.randint(a.shape[0], size=2000)\n",
    "cols = np.array([1,3,4,5])\n",
    "\n",
    "result2 = (a.ravel()[(cols + (rows * a.shape[1]).reshape((-1,1))).ravel()]).reshape(rows.size, cols.size)\n",
    "print(result2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d1da27c-e4c6-4bb5-97e3-77579ff44632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a contiguous flattened array.\n",
       "\n",
       "A 1-D array, containing the elements of the input, is returned.  A copy is\n",
       "made only if needed.\n",
       "\n",
       "As of NumPy 1.10, the returned array will have the same type as the input\n",
       "array. (for example, a masked array will be returned for a masked array\n",
       "input)\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a : array_like\n",
       "    Input array.  The elements in `a` are read in the order specified by\n",
       "    `order`, and packed as a 1-D array.\n",
       "order : {'C','F', 'A', 'K'}, optional\n",
       "\n",
       "    The elements of `a` are read using this index order. 'C' means\n",
       "    to index the elements in row-major, C-style order,\n",
       "    with the last axis index changing fastest, back to the first\n",
       "    axis index changing slowest.  'F' means to index the elements\n",
       "    in column-major, Fortran-style order, with the\n",
       "    first index changing fastest, and the last index changing\n",
       "    slowest. Note that the 'C' and 'F' options take no account of\n",
       "    the memory layout of the underlying array, and only refer to\n",
       "    the order of axis indexing.  'A' means to read the elements in\n",
       "    Fortran-like index order if `a` is Fortran *contiguous* in\n",
       "    memory, C-like order otherwise.  'K' means to read the\n",
       "    elements in the order they occur in memory, except for\n",
       "    reversing the data when strides are negative.  By default, 'C'\n",
       "    index order is used.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "y : array_like\n",
       "    y is an array of the same subtype as `a`, with shape ``(a.size,)``.\n",
       "    Note that matrices are special cased for backward compatibility, if `a`\n",
       "    is a matrix, then y is a 1-D ndarray.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ndarray.flat : 1-D iterator over an array.\n",
       "ndarray.flatten : 1-D array copy of the elements of an array\n",
       "                  in row-major order.\n",
       "ndarray.reshape : Change the shape of an array without changing its data.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "In row-major, C-style order, in two dimensions, the row index\n",
       "varies the slowest, and the column index the quickest.  This can\n",
       "be generalized to multiple dimensions, where row-major order\n",
       "implies that the index along the first axis varies slowest, and\n",
       "the index along the last quickest.  The opposite holds for\n",
       "column-major, Fortran-style index ordering.\n",
       "\n",
       "When a view is desired in as many cases as possible, ``arr.reshape(-1)``\n",
       "may be preferable.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "It is equivalent to ``reshape(-1, order=order)``.\n",
       "\n",
       ">>> x = np.array([[1, 2, 3], [4, 5, 6]])\n",
       ">>> np.ravel(x)\n",
       "array([1, 2, 3, 4, 5, 6])\n",
       "\n",
       ">>> x.reshape(-1)\n",
       "array([1, 2, 3, 4, 5, 6])\n",
       "\n",
       ">>> np.ravel(x, order='F')\n",
       "array([1, 4, 2, 5, 3, 6])\n",
       "\n",
       "When ``order`` is 'A', it will preserve the array's 'C' or 'F' ordering:\n",
       "\n",
       ">>> np.ravel(x.T)\n",
       "array([1, 4, 2, 5, 3, 6])\n",
       ">>> np.ravel(x.T, order='A')\n",
       "array([1, 2, 3, 4, 5, 6])\n",
       "\n",
       "When ``order`` is 'K', it will preserve orderings that are neither 'C'\n",
       "nor 'F', but won't reverse axes:\n",
       "\n",
       ">>> a = np.arange(3)[::-1]; a\n",
       "array([2, 1, 0])\n",
       ">>> a.ravel(order='C')\n",
       "array([2, 1, 0])\n",
       ">>> a.ravel(order='K')\n",
       "array([2, 1, 0])\n",
       "\n",
       ">>> a = np.arange(12).reshape(2,3,2).swapaxes(1,2); a\n",
       "array([[[ 0,  2,  4],\n",
       "        [ 1,  3,  5]],\n",
       "       [[ 6,  8, 10],\n",
       "        [ 7,  9, 11]]])\n",
       ">>> a.ravel(order='C')\n",
       "array([ 0,  2,  4,  1,  3,  5,  6,  8, 10,  7,  9, 11])\n",
       ">>> a.ravel(order='K')\n",
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
       "\u001b[0;31mFile:\u001b[0m      /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/core/fromnumeric.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.ravel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a6613-2e9d-466f-927e-92e7d64f0e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9712311d-fc15-49f4-a38f-fe2fcc2ce007",
   "metadata": {},
   "source": [
    "Trying the `np.ix_` method from the same [SO thread](https://stackoverflow.com/questions/14386822/fast-numpy-fancy-indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8814b9f-def0-4f94-bc80-fba683e7f046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Construct an open mesh from multiple sequences.\n",
       "\n",
       "This function takes N 1-D sequences and returns N outputs with N\n",
       "dimensions each, such that the shape is 1 in all but one dimension\n",
       "and the dimension with the non-unit shape value cycles through all\n",
       "N dimensions.\n",
       "\n",
       "Using `ix_` one can quickly construct index arrays that will index\n",
       "the cross product. ``a[np.ix_([1,3],[2,5])]`` returns the array\n",
       "``[[a[1,2] a[1,5]], [a[3,2] a[3,5]]]``.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "args : 1-D sequences\n",
       "    Each sequence should be of integer or boolean type.\n",
       "    Boolean sequences will be interpreted as boolean masks for the\n",
       "    corresponding dimension (equivalent to passing in\n",
       "    ``np.nonzero(boolean_sequence)``).\n",
       "\n",
       "Returns\n",
       "-------\n",
       "out : tuple of ndarrays\n",
       "    N arrays with N dimensions each, with N the number of input\n",
       "    sequences. Together these arrays form an open mesh.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ogrid, mgrid, meshgrid\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = np.arange(10).reshape(2, 5)\n",
       ">>> a\n",
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])\n",
       ">>> ixgrid = np.ix_([0, 1], [2, 4])\n",
       ">>> ixgrid\n",
       "(array([[0],\n",
       "       [1]]), array([[2, 4]]))\n",
       ">>> ixgrid[0].shape, ixgrid[1].shape\n",
       "((2, 1), (1, 2))\n",
       ">>> a[ixgrid]\n",
       "array([[2, 4],\n",
       "       [7, 9]])\n",
       "\n",
       ">>> ixgrid = np.ix_([True, True], [2, 4])\n",
       ">>> a[ixgrid]\n",
       "array([[2, 4],\n",
       "       [7, 9]])\n",
       ">>> ixgrid = np.ix_([True, True], [False, False, True, False, True])\n",
       ">>> a[ixgrid]\n",
       "array([[2, 4],\n",
       "       [7, 9]])\n",
       "\u001b[0;31mFile:\u001b[0m      /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/lib/index_tricks.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.ix_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5250c881-2743-4068-8349-c1fa3f21ce00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i shape = (576, 4000000)\n",
      "j shape = (576, 4000000)\n",
      "d shape = (576, 1)\n",
      "input_padded shape = (1, 64, 2002, 2002)\n",
      "cols shape before concatenation = (1, 576, 4000000)\n",
      "cols shape = (6,)\n"
     ]
    }
   ],
   "source": [
    "print('i shape =', i.shape)\n",
    "print('j shape =',j.shape)\n",
    "print('d shape =',d.shape)\n",
    "print('input_padded shape =',input_padded.shape)\n",
    "print('cols shape before concatenation =', input_padded[:, d, i, j].shape)\n",
    "print('cols shape =', cols.shape) # cols = np.concatenate(cols, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50735ad9-38df-4940-b5f7-1bef0804025d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ... 1999 1999 1999]\n",
      " [   0    0    0 ... 1999 1999 1999]\n",
      " [   0    0    0 ... 1999 1999 1999]\n",
      " ...\n",
      " [   2    2    2 ... 2001 2001 2001]\n",
      " [   2    2    2 ... 2001 2001 2001]\n",
      " [   0    0    0 ... 1999 1999 1999]]\n"
     ]
    }
   ],
   "source": [
    "print(i[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a5e8916-aa99-4428-9a1b-6a0dcaefaaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(1, 64, 2002, 2002)\n",
    "rows = np.random.randint(a.shape[0], size=2000)\n",
    "cols = np.random.randint(a.shape[1], size=6)\n",
    "\n",
    "ix_ = np.ix_(rows, cols)\n",
    "result1 = a[ix_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "865f0b92-4142-48c3-95dc-ea33b4e118ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "472a8d82-826a-4672-b23b-19c08dd4bc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Construct an open mesh from multiple sequences.\n",
       "\n",
       "This function takes N 1-D sequences and returns N outputs with N\n",
       "dimensions each, such that the shape is 1 in all but one dimension\n",
       "and the dimension with the non-unit shape value cycles through all\n",
       "N dimensions.\n",
       "\n",
       "Using `ix_` one can quickly construct index arrays that will index\n",
       "the cross product. ``a[np.ix_([1,3],[2,5])]`` returns the array\n",
       "``[[a[1,2] a[1,5]], [a[3,2] a[3,5]]]``.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "args : 1-D sequences\n",
       "    Each sequence should be of integer or boolean type.\n",
       "    Boolean sequences will be interpreted as boolean masks for the\n",
       "    corresponding dimension (equivalent to passing in\n",
       "    ``np.nonzero(boolean_sequence)``).\n",
       "\n",
       "Returns\n",
       "-------\n",
       "out : tuple of ndarrays\n",
       "    N arrays with N dimensions each, with N the number of input\n",
       "    sequences. Together these arrays form an open mesh.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ogrid, mgrid, meshgrid\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = np.arange(10).reshape(2, 5)\n",
       ">>> a\n",
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])\n",
       ">>> ixgrid = np.ix_([0, 1], [2, 4])\n",
       ">>> ixgrid\n",
       "(array([[0],\n",
       "       [1]]), array([[2, 4]]))\n",
       ">>> ixgrid[0].shape, ixgrid[1].shape\n",
       "((2, 1), (1, 2))\n",
       ">>> a[ixgrid]\n",
       "array([[2, 4],\n",
       "       [7, 9]])\n",
       "\n",
       ">>> ixgrid = np.ix_([True, True], [2, 4])\n",
       ">>> a[ixgrid]\n",
       "array([[2, 4],\n",
       "       [7, 9]])\n",
       ">>> ixgrid = np.ix_([True, True], [False, False, True, False, True])\n",
       ">>> a[ixgrid]\n",
       "array([[2, 4],\n",
       "       [7, 9]])\n",
       "\u001b[0;31mFile:\u001b[0m      /global/common/software/nersc/shasta2105/pytorch/1.9.0/lib/python3.8/site-packages/numpy/lib/index_tricks.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.ix_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c505735-b9d1-4e4c-bb9c-7f1d61331903",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Experimenting with the `np.take` to see if it's faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d65add-5c61-4c93-b333-4b5b7206bc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 µs ± 2.37 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "169 µs ± 976 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "136 µs ± 2.18 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "m = [1, 7, 12, 40]\n",
    "r = np.arange(5000)\n",
    "r = np.delete(r, m, axis=0)\n",
    "\n",
    "x = np.random.rand(5000,5000,10)\n",
    "\n",
    "%timeit tmp = x[:,m,:]\n",
    "\n",
    "%timeit tmp = np.delete(x, r, axis=1)\n",
    "\n",
    "%timeit tmp = np.take(x, m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d78a55c6-9349-4135-acc7-92459b4240de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 4.249502338992897 seconds\n"
     ]
    }
   ],
   "source": [
    "input_data=out\n",
    "weights_dict = weights\n",
    "prefix = 'layers.1.0.'\n",
    "padding=1\n",
    "stride=1\n",
    "\n",
    "im2col_start = time.perf_counter()\n",
    "if len(input_data.shape) == 4:\n",
    "    \n",
    "    batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "elif len(input_data.shape) == 3:\n",
    "\n",
    "    input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "    batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "# Padding\n",
    "input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f0cd80-2d84-4648-9350-bbe68efc00fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i shape = (576, 4000000)\n",
      "j shape = (576, 4000000)\n",
      "d shape = (576, 1)\n",
      "input_padded shape = (1, 64, 2002, 2002)\n",
      "cols shape before concatenation = (1, 576, 4000000)\n",
      "cols shape = (576, 4000000)\n"
     ]
    }
   ],
   "source": [
    "print('i shape =', i.shape)\n",
    "print('j shape =',j.shape)\n",
    "print('d shape =',d.shape)\n",
    "print('input_padded shape =',input_padded.shape)\n",
    "print('cols shape before concatenation =', input_padded[:, d, i, j].shape)\n",
    "print('cols shape =', cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d3288e5-035e-42a1-8698-92e1086df185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 2002, 2002)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a6f52f9-5f96-48b9-8200-c80605ffea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice_start = time.perf_counter()\n",
    "# dcols = np.take(input_padded, d, axis=1)\n",
    "# icols = np.take(input_padded, i, axis=2)\n",
    "# jcols = np.take(input_padded, j, axis=3)\n",
    "\n",
    "# slice_end = time.perf_counter()\n",
    "# print('Slicing takes', slice_end-slice_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c39955-f4fa-4593-9988-272beed88458",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Experimenting with the transpose of the data array to see if its faster - **IT'S NOT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d361d-a1bb-4070-9def-0f375bb39cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b5139d6-6a93-4ccd-b3b1-79bd76e06a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 4.482630530001188 seconds\n",
      "Total Im2col takes: 15.671476784998958 seconds\n"
     ]
    }
   ],
   "source": [
    "input_data=out\n",
    "weights_dict = weights\n",
    "prefix = 'layers.1.0.'\n",
    "padding=1\n",
    "stride=1\n",
    "\n",
    "im2col_start = time.perf_counter()\n",
    "if len(input_data.shape) == 4:\n",
    "    \n",
    "    batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "elif len(input_data.shape) == 3:\n",
    "\n",
    "    input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "    batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "# Padding\n",
    "input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "# Multi-dimensional arrays indexing.\n",
    "input_padded = input_padded.T\n",
    "cols = input_padded[j, i, d, :].T\n",
    "cols = np.concatenate(cols, axis=-1)\n",
    "\n",
    "im2col_end = time.perf_counter()\n",
    "print('Total Im2col takes:', im2col_end-im2col_start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27e71f5-2808-450d-94c6-ba824324ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i shape = (576, 4000000)\n",
      "j shape = (576, 4000000)\n",
      "d shape = (576, 1)\n",
      "input_padded shape = (2002, 2002, 64, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 64 is out of bounds for axis 2 with size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_120822/2423358473.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'd shape ='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_padded shape ='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cols shape before concatenation ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cols shape ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 64 is out of bounds for axis 2 with size 64"
     ]
    }
   ],
   "source": [
    "print('i shape =', i.shape)\n",
    "print('j shape =',j.shape)\n",
    "print('d shape =',d.shape)\n",
    "print('input_padded shape =',input_padded.shape)\n",
    "print('cols shape before concatenation =', input_padded[:, d, i, j].shape)\n",
    "print('cols shape =', cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8c5aa-5b3f-4345-a032-f821dff5ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf94a4-e630-4496-9867-c8c3f81244e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2col_testing(input_data=out, weights_dict=weights, prefix='layers.1.0.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fdba80-0415-4e37-830e-555ba03c6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = np_Conv2d(input_data=out2, weights_dict=weights, prefix='layers.18.0.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
