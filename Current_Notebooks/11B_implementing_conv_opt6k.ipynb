{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db877ef9-5527-4730-90c2-0a5d57f15739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu, np_BatchNorm2d\n",
    "\n",
    "import time \n",
    "from collections import OrderedDict\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe201d-0c0a-46c1-ba0a-ce9b47d68b45",
   "metadata": {},
   "source": [
    "**The goal of this notebook is to implement the optimization we found in notebook `11B_testing_im2col_times` where we call `get_indices` 3 times and then saving those 3 indice matrices. Then we use `np.ravel_multi_index()` in `im2col`.**\n",
    "\n",
    "**NOTE: This is for a full 6k by 6k image.**\n",
    "\n",
    "This notebook is creating the respective index matrices, so that it can be used in another notebook which just uses the already created matrices, instead of creating their own every call. This is supposedly to save a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d74917-a526-4ddf-90f0-eb5768878f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "# Loading data & weights dictionary\n",
    "\n",
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "# name = '6k_model_wb_e800_lys20_58feat.pth'\n",
    "name = '6k_model_wb_e800.pth'\n",
    "# weights = np.load(DATA / name)\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)\n",
    "\n",
    "samp = sample[0][0]\n",
    "samp = samp.reshape((1, 1, 6000, 6000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84166dd5-c6a2-40f3-8eb7-abbf77f9cb89",
   "metadata": {},
   "source": [
    "Need to call this three times:\n",
    "1. First for the untransformed input. (1 channel -> 64 channels)\n",
    "2. For the middle layers (64 channels -> 64 channels)\n",
    "3. For the last layer (64 channels -> 1 channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49daf5b2-1ea5-4e0f-ad39-65c2a3e3e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "\n",
    "    # Get input size\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 6000 , 6000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Calculations for the output H and W dimensions.\n",
    "    height_out = ((height + (2*padding) - (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "    \n",
    "    \n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(kernel_size[0]), kernel_size[1])\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(height_out), width_out)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(kernel_size[1]), kernel_size[0])\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(width_out), height_out)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(input_channels), kernel_size[0] * kernel_size[1]).reshape(-1, 1)\n",
    "    \n",
    "    \n",
    "    return i, j, d\n",
    "\n",
    "\n",
    "def im2col(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 6000 , 6000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = input_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    \n",
    "    \n",
    "    return cols\n",
    "\n",
    "\n",
    "def np_Conv2d(input_data, weights_dict, prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 6000 , 6000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out\n",
    "\n",
    "\n",
    "def im2col_save(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 6000 , 6000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    idx = np.ravel_multi_index(([0], d, i, j), input_padded.shape)\n",
    "    cols2 = input_padded.reshape(-1)[idx]  \n",
    "\n",
    "    return cols2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3948c8d8-398e-4a18-b675-561ac49e1da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv takes: 4.894506996031851 seconds\n"
     ]
    }
   ],
   "source": [
    "# DnCNN Model\n",
    "\n",
    "# 1st layer block\n",
    "idx_start = im2col_save(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "conv_out0 = np_Conv2d(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "out0 = relu(conv_out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91190cc1-5c4a-43c7-a18f-b9ebea66f1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36000000.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6000*6000 / 2000*2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffcfe08-330b-4685-9b41-1e3303eb7a7b",
   "metadata": {},
   "source": [
    "# **Code is to see how long the first layer of the convolutional layer takes with the saved/stored index arrays.**\n",
    "\n",
    "**This is for comparison with the 2k by 2k first layer convolution, which is found in notebook `12_Testing_Opt_Conv2d.ipynb` and takes 0.413180093979463 seconds**\n",
    "- First layer convolution of 6k by 6k takes 2.392761211958714 seconds\n",
    "    - That is 6 times **longer** for a 9 **larger** image \n",
    "- If the extrapolation can be allowed then the intermediate layers of the 6k by 6k model would also be 6 times longer than the intermediate convolutions of the 2k by 2k model\n",
    "    - Ie. going from ~5 seconds for 2k by 2k to ~ 30 seconds for 6k by 6k\n",
    "    - This would be 30 seconds for 18 convolution layers ie. 540 seconds == 1 hour\n",
    "- **Total 6k by 6k model would take **~ $1 \\pm 0.1$ hrs****\n",
    "    - Compared to the 37 minutes of 21 calls needed by the afterburner of the 2k by 2k model\n",
    "        - **~13 hours of computation**\n",
    "\n",
    "**Intermediate Convolutions of the 2k by 2k model with saved index arrays takes, ~5.155830833973596 seconds**\n",
    "\n",
    "\n",
    "**In Summary:**\n",
    "- 2k by 2k model is faster even with the 21 calls by almost half the time. Need to tell David & also recheck these times again to make sure they're correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0e201b-9a04-4915-a453-fbcac98d3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col2(input_data, im2col_mat, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    idx = im2col_mat\n",
    "    cols2 = input_padded.reshape(-1)[idx]  \n",
    "    \n",
    "    return cols2\n",
    "\n",
    "\n",
    "def np_Conv2d2(input_data, weights_dict, prefix, im2col_mat):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    \n",
    "    X_col = im2col_mat\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "553b6226-83bf-4278-bd21-9f488829df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv takes: 2.392761211958714 seconds\n"
     ]
    }
   ],
   "source": [
    "conv_out0_2 = np_Conv2d2(input_data=samp, weights_dict=weights, prefix='layers.0.0.', im2col_mat=idx_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c931d-f912-4267-a1e1-579080901128",
   "metadata": {},
   "source": [
    "Compare values of normal conv versus saved indice conv to check that they are in fact given similar values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b9ed7bf-cc7e-4d55-b528-9eadb74ae3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(conv_out0, conv_out0_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1184a-dab9-483c-8e77-b2170ceba5b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Code below is creating the model to use the outputs to create the multi-dimensional arrays of indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086400d-2e2e-40e3-a133-9672207ad72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2nd layer block\n",
    "idx_mid = im2col_save(input_data=out0, weights_dict=weights, prefix='layers.1.0.')\n",
    "# conv_out1 = np_Conv2d(input_data=out0, weights_dict=weights, prefix='layers.1.0.')\n",
    "# batch_out1 = np_BatchNorm2d(x=conv_out1, weights_dict=weights, prefix='layers.1.1.')\n",
    "# out1 = relu(batch_out1)\n",
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7573133-b30f-4f2f-bcc9-c2780b518894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer block\n",
    "conv_out2 = np_Conv2d(input_data=out1, weights_dict=weights, prefix='layers.2.0.')\n",
    "batch_out2 = np_BatchNorm2d(x=conv_out2, weights_dict=weights, prefix='layers.2.1.')\n",
    "out2 = relu(batch_out2)\n",
    "print(3)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out3 = np_Conv2d(input_data=out2, weights_dict=weights, prefix='layers.3.0.')\n",
    "batch_out3= np_BatchNorm2d(x=conv_out3, weights_dict=weights, prefix='layers.3.1.')\n",
    "out3 = relu(batch_out3)\n",
    "print(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da590be-5b1a-4415-906d-76ff8e8c64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer block\n",
    "conv_out4 = np_Conv2d(input_data=out3, weights_dict=weights, prefix='layers.4.0.')\n",
    "batch_out4 = np_BatchNorm2d(x=conv_out4, weights_dict=weights, prefix='layers.4.1.')\n",
    "out4 = relu(batch_out4)\n",
    "print(5)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out5 = np_Conv2d(input_data=out4, weights_dict=weights, prefix='layers.5.0.')\n",
    "batch_out5 = np_BatchNorm2d(x=conv_out5, weights_dict=weights, prefix='layers.5.1.')\n",
    "out5 = relu(batch_out5)\n",
    "print(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3aafd-2ba7-453e-8362-7abca48d79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer block\n",
    "conv_out6 = np_Conv2d(input_data=out5, weights_dict=weights, prefix='layers.6.0.')\n",
    "batch_out6 = np_BatchNorm2d(x=conv_out6, weights_dict=weights, prefix='layers.6.1.')\n",
    "out6 = relu(batch_out6)\n",
    "print(7)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out7 = np_Conv2d(input_data=out6, weights_dict=weights, prefix='layers.7.0.')\n",
    "batch_out7 = np_BatchNorm2d(x=conv_out7, weights_dict=weights, prefix='layers.7.1.')\n",
    "out7 = relu(batch_out7)\n",
    "print(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3814f05-f807-4a50-bf73-d963cc711d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer block\n",
    "conv_out8 = np_Conv2d(input_data=out7, weights_dict=weights, prefix='layers.8.0.')\n",
    "batch_out8 = np_BatchNorm2d(x=conv_out8, weights_dict=weights, prefix='layers.8.1.')\n",
    "out8 = relu(batch_out8)\n",
    "print(9)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out9 = np_Conv2d(input_data=out8, weights_dict=weights, prefix='layers.9.0.')\n",
    "batch_out9 = np_BatchNorm2d(x=conv_out9, weights_dict=weights, prefix='layers.9.1.')\n",
    "out9 = relu(batch_out9)\n",
    "print(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88b538-7337-41fe-b19a-8169fc84a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer block\n",
    "conv_out10 = np_Conv2d(input_data=out9, weights_dict=weights, prefix='layers.10.0.')\n",
    "batch_out10 = np_BatchNorm2d(x=conv_out10, weights_dict=weights, prefix='layers.10.1.')\n",
    "out10 = relu(batch_out10)\n",
    "print(11)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out11 = np_Conv2d(input_data=out10, weights_dict=weights, prefix='layers.11.0.')\n",
    "batch_out11 = np_BatchNorm2d(x=conv_out11, weights_dict=weights, prefix='layers.11.1.')\n",
    "out11 = relu(batch_out11)\n",
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0476a437-8856-43e1-9bfa-879ed019f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer block\n",
    "conv_out12 = np_Conv2d(input_data=out11, weights_dict=weights, prefix='layers.12.0.')\n",
    "batch_out12 = np_BatchNorm2d(x=conv_out12, weights_dict=weights, prefix='layers.12.1.')\n",
    "out12 = relu(batch_out12)\n",
    "print(13)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out13 = np_Conv2d(input_data=out12, weights_dict=weights, prefix='layers.13.0.')\n",
    "batch_out13 = np_BatchNorm2d(x=conv_out13, weights_dict=weights, prefix='layers.13.1.')\n",
    "out13 = relu(batch_out13)\n",
    "print(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680b2f5-884c-4843-9096-c3e3f6b28c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer block\n",
    "conv_out14 = np_Conv2d(input_data=out13, weights_dict=weights, prefix='layers.14.0.')\n",
    "batch_out14 = np_BatchNorm2d(x=conv_out14, weights_dict=weights, prefix='layers.14.1.')\n",
    "out14 = relu(batch_out14)\n",
    "print(15)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out15 = np_Conv2d(input_data=out14, weights_dict=weights, prefix='layers.15.0.')\n",
    "batch_out15 = np_BatchNorm2d(x=conv_out15, weights_dict=weights, prefix='layers.15.1.')\n",
    "out15 = relu(batch_out15)\n",
    "print(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43879126-d67e-4ff0-a4f0-15ab75d92c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer block\n",
    "conv_out16 = np_Conv2d(input_data=out15, weights_dict=weights, prefix='layers.16.0.')\n",
    "batch_out16 = np_BatchNorm2d(x=conv_out16, weights_dict=weights, prefix='layers.16.1.')\n",
    "out16 = relu(batch_out16)\n",
    "print(17)\n",
    "\n",
    "# 2nd layer block\n",
    "conv_out17 = np_Conv2d(input_data=out16, weights_dict=weights, prefix='layers.17.0.')\n",
    "batch_out17 = np_BatchNorm2d(x=conv_out17, weights_dict=weights, prefix='layers.17.1.')\n",
    "out17 = relu(batch_out17)\n",
    "print(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e9462-58c1-47f1-ac38-0ffb8ea0d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd layer block\n",
    "conv_out18 = np_Conv2d(input_data=out17, weights_dict=weights, prefix='layers.18.0.')\n",
    "batch_out18 = np_BatchNorm2d(x=conv_out18, weights_dict=weights, prefix='layers.18.1.')\n",
    "out18 = relu(batch_out18)\n",
    "print(19)\n",
    "\n",
    "# Last layer\n",
    "idx_last = im2col_save(input_data=out18, weights_dict=weights, prefix='layers.19.')\n",
    "conv_out19 = np_Conv2d(input_data=out18, weights_dict=weights, prefix='layers.19.')\n",
    "print(20)\n",
    "\n",
    "resid_img = samp - conv_out19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3880f6-87b9-4157-ae06-3f8a73b0f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2col_layer_dict = {'start': idx_start, 'mid':idx_mid, 'last': idx_last}\n",
    "\n",
    "sl.NERSC_save(name='im2col_layer_dict_6k.pkl', data=im2col_layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84619909-f72d-4374-8613-7bc2ccf620a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2col_mat = sl.NERSC_load(name='im2col_layer_dict_6k.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
