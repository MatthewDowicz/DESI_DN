{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970379a9-6168-4b9c-89fe-beb140dd83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu\n",
    "\n",
    "import time \n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d2affd-4509-4c06-91cb-be2a16b9b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "# name = '6k_model_wb_e800_lys20_58feat.pth'\n",
    "name = '2k_model_bs64_e800_ps50_Adam.pth'\n",
    "\n",
    "# weights = np.load(DATA / name)\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e230c5c-4d8b-4e68-88a8-63621d5f0898",
   "metadata": {},
   "source": [
    "**HOLY SHIT THE IM2COL CONVULTION GIVES THE SAME OUTPUT AS PYTORCH WTF**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730649b-3e67-47ed-b4f2-f755a98857ab",
   "metadata": {},
   "source": [
    "# **Testing the `im2col` MATLAB function. Want to see if it's faster and then see if the results are any better...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3afc16-98b3-4a18-a10d-7294463e0f85",
   "metadata": {},
   "source": [
    "Might be interesting to look at the [numpy-ml package](https://github.com/ddbourgin/numpy-ml/blob/master/numpy_ml/neural_nets/utils/utils.py) to see how they create a 2D Convolution layer.\n",
    "\n",
    "- They take inspiration from Andrej Karpathy's `im2col.py` file which can be found in these [slides here](http://cs231n.stanford.edu/slides/2016/winter1516_lecture11.pdf). \n",
    "\n",
    "- An article that I believe talks about the speed of `im2col.py` is [linked here](https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/). Need to read.\n",
    "\n",
    "- Lastly, there's a nice package that implements convolutions in a slow (ie. nested for loops) and a fast way (ie. uses im2col idea). Seems like it's fast? That's linked [here](https://github.com/3outeille/CNNumpy/blob/master/src/slow/layers.py)\n",
    "    - [Blog post](https://hackmd.io/@machine-learning/blog-post-cnnumpy-slow) discussing the `slow` version \n",
    "    - [Blog post](https://hackmd.io/@machine-learning/blog-post-cnnumpy-fast) discussing the `fast` version that uses im2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f18773-2fee-4e62-b57d-edd9fcc78f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = sample[0][0][1000:3000, 1000:3000]\n",
    "samp = samp.reshape((1, 1, 2000, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86e97fa-703a-4ca1-ad0a-1006d4ec25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(X_shape, HF, WF, stride, pad):\n",
    "    \"\"\"\n",
    "        Returns index matrices in order to transform our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -X_shape: Input image shape.\n",
    "        -HF: filter height.\n",
    "        -WF: filter width.\n",
    "        -stride: stride value.\n",
    "        -pad: padding value.\n",
    "\n",
    "        Returns:\n",
    "        -i: matrix of index i.\n",
    "        -j: matrix of index j.\n",
    "        -d: matrix of index d. \n",
    "            (Use to mark delimitation for each channel\n",
    "            during multi-dimensional arrays indexing).\n",
    "    \"\"\"\n",
    "    # get input size\n",
    "    m, n_C, n_H, n_W = X_shape\n",
    "\n",
    "    # get output size\n",
    "    out_h = int((n_H + 2 * pad - HF) / stride) + 1\n",
    "    out_w = int((n_W + 2 * pad - WF) / stride) + 1\n",
    "  \n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(HF), WF)\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, n_C)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(out_h), out_w)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "\n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(WF), HF)\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, n_C)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(out_w), out_h)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "\n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(n_C), HF * WF).reshape(-1, 1)\n",
    "\n",
    "    return i, j, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897b1fed-b91c-4a1f-8d4d-f33e735a4397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i,j,d = get_indices(X_shape=sample[:1].shape, HF=3, WF=3, stride=1, pad=1)\n",
    "i,j,d = get_indices(X_shape=samp.shape, HF=3, WF=3, stride=1, pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb011cee-3416-4398-80a4-1f787ad89b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, HF, WF, stride, pad):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        - X: input image.\n",
    "        - HF: filter height.\n",
    "        - WF: filter width.\n",
    "        - stride: stride value.\n",
    "        - pad: padding value.\n",
    "\n",
    "        Returns:\n",
    "        -cols: output matrix.\n",
    "    \"\"\"\n",
    "    # Padding\n",
    "    X_padded = np.pad(X, ((0,0), (0,0), (pad, pad), (pad, pad)), mode='constant')\n",
    "    i, j, d = get_indices(X.shape, HF, WF, stride, pad)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = X_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29043ad6-7c7a-4dcd-8bd5-d10c4458eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = im2col(X=sample[:1], HF=3, WF=3, stride=1, pad=1)\n",
    "cols = im2col(X=samp, HF=3, WF=3, stride=1, pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c7471d1-6467-4b8c-a826-d52c8c61c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, weights_dict):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    m, C_in, H_in, W_in = X.shape\n",
    "\n",
    "    n_C = 64 # num_of_filters\n",
    "    H_out = int((H_in + 2 * 1 - 3)/ 1) + 1\n",
    "    W_out = int((W_in + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(X, 3, 3, 1, 1)\n",
    "    w_col = weights_dict['layers.0.0.weight'].detach().cpu().numpy().reshape((64, -1))\n",
    "    b_col = weights_dict['layers.0.0.bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, m)).reshape((m, n_C, H_out, W_out))\n",
    "    cache = X, X_col, w_col\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f44ce1-5c57-47a6-8538-45f92ac07294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_out = forward(X=sample[:1], weights_dict=weights)\n",
    "conv_out = forward(X=samp, weights_dict=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3539a2ed-430e-4acd-a8f6-5637a2a78427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 2000, 2000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e23ad1fd-fcac-4fa3-a189-d5dfdf684e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def np_Conv2d(input_data, weights_dict, prefix, stride=1, padding=\"same\", dilation=1):\n",
    "#     \"\"\"\n",
    "#     Numpy implementation of the PyTorch Conv2d layer that uses the \n",
    "#     learned PyTorch weights in the model.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     input_data: nd.array\n",
    "#         Input data of shape '(batch_size, in_channels, height, width)'\n",
    "#     weights_dict: OrderedDict\n",
    "#         weights_dict['weight']: torch.Tensor\n",
    "#             Weights tensor of shape '(out_channels, in_channels, kernel_size[0], kernel_size[1])'\n",
    "#         weights_dict['bias']: torch.Tensor\n",
    "#             Bias tensor of shape '(out_channels)'\n",
    "#     stride: int, optional\n",
    "#         The number of entries by which the filter is moved at each step.\n",
    "#         Defaults to 1\n",
    "#     padding: str, optional\n",
    "#         What padding strategy to use for this conv layer. Defaults to \"same\",\n",
    "#         which pads the layer such that the output has the same height and width\n",
    "#         as the input when the stride = 1. Specifically makes output of\n",
    "#         scipy.correlate2d have same shape as in1. An alternative option is \"valid\",\n",
    "#         which means no padding is done and the output has smaller dimensions\n",
    "#         than the input.\n",
    "#     dilation: int, optional\n",
    "#         Spacing between kernel elements.\n",
    "#         Defaults to 1.\n",
    "     \n",
    "        \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     output: nd.array\n",
    "#         Array output of the convolution step with shape\n",
    "#         `(batch_size, out_channels, out_height, out_width)`.\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Checking to see if a single sample or a batch of samples is given.\n",
    "#     # If batch take the batch_size, in_channels, H, and W\n",
    "#     # If single sample is given reshape so the values above can be calculated\n",
    "#     dimensions_start = time.perf_counter()\n",
    "#     if len(input_data.shape) == 4:\n",
    "    \n",
    "#         batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "#     elif len(input_data.shape) == 3:\n",
    "        \n",
    "#         input_data = input_data.reshape((1, 1, 6000 , 6000))\n",
    "#         batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "#     dimensions_end = time.perf_counter()\n",
    "#     print('Getting input dimensions takes', dimensions_end-dimensions_start, 'seconds')\n",
    "\n",
    "#     # Load the weights and biases needed for a convolution\n",
    "#     # then take off gpu memory, move to CPU memory,\n",
    "#     # and lastly transform to numpy\n",
    "#     loading_start = time.perf_counter()\n",
    "#     weight = weights_dict[str(prefix) + 'weight']\n",
    "#     weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "#     bias = weights_dict[str(prefix) + 'bias']\n",
    "#     bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "#     # Calculate the kernel size and output channels from\n",
    "#     # the loaded weights from above\n",
    "#     kernel_size = weight[0][0].shape\n",
    "#     output_channels = len(weight)\n",
    "#     loading_end = time.perf_counter()\n",
    "#     print('Loading the weights takes', loading_end-loading_start, 'seconds')\n",
    "    \n",
    "#     # Convert string padding into numerical padding\n",
    "#     # Using strings allow for one variable to account for padding & mode (see signal.correlated2d)\n",
    "#     out_dimensions_start = time.perf_counter()\n",
    "#     mode = padding\n",
    "#     if mode == \"same\":\n",
    "#         padding = 1\n",
    "#     elif mode == \"valid\":\n",
    "#         padding = 0\n",
    "    \n",
    "#     # Calculations for the output H and W dimensions\n",
    "#     height_out = ((height + (2*padding) - dilation * (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "#     height_out = int(height_out)\n",
    "#     width_out = ((width + (2*padding) - dilation * (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "#     width_out = int(width_out)\n",
    "\n",
    "#     # Create empty array of correct output dimensions\n",
    "#     # output = np.empty((batch_size, output_channels, height_out, width_out))\n",
    "#     output = np.zeros((batch_size, output_channels, height_out, width_out))\n",
    "#     out_dimensions_end = time.perf_counter()\n",
    "#     print('Getting output dimensions takes', out_dimensions_end-out_dimensions_start, 'seconds')\n",
    "    \n",
    "#     # Place the cross correlated elements into the newly created \n",
    "#     # empty array of correct output dimensions\n",
    "#     loop_start = time.perf_counter()\n",
    "    \n",
    "#     for i in range(batch_size):\n",
    "#         for j in range(output_channels):\n",
    "#             for k in range(input_channels):\n",
    "#                 # See PyTorch docs for this eqn: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "#                 output[i, j, :, :] = bias[j] + signal.fftconvolve(input_data[i][k], weight[j][k][::-1, ::-1], mode=mode)\n",
    "#                 # output[i, j, :, :] = bias[j] + signal.correlate2d(input_data[i][k], weight[j][k], mode=mode)\n",
    "\n",
    "#     loop_end = time.perf_counter()\n",
    "#     print('Convolution loop takes', loop_end-loop_start, 'seconds')\n",
    "    \n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "714cfe6c-1a21-4f9f-9201-ba1cadbafcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_conv_out = np_Conv2d(input_data=sample[0], weights_dict=weights, prefix='layers.0.0.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a701ee73-c056-40d2-82d4-26edd0c92026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.allclose(np_conv_out, conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d468a873-d45d-4276-9cdc-609de97616fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sample = sample[0]\n",
    "# test_sample = test_sample.reshape((1, 1, 6000 , 6000))\n",
    "\n",
    "test_sample = samp\n",
    "\n",
    "# test_sample = test_sample.reshape((1, 1, 6000 , 6000))\n",
    "test_sample = torch.as_tensor(test_sample)\n",
    "test_sample = test_sample.to(device)\n",
    "# sample_torch = torch.from_numpy(sample)\n",
    "params = OrderedDict({'weight': weights['layers.0.0.weight'], 'bias': weights['layers.0.0.bias']})\n",
    "\n",
    "model = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding='same') # 1 input channel, 1 output channels, kernelsize=3, stride=1, padding=0\n",
    "model.to(device)\n",
    "model.load_state_dict(params)\n",
    "pytorch_conv_out = model(test_sample)\n",
    "pytorch_conv_out = pytorch_conv_out.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821bc53-3833-41b3-a6da-201a9dca7eb0",
   "metadata": {},
   "source": [
    "# **THE `im2col` FUNCTION IS THE SAME AS THE PYTORCH OUTPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7a0e32b-4534-4b66-b555-f18b8c09c5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(conv_out, pytorch_conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ace26f0e-e4b6-4014-90a7-59576436105a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2597221492.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_21550/2597221492.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    np.allclose(\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "np.allclose("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a71ee-7674-445b-929a-e30f1ee899d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb87efe-6b65-4160-bce0-2f76ed4dccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def np_BatchNorm2d(input_data, prefix, weights_dict, epsilon=1e-5):\n",
    "    \n",
    "    x = input_data\n",
    "    \n",
    "    gamma = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    beta = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    mean = weights_dict[str(prefix) + 'running_mean'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    var = weights_dict[str(prefix) + 'running_var'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "        \n",
    "        \n",
    "    output = ((x - mean) / np.sqrt(var + epsilon)) * gamma + beta\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
