{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a555d761-6816-4aff-8513-bbb47a72d039",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PT_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_63247/3844537819.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Importing utitility functions for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPT_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDnCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDnCNN_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPT_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImg_Dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLarge_Img_Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPT_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mppd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PT_files'"
     ]
    }
   ],
   "source": [
    "# import save_load as sl\n",
    "# import preprocess_data as ppd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "# from model import DnCNN\n",
    "# from Dataset import Img_Dataset\n",
    "import numpy as np \n",
    "import pathlib\n",
    "\n",
    "# Importing utitility functions for training\n",
    "from PT_files.model import DnCNN, DnCNN_B\n",
    "from PT_files.Dataset import Img_Dataset, Large_Img_Dataset\n",
    "import PT_files.preprocess_data as ppd\n",
    "import PT_files.save_load as sl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4dde8-7d74-4fe7-bda1-5683ee3aa2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_6k = sl.NERSC_load('test_data70-6000.npy')\n",
    "model = DnCNN()\n",
    "param_name = \"2k_model_bs64_e200.pth\"    \n",
    "start_idx = 0\n",
    "end_idx = 2000\n",
    "\n",
    "samp_idx = 0\n",
    "noise_data_2k = data_6k[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031f343-9f33-4460-a645-bd60d3076ba3",
   "metadata": {},
   "source": [
    "Quick test to see if running inference on the CPU allows for inference on the entire 6k by 6k image to be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f5e6d-66f0-4de7-9763-f65e87a6ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_grid_pass_window(dataset, model, samp_idx):\n",
    "    \n",
    "    full = np.empty((1, 1, 6000,6000))\n",
    "    count = np.empty((1, 1, 6000,6000))\n",
    "    \n",
    "    noise_data = dataset[0]\n",
    "    param_name = \"6k_model_bs64_e75.pth\"\n",
    "    \n",
    "    current_dir = pathlib.Path().resolve()\n",
    "    model_params_path = current_dir / 'Model_params'\n",
    "    assert model_params_path.exists()\n",
    "    model_path = model_params_path / param_name\n",
    "    \n",
    "    model = model()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(str(model_path)))\n",
    "    model.eval();\n",
    "    # telling pytorch this is for inference and not learning, so keeps the weights unchanged\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        test_noise = torch.as_tensor(noise_data[samp_idx:samp_idx+1,:,:, :])\n",
    "        test_noise = test_noise.to(device)\n",
    "\n",
    "        output = model(test_noise)\n",
    "        resid_img = output.to('cpu').detach().numpy()\n",
    "        \n",
    "        full[:, :, :, :] += resid_img\n",
    "        \n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4b4b4-27d1-4655-b9b8-cb21d03d2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full_grid_pass_window(dataset=data_6k,\n",
    "                             model=DnCNN_B,\n",
    "                             samp_idx=0\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbe023-cb90-47f2-b917-a5b16a31cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(24,20))\n",
    "vmin, vmax = np.percentile(data_6k[0][0][0], (1,99))\n",
    "\n",
    "ax[0].imshow(data_6k[0][0][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Noisy Sample')\n",
    "ax[1].imshow(full[0][0], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Denoised Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92060fc-6b51-48f1-8a33-300fd715e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(24,20))\n",
    "vmin, vmax = np.percentile(data_6k[0][0][0][1000:1200,1000:1200], (1,99))\n",
    "\n",
    "\n",
    "ax[0].imshow(data_6k[0][0][0][1000:1200,1000:1200], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Noisy Sample')\n",
    "ax[1].imshow(full[0][0][1000:1200,1000:1200],vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Denoised Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52c45f-e550-441c-b26d-69491b2bbf15",
   "metadata": {},
   "source": [
    "Function that uses 2k by 2k slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e16367-c4b9-4f48-a629-2c57b7f392f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_grid_pass_window(dataset,\n",
    "                   model,\n",
    "                   samp_idx,\n",
    "                   w_start,\n",
    "                   w_end,\n",
    "                   h_start,\n",
    "                   h_end):\n",
    "    \n",
    "    full = np.empty((1, 1, 6000,6000))\n",
    "    count = np.empty((1, 1, 6000,6000))\n",
    "    \n",
    "    noise_data = dataset[0]\n",
    "    param_name = \"2k_model_bs64_e200.pth\"\n",
    "    \n",
    "    current_dir = pathlib.Path().resolve()\n",
    "    model_params_path = current_dir / 'Model_params'\n",
    "    assert model_params_path.exists()\n",
    "    model_path = model_params_path / param_name\n",
    "    \n",
    "    model = model()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(str(model_path)))\n",
    "    model.eval();\n",
    "    # telling pytorch this is for inference and not learning, so keeps the weights unchanged\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        test_noise = torch.as_tensor(noise_data[samp_idx:samp_idx+1,:, w_start:w_end, h_start:h_end])\n",
    "        test_noise = test_noise.to(device)\n",
    "\n",
    "        output = model(test_noise)\n",
    "        resid_img = output.to('cpu').detach().numpy()\n",
    "        \n",
    "        full[:, :, w_start: w_end, h_start: h_end] += resid_img\n",
    "        count[:, :, w_start: w_end, h_start: h_end] += 1\n",
    "        \n",
    "    return full, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0585e8-f976-4aaf-ad2b-46549b899cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full, count = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=0,\n",
    "                             w_end=2000,\n",
    "                             h_start=0,\n",
    "                             h_end=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f81b243-f180-4d58-9427-7941d31ba779",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931dc156-53b8-450f-b878-6f76f7196ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_6k[0][0][0][:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6460b8-0caa-4728-b0aa-0355ab2661d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_6k[0][0][0][0:2000,0:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f487fb0-05a8-46ea-9703-994711626982",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(full[0][0][:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643581b-a9cb-4399-bfdf-91ff08450077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_grid_pass(dataset,\n",
    "                   model,\n",
    "                   samp_idx,\n",
    "                   w_start,\n",
    "                   w_end,\n",
    "                   h_start,\n",
    "                   h_end):\n",
    "    \n",
    "    slice_list = [2000, 4000, 6000]\n",
    "    \n",
    "    for i in range(slice_list):\n",
    "        for j in range(slice_list):\n",
    "            full, count = full_grid_pass_window(dataset=data_6k,\n",
    "                                     model= DnCNN,\n",
    "                                     samp_idx=0,\n",
    "                                     w_start=0,\n",
    "                                     w_end=slice_list[j],\n",
    "                                     h_start=0,\n",
    "                                     h_end=slice_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6730b-f774-475c-b227-a88d9347d285",
   "metadata": {},
   "source": [
    "CUDA out of memory. I can see why because I'm trying to run inference on 9 separate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d5549-03ca-44f4-a189-2a5021c96e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_list = [2000, 4000, 6000]\n",
    "\n",
    "for i in range(len(slice_list)):\n",
    "    for j in range(len(slice_list)):\n",
    "        full, count = full_grid_pass_window(dataset=data_6k,\n",
    "                                 model= DnCNN,\n",
    "                                 samp_idx=0,\n",
    "                                 w_start=0,\n",
    "                                 w_end=slice_list[j],\n",
    "                                 h_start=0,\n",
    "                                 h_end=slice_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa265cf-61aa-43d3-b483-bb87e6cb983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(full[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb521c2-0880-481a-a265-1059c474075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(24,20))\n",
    "vmin, vmax = np.percentile(data_6k[0][0][0][1000:1200,1000:1200], (1,99))\n",
    "ax[0].imshow(data_6k[0][0][0][1000:1200,1000:1200], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Noisy Sample')\n",
    "ax[1].imshow(full[0][0][1000:1200,1000:1200], vmin=vmin, vmax=vmax, origin='lower', interpolation='none')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Denoised Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640833f-bc8b-490b-9d7d-e9cd3baa0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(full[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414218e-901b-4b6c-9313-5015b075d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_list = [2000, 4000, 6000]\n",
    "    \n",
    "for i in range(len(slice_list)):\n",
    "    full1, count1 = full_grid_pass_window(dataset=data_6k,\n",
    "                                     model= DnCNN,\n",
    "                                     samp_idx=0,\n",
    "                                     w_start=0,\n",
    "                                     w_end=slice_list[i],\n",
    "                                     h_start=0,\n",
    "                                     h_end=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5036e-12f7-461e-8195-276deaa94c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_list = [2000, 4000, 6000]\n",
    "\n",
    "for j in range(len(slice_list)):\n",
    "    full2, count2 = full_grid_pass_window(dataset=data_6k,\n",
    "                                     model= DnCNN,\n",
    "                                     samp_idx=0,\n",
    "                                     w_start=0,\n",
    "                                     w_end=slice_list[i],\n",
    "                                     h_start=0,\n",
    "                                     h_end=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8c641-8cd0-486e-9893-d34349a074c5",
   "metadata": {},
   "source": [
    "I'm curious why this is out of memory? Trying to allocate the same amount of memory as the double for loop. Seems like I'm not shutting off or deleting the data & it's being stored in successive calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ac4e8-2f3c-4d4c-aa75-a2168b9f1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_list = [2000, 4000, 6000]\n",
    " \n",
    "for k in range(len(slice_list)):\n",
    "    full3, count3 = full_grid_pass_window(dataset=data_6k,\n",
    "                                     model=DnCNN,\n",
    "                                     samp_idx=0,\n",
    "                                     w_start=0,\n",
    "                                     w_end=slice_list[k],\n",
    "                                     h_start=0,\n",
    "                                     h_end=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050bd830-e18d-4c29-8c9a-618fa291edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full1 + full2 + full3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2060249-c979-46e2-9c4f-e27d25b2a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(full[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1e031-52b0-4783-9817-f5164c644b4a",
   "metadata": {},
   "source": [
    "When I do eveything manually and separately and then add everything together at the end it works. But this isn't clean. Need to figure out a way of not doing for loops potentionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c97b86-ef59-4583-8e20-f915805fbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_list = [2000, 4000, 6000]\n",
    "\n",
    "\n",
    "\n",
    "full1, count1 = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=0,\n",
    "                             w_end=2000,\n",
    "                             h_start=0,\n",
    "                             h_end=2000)\n",
    "\n",
    "full2, count2 = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=2000,\n",
    "                             w_end=4000,\n",
    "                             h_start=0,\n",
    "                             h_end=2000)\n",
    "\n",
    "full3, count3 = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=4000,\n",
    "                             w_end=6000,\n",
    "                             h_start=0,\n",
    "                             h_end=2000)\n",
    "\n",
    "full4, count4 = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=0,\n",
    "                             w_end=2000,\n",
    "                             h_start=2000,\n",
    "                             h_end=4000)\n",
    "\n",
    "full5, count5 = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=2000,\n",
    "                             w_end=4000,\n",
    "                             h_start=2000,\n",
    "                             h_end=4000)\n",
    "\n",
    "full6, count6 = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=4000,\n",
    "                             w_end=6000,\n",
    "                             h_start=2000,\n",
    "                             h_end=4000)\n",
    "\n",
    "full7, count7 = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=0,\n",
    "                             w_end=2000,\n",
    "                             h_start=4000,\n",
    "                             h_end=6000)\n",
    "\n",
    "full8, count8 = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=2000,\n",
    "                             w_end=4000,\n",
    "                             h_start=4000,\n",
    "                             h_end=6000)\n",
    "\n",
    "full9, count9 = full_grid_pass_window(dataset=data_6k,\n",
    "                             model= DnCNN,\n",
    "                             samp_idx=0,\n",
    "                             w_start=4000,\n",
    "                             w_end=6000,\n",
    "                             h_start=4000,\n",
    "                             h_end=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017a177-5fa8-4527-a4cd-f9f2e097cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full1 + full2 + full3 + full4 + full5 + full6 + full7 + full8 + full9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf19fa9-5ee8-4dda-a096-3cdabc88eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(full[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee5c3a-9fac-4128-9269-cbb0e1874c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(24,20))\n",
    "ax[0].imshow(data_6k[0][0][0][1000:1200,1000:1200], origin='lower', interpolation='none')\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Noisy Sample')\n",
    "ax[1].imshow(full[0][0][1000:1200,1000:1200], origin='lower', interpolation='none')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Clean Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66836f-3dbd-48c5-8762-c57652ebedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(full[0][0][1000:1200,1000:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218caee-0ae1-4c50-b315-27ffe1178d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_6k[0][0][0][1000:1200,1000:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e4179-991e-4d1e-9287-b737b66a536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full, count = full_grid_pass_window(dataset=data_6k,\n",
    "#                              model= DnCNN,\n",
    "#                              samp_idx=0,\n",
    "#                              w_start=2000,\n",
    "#                              w_end=4000,\n",
    "#                              h_start=0,\n",
    "#                              h_end=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e122f-09e2-4027-b99e-a78943085fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full, count = full_grid_pass_window(dataset=data_6k,\n",
    "#                              model= DnCNN,\n",
    "#                              samp_idx=0,\n",
    "#                              w_start=4000,\n",
    "#                              w_end=6000,\n",
    "#                              h_start=0,\n",
    "#                              h_end=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a7993-78ef-4027-8a5c-891554800aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full, count = full_grid_pass_window(dataset=data_6k,\n",
    "#                              model= DnCNN,\n",
    "#                              samp_idx=0,\n",
    "#                              w_start=0,\n",
    "#                              w_end=2000,\n",
    "#                              h_start=2000,\n",
    "#                              h_end=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a18a84-9a5f-48cd-bd7f-e833b33eed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full, count = full_grid_pass_window(dataset=data_6k,\n",
    "#                              model= DnCNN,\n",
    "#                              samp_idx=0,\n",
    "#                              w_start=2000,\n",
    "#                              w_end=4000,\n",
    "#                              h_start=2000,\n",
    "#                              h_end=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dcfff5-4819-4e70-a3c5-24e25d338f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full, count = full_grid_pass_window(dataset=data_6k,\n",
    "#                              model= DnCNN,\n",
    "#                              samp_idx=0,\n",
    "#                              w_start=4000,\n",
    "#                              w_end=6000,\n",
    "#                              h_start=2000,\n",
    "#                              h_end=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79253db-f744-485f-a680-1a2fff397bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full, count = full_grid_pass_window(dataset=data_6k,\n",
    "#                              model= DnCNN,\n",
    "#                              samp_idx=0,\n",
    "#                              w_start=0,\n",
    "#                              w_end=2000,\n",
    "#                              h_start=4000,\n",
    "#                              h_end=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82584ab3-51b9-47ba-b0e6-873be83191e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full, count = full_grid_pass_window(dataset=data_6k,\n",
    "#                              model= DnCNN,\n",
    "#                              samp_idx=0,\n",
    "#                              w_start=2000,\n",
    "#                              w_end=4000,\n",
    "#                              h_start=4000,\n",
    "#                              h_end=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32daca63-35bf-4e06-a6f1-10fe9c82949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full, count = full_grid_pass_window(dataset=data_6k,\n",
    "#                              model= DnCNN,\n",
    "#                              samp_idx=0,\n",
    "#                              w_start=4000,\n",
    "#                              w_end=6000,\n",
    "#                              h_start=4000,\n",
    "#                              h_end=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c3f3f-fc08-4f13-87f7-7607919a9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(full[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391e452-a3e6-4f96-8b3f-911ed0169ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_grid_pass(dataset,\n",
    "                   model,\n",
    "                   w_start_idx,\n",
    "                   w_end_idx,\n",
    "                   h_start_idx,\n",
    "                   h_end_idx):\n",
    "    \n",
    "    \"\"\"\n",
    "    Conducts denoising in 2000x2000 sub-image slices of the whole \n",
    "    6000x6000 focal plane image. It implements the first of three\n",
    "    passes of the image. It implements 9 inferences over the whole\n",
    "    focal plane image and covers the entire image.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    dataset: np.array\n",
    "        Should be a 5-D array of:\n",
    "        \n",
    "        dataset.shape = (dataset, number of samples, channel number,\n",
    "                         number of pixels in width, number of pixels in height)\n",
    "    \n",
    "    \n",
    "    model: pytorch model\n",
    "        Should be DnCNN or DnCNN-B as proposed as in Zheng et al. 2017\n",
    "        \n",
    "    \n",
    "    w_start_idx: int\n",
    "        Starting index of the width of the subimage window\n",
    "        \n",
    "    w_end_idx: int\n",
    "        Ending index of the width of the subimage window\n",
    "        \n",
    "    h_start_idx: int\n",
    "        Starting index of the height of the subimage window\n",
    "        \n",
    "    h_end_idx: int\n",
    "        Ending index of the height of the subimage window  \n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    \n",
    "    full: np.array\n",
    "        A (6000, 6000) array that contains all 9 of the (2000x2000) \n",
    "        sub-images combined together\n",
    "        \n",
    "        \n",
    "    count: np.array\n",
    "        An array that counts how many times an individual pixel has had\n",
    "        a denoising window applied to it. This will be used to average\n",
    "        over the pixels that are denoised multiple times.\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
