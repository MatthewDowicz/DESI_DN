{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970379a9-6168-4b9c-89fe-beb140dd83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu\n",
    "\n",
    "import time \n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d2affd-4509-4c06-91cb-be2a16b9b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "name = '6k_model_wb_e800_lys20_58feat.pth'\n",
    "\n",
    "# weights = np.load(DATA / name)\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730649b-3e67-47ed-b4f2-f755a98857ab",
   "metadata": {},
   "source": [
    "# **Testing the fftconvolve broadcasting version. Just want to see if it's faster and then see if the results are any better...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3afc16-98b3-4a18-a10d-7294463e0f85",
   "metadata": {},
   "source": [
    "Might be interesting to look at the [numpy-ml package](https://github.com/ddbourgin/numpy-ml/blob/master/numpy_ml/neural_nets/utils/utils.py) to see how they create a 2D Convolution layer.\n",
    "\n",
    "- They take inspiration from Andrej Karpathy's `im2col.py` file which can be found in these [slides here](http://cs231n.stanford.edu/slides/2016/winter1516_lecture11.pdf). \n",
    "\n",
    "- An article that I believe talks about the speed of `im2col.py` is [linked here](https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/). Need to read.\n",
    "\n",
    "- Lastly, there's a nice package that implements convolutions in a slow (ie. nested for loops) and a fast way (ie. uses im2col idea). Seems like it's fast? That's linked [here](https://github.com/3outeille/CNNumpy/blob/master/src/slow/layers.py)\n",
    "    - [Blog post](https://hackmd.io/@machine-learning/blog-post-cnnumpy-slow) discussing the `slow` version \n",
    "    - [Blog post](https://hackmd.io/@machine-learning/blog-post-cnnumpy-fast) discussing the `fast` version that uses im2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5585dfea-19b1-4f70-9f68-7e152f4e6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_Conv2d(input_data, weights_dict, prefix, stride=1, padding=\"same\", dilation=1):\n",
    "    \"\"\"\n",
    "    Numpy implementation of the PyTorch Conv2d layer that uses the \n",
    "    learned PyTorch weights in the model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data: nd.array\n",
    "        Input data of shape '(batch_size, in_channels, height, width)'\n",
    "    weights_dict: OrderedDict\n",
    "        weights_dict['weight']: torch.Tensor\n",
    "            Weights tensor of shape '(out_channels, in_channels, kernel_size[0], kernel_size[1])'\n",
    "        weights_dict['bias']: torch.Tensor\n",
    "            Bias tensor of shape '(out_channels)'\n",
    "    stride: int, optional\n",
    "        The number of entries by which the filter is moved at each step.\n",
    "        Defaults to 1\n",
    "    padding: str, optional\n",
    "        What padding strategy to use for this conv layer. Defaults to \"same\",\n",
    "        which pads the layer such that the output has the same height and width\n",
    "        as the input when the stride = 1. Specifically makes output of\n",
    "        scipy.correlate2d have same shape as in1. An alternative option is \"valid\",\n",
    "        which means no padding is done and the output has smaller dimensions\n",
    "        than the input.\n",
    "    dilation: int, optional\n",
    "        Spacing between kernel elements.\n",
    "        Defaults to 1.\n",
    "     \n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    output: nd.array\n",
    "        Array output of the convolution step with shape\n",
    "        `(batch_size, out_channels, out_height, out_width)`.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    dimensions_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 6000 , 6000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    dimensions_end = time.perf_counter()\n",
    "    print('Getting input dimensions takes', dimensions_end-dimensions_start, 'seconds')\n",
    "\n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    loading_start = time.perf_counter()\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    loading_end = time.perf_counter()\n",
    "    print('Loading the weights takes', loading_end-loading_start, 'seconds')\n",
    "    \n",
    "    # Convert string padding into numerical padding\n",
    "    # Using strings allow for one variable to account for padding & mode (see signal.correlated2d)\n",
    "    out_dimensions_start = time.perf_counter()\n",
    "    mode = padding\n",
    "    if mode == \"same\":\n",
    "        padding = 1\n",
    "    elif mode == \"valid\":\n",
    "        padding = 0\n",
    "    \n",
    "    # Calculations for the output H and W dimensions\n",
    "    height_out = ((height + (2*padding) - dilation * (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - dilation * (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "\n",
    "    # Create empty array of correct output dimensions\n",
    "    # output = np.empty((batch_size, output_channels, height_out, width_out))\n",
    "    output = np.zeros((batch_size, output_channels, height_out, width_out))\n",
    "    out_dimensions_end = time.perf_counter()\n",
    "    print('Getting output dimensions takes', out_dimensions_end-out_dimensions_start, 'seconds')\n",
    "    \n",
    "    # Place the cross correlated elements into the newly created \n",
    "    # empty array of correct output dimensions\n",
    "    loop_start = time.perf_counter()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        for j in range(output_channels):\n",
    "            for k in range(input_channels):\n",
    "                # See PyTorch docs for this eqn: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "                output[i, j, :, :] = bias[j] + signal.fftconvolve(input_data[i][k], weight[j][k][::-1, ::-1], mode=mode)\n",
    "                # output[i, j, :, :] = bias[j] + signal.correlate2d(input_data[i][k], weight[j][k], mode=mode)\n",
    "\n",
    "    loop_end = time.perf_counter()\n",
    "    print('Convolution loop takes', loop_end-loop_start, 'seconds')\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4a8fcb-eaad-4135-a1b8-35eca73e0038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting input dimensions takes 5.330002750270069e-06 seconds\n",
      "Loading the weights takes 0.0003740029933396727 seconds\n",
      "Getting output dimensions takes 0.0001379629975417629 seconds\n",
      "Convolution loop takes 46.13671796300332 seconds\n"
     ]
    }
   ],
   "source": [
    "np_conv_out = np_Conv2d(input_data=sample[0], weights_dict=weights, prefix='layers.0.0.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e248860-9a31-4c57-a566-a8f145de1725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 6000, 6000)\n",
      "(58, 1, 3, 3)\n",
      "Convolution via broadcasting takes 49.164740362990415 seconds\n"
     ]
    }
   ],
   "source": [
    "weight = weights['layers.0.0.weight'].detach().cpu().numpy()\n",
    "bias = weights['layers.0.0.bias'].detach().cpu().numpy()\n",
    "samples = sample[:2]\n",
    "print(samples.shape)\n",
    "print(weight.shape)\n",
    "\n",
    "samples = samples.reshape((2, 1, 1, 6000, 6000))\n",
    "weight = weight.reshape((1, 1, 58, 3, 3))\n",
    "\n",
    "broadcasting_start = time.perf_counter()\n",
    "speed = signal.fftconvolve(samples, weight, mode='same', axes=(3, 4))\n",
    "broadcasting_end = time.perf_counter()\n",
    "print('Convolution via broadcasting takes', broadcasting_end-broadcasting_start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e86b515-c55c-4170-8f3e-165b683dc1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 1, 6000, 6000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a71ee-7674-445b-929a-e30f1ee899d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb87efe-6b65-4160-bce0-2f76ed4dccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def np_BatchNorm2d(input_data, prefix, weights_dict, epsilon=1e-5):\n",
    "    \n",
    "    x = input_data\n",
    "    \n",
    "    gamma = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    beta = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    mean = weights_dict[str(prefix) + 'running_mean'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "    var = weights_dict[str(prefix) + 'running_var'].detach().cpu().numpy().reshape(-1, 1, 1)\n",
    "        \n",
    "        \n",
    "    output = ((x - mean) / np.sqrt(var + epsilon)) * gamma + beta\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
