{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a555d761-6816-4aff-8513-bbb47a72d039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# import save_load as sl\n",
    "# import preprocess_data as ppd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "# from model import DnCNN\n",
    "# from Dataset import Img_Dataset\n",
    "import numpy as np \n",
    "import pathlib\n",
    "\n",
    "# Importing utitility functions for training\n",
    "from PT_files.model import DnCNN_2k, DnCNN_B, DnCNN\n",
    "from PT_files.Dataset import Img_Dataset, Large_Img_Dataset\n",
    "import PT_files.preprocess_data as ppd\n",
    "import PT_files.save_load as sl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e4dde8-7d74-4fe7-bda1-5683ee3aa2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_6k = sl.NERSC_load('test_data70-6000.npy')\n",
    "data_6k = sl.NERSC_load('test_data_40%_6000.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031f343-9f33-4460-a645-bd60d3076ba3",
   "metadata": {},
   "source": [
    "Quick test to see if running inference on the CPU allows for inference on the entire 6k by 6k image to be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233f5e6d-66f0-4de7-9763-f65e87a6ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_grid_pass_window(dataset, model, model_params, samp_idx):\n",
    "    \n",
    "    full = np.empty((1, 1, 6000,6000))\n",
    "    count = np.empty((1, 1, 6000,6000))\n",
    "    \n",
    "    noise_data = dataset[0]\n",
    "    param_name = model_params\n",
    "    print('pass 1')\n",
    "    \n",
    "    current_dir = pathlib.Path().resolve()\n",
    "    model_params_path = current_dir / 'Model_params'\n",
    "    assert model_params_path.exists()\n",
    "    model_path = model_params_path / param_name\n",
    "    print('pass 2')\n",
    "    \n",
    "    model = model()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(str(model_path)))\n",
    "    model.eval();\n",
    "    print('pass 3')\n",
    "    # telling pytorch this is for inference and not learning, so keeps the weights unchanged\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        print('pass 4')\n",
    "        torch.cuda.empty_cache()\n",
    "        test_noise = torch.as_tensor(noise_data[samp_idx:samp_idx+1,:,:, :])\n",
    "        test_noise = test_noise.to(device)\n",
    "\n",
    "        print('pass 5')\n",
    "        output = model(test_noise)\n",
    "        print('pass 6')\n",
    "        resid_img = output.to('cpu').detach().numpy()\n",
    "        print('pass 7')\n",
    "\n",
    "        full[:, :, :, :] += resid_img\n",
    "\n",
    "    return full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f8bb8-88e4-4bde-a36e-d35683990224",
   "metadata": {},
   "source": [
    "Test of model trained on batch size of 16, patch size of 150x150, and 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b4b4b4-27d1-4655-b9b8-cb21d03d2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full = full_grid_pass_window(dataset=data_6k,\n",
    "#                              model=DnCNN_B,\n",
    "#                              model_params=\"6k_model_wb_e800.pth\",\n",
    "#                              samp_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308b3a6-5ce7-47b5-90d2-bf7ff42988e4",
   "metadata": {},
   "source": [
    "Time for cpu based inference for base DnCNN w adam optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5fb306d-32c6-4e17-807f-59ca06947d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass 1\n",
      "pass 2\n",
      "pass 3\n",
      "pass 4\n",
      "pass 5\n",
      "pass 6\n",
      "pass 7\n"
     ]
    }
   ],
   "source": [
    "full = full_grid_pass_window(dataset=data_6k, model=DnCNN_2k, model_params=\"6k_model_wb_e800_lys10_32feat.pth\", samp_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437bf9c5-2d42-4005-83d4-f0b86da6aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(24,20))\n",
    "# vmin, vmax = np.percentile(data_6k[0][0][0], (1,99))\n",
    "\n",
    "# plt.imshow(full[0][0][2800:3000, 2800:3000], vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643743a1-aa69-4e16-b2cd-2092996453fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl.NERSC_save('6k_model_wb_e800_lys10_32feat.npy', full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159939fd-ed7c-4453-abad-26fac8447ada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
