{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2556c370-8bee-49b8-9889-59d132b67c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu, np_BatchNorm2d\n",
    "\n",
    "import time \n",
    "from collections import OrderedDict\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581bd85-0df4-4671-a756-fac9c1f091a2",
   "metadata": {},
   "source": [
    "**The goal of this notebook is to implement the optimization we found in notebook `11B_testing_im2col_times` where we call `get_indices` 3 times and then saving those 3 indice matrices. Then we use `np.ravel_multi_index()` in `im2col`.**\n",
    "\n",
    "**NOTE: This is for a 2k by 2k image instead of the full 6k by 6k image.**\n",
    "\n",
    "This notebook is creating the respective index matrices, so that it can be used in another notebook which just uses the already created matrices, instead of creating their own every call. This is supposedly to save a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da82d657-cc15-4d46-9ffa-e2b9292e7ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "# Loading data & weights dictionary\n",
    "\n",
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "# name = '6k_model_wb_e800_lys20_58feat.pth'\n",
    "name = '2k_model_bs64_e800_ps50_Adam.pth'\n",
    "# weights = np.load(DATA / name)\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)\n",
    "\n",
    "samp = sample[0][0][1000:3000, 1000:3000]\n",
    "samp = samp.reshape((1, 1, 2000, 2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6654330-7cb7-46cb-aa23-ebc4a7d33c12",
   "metadata": {},
   "source": [
    "Need to call this three times:\n",
    "1. First for the untransformed input. (1 channel -> 64 channels)\n",
    "2. For the middle layers (64 channels -> 64 channels)\n",
    "3. For the last layer (64 channels -> 1 channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc09ac6-0e60-4660-a85b-2854bf9f352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    get_indices_start = time.perf_counter()\n",
    "\n",
    "    # Get input size\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Calculations for the output H and W dimensions.\n",
    "    height_out = ((height + (2*padding) - (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "    \n",
    "    \n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(kernel_size[0]), kernel_size[1])\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(height_out), width_out)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(kernel_size[1]), kernel_size[0])\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(width_out), height_out)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(input_channels), kernel_size[0] * kernel_size[1]).reshape(-1, 1)\n",
    "    \n",
    "    get_indices_end = time.perf_counter()\n",
    "    print('get_indices takes:', get_indices_end-get_indices_start, 'seconds')\n",
    "    \n",
    "    return i, j, d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13106bc4-30bc-4512-965a-a051e6ae14cb",
   "metadata": {},
   "source": [
    "Need to load `im2col` &` np_Conv2d`because we need to get the output of `np_Conv2d` for the first layer, intermediate layers, and last layer so that we have the correct shapes for the indices (via `get_indices` that will be used in `im2col` and thus `np_Conv2d`. The differences of `im2col2` and `np_conv2d2` are the versions of the functions that instead of creating the `i, j, d` index matrices it automatically loads them in thus saving ~4 seconds in the intermediate layers of the model that would call `get_indices` for every Conv layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f886c5d-1e0a-4ed3-b57c-bdcdd7ea0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = input_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols\n",
    "\n",
    "def im2col2(input_data, weights_dict, prefix, layer_matrices,  stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = layer_matrices\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    idx = np.ravel_multi_index(([0], d, i, j), input_padded.shape)\n",
    "    cols2 = input_padded.reshape(-1)[idx]  \n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols2\n",
    "\n",
    "def np_Conv2d(input_data, weights_dict, prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out\n",
    "\n",
    "def np_Conv2d2(input_data, weights_dict, prefix, layers_matrices):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    \n",
    "    X_col = im2col2(input_data=input_data,weights_dict=weights_dict,prefix=prefix,layer_matrices=layers_matrices)    \n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b016b172-43eb-47c2-8df2-5ebba8b74e78",
   "metadata": {},
   "source": [
    "Creating the correct shapes/values of the intermediate arrays that are necessary\n",
    "for creating the intermediate and final index matrices.\n",
    "\n",
    "These use the original functions that take a long time to process\n",
    "(ie. the unoptimized versions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b2ea69-2ae2-4fe2-935d-6ef2ad77715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.20318904699524865 seconds\n",
      "Im2col takes: 0.38422512699617073 seconds\n",
      "Conv takes: 0.6892922529950738 seconds\n",
      "get_indices takes: 4.506992716982495 seconds\n",
      "Im2col takes: 16.17006884800503 seconds\n",
      "Conv takes: 18.831207142968196 seconds\n",
      "Batch takes 0.5197017129976302 seconds\n",
      "get_indices takes: 4.58227440295741 seconds\n",
      "Im2col takes: 16.320511292957235 seconds\n",
      "Conv takes: 18.291405173018575 seconds\n",
      "Batch takes 0.5131230020197108 seconds\n",
      "get_indices takes: 4.383848374010995 seconds\n",
      "Im2col takes: 15.872206142987125 seconds\n",
      "Conv takes: 16.21529218700016 seconds\n"
     ]
    }
   ],
   "source": [
    "# Creating the correct shapes/values of the intermediate arrays that are necessary\n",
    "# for creating the intermediate and final index matrices.\n",
    "#\n",
    "# These use the original functions that take a long time to process\n",
    "# (ie. the unoptimized versions)\n",
    "\n",
    "# First layer\n",
    "conv0 = np_Conv2d(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "out0 = relu(conv0)\n",
    "\n",
    "# Second layer\n",
    "conv1 = np_Conv2d(input_data=out0, weights_dict=weights, prefix='layers.1.0.')\n",
    "batch1 = np_BatchNorm2d(x=conv1, weights_dict=weights, prefix='layers.1.1.')\n",
    "out1 = relu(batch1)\n",
    "\n",
    "# Third layer \n",
    "conv2 = np_Conv2d(input_data=out1, weights_dict=weights, prefix='layers.2.0.')\n",
    "batch2 = np_BatchNorm2d(x=conv2, weights_dict=weights, prefix='layers.2.1.')\n",
    "out2 = relu(batch2)\n",
    "\n",
    "# Last layer: Due to get_indices being only dependent on shape and not actual \n",
    "# values we can just use any of the intermediate outputs, due to them \n",
    "# having the correct shape.\n",
    "conv19 = np_Conv2d(input_data=out2, weights_dict=weights, prefix='layers.19.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f4cbe3-8eec-443f-8f14-e93cdfa5b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 2000, 2000)\n",
      "(1, 1, 2000, 2000)\n",
      "torch.Size([1, 64, 3, 3])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(out2.shape)\n",
    "print(conv19.shape)\n",
    "print(weights['layers.19.weight'].shape)\n",
    "print(len(weights['layers.19.weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e911e2-15ba-4020-92cd-1c420c397fe4",
   "metadata": {},
   "source": [
    "Creation of the first index matrix (1 C -> 64 C), the intermediate\n",
    "index matrix (64 C -> 64 C), and the final index matrix (64 C -> 1 C).\n",
    "\n",
    "For the intermediate index matrix we need the shape of the input data, but\n",
    "because the first layer transforms the shape of the input data, we need \n",
    "to run the first layer of the model to get the correct shape of the data\n",
    "that will be used for creating the index matrix.\n",
    "\n",
    "NOTE: If the values of the last index matrix don't work, we'll need to create the whole model and use the final output to create the correct `i_last, j_last, d_last` index matrices.\n",
    "\n",
    "**NOTE: It seems it does NOT work. Thus we'll need to run the whole model toward the end except for the last layer to get the correct indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86a437f-7323-49cf-956b-81e76e44e609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.09487872099271044 seconds\n",
      "get_indices takes: 4.8536589840077795 seconds\n",
      "get_indices takes: 0.09628924203570932 seconds\n"
     ]
    }
   ],
   "source": [
    "# Creation of the first index matrix (1 C -> 64 C) and the intermediate\n",
    "# index matrix (64 C -> 64 C).\n",
    "#\n",
    "# For the intermediate index matrix we need the shape of the input data, but\n",
    "# because the first layer transforms the shape of the input data, we need \n",
    "# to run the first layer of the model to get the correct shape of the data\n",
    "# that will be used for creating the index matrix\n",
    "\n",
    "\n",
    "# First layer\n",
    "i_start, j_start, d_start = get_indices(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "index_mat_start = (i_start, j_start, d_start)\n",
    "\n",
    "# Second layer\n",
    "i_mid, j_mid, d_mid = get_indices(input_data=out0, weights_dict=weights, prefix='layers.1.0.')\n",
    "index_mat_mid = (i_mid, j_mid, d_mid)\n",
    "\n",
    "# Last layer\n",
    "# NOTE: If these don't work we'll need to run the entire model to get the\n",
    "# correct values/shape of the output data.\n",
    "i_last, j_last, d_last = get_indices(input_data=conv19, weights_dict=weights, prefix='layers.19.')\n",
    "index_mat_last = (i_last, j_last, d_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c199004-a55f-4ce9-89af-8d46301d421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_matrices = {'start': index_mat_start, 'mid': index_mat_mid, 'last': index_mat_last}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff063023-c6a2-46f7-bf81-a4e80cc5366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = sl.NERSC_load(name='index_matrices_2k.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998f29a-4578-40d7-b584-7ec77623ebfd",
   "metadata": {},
   "source": [
    "Creating a new version of `im2col` where it loads in the saved index matrices created from `get_indices`, and outputs the output of `np.ravel_multi_index()` to then be run 3 times (due to the 3 calls of `get_indices` we must do to go from 1C->64C, 64C->64C, 64C->1C) to then combine the three runs of `np.ravel_multi_index()` into a dictionary to then be saved to the `Data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc95647-8cc8-4a73-bd22-9316728578d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def im2col2_save(input_data, prefix, layer_matrices,  stride=1, padding=1):\n",
    "#     \"\"\"\n",
    "#         Transforms our input image into a matrix.\n",
    "\n",
    "#         Parameters:\n",
    "#         -----------\n",
    "#         input_data: nd.array\n",
    "#             The input image(s)\n",
    "#         weights_dict: OrderedDict\n",
    "#             Dictionary containing the PyTorch trained weights for every \n",
    "#             layer of the model\n",
    "#         prefix: str\n",
    "#             Prefix to use to identify which multi-dimensional array indexing \n",
    "#             array we're saving (ie. first, mid, last). Similar to the naming\n",
    "#             convetion we have for the individual matrix indices from \n",
    "#             get_indices\n",
    "\n",
    "#         Returns:\n",
    "#         --------\n",
    "#         cols: output matrix.\n",
    "#     \"\"\"\n",
    "#     im2col_start = time.perf_counter()\n",
    "\n",
    "#     if len(input_data.shape) == 4:\n",
    "    \n",
    "#         batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "#     elif len(input_data.shape) == 3:\n",
    "        \n",
    "#         input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "#         batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "#     # Padding\n",
    "#     input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "#     i, j, d = layer_matrices\n",
    "#     # Multi-dimensional arrays indexing.\n",
    "#     idx = np.ravel_multi_index(([0], d, i, j), input_padded.shape)\n",
    "    \n",
    "    \n",
    "#     sl.NERSC_save(name='array_idx_' +str(prefix), data=idx)\n",
    "    \n",
    "    \n",
    "#     cols2 = input_padded.reshape(-1)[idx]  \n",
    "    \n",
    "#     im2col_end = time.perf_counter()\n",
    "#     print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "#     return cols2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f972f-7f7b-4972-963f-41e0d80d726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols2 = im2col2_save(input_data=samp, prefix='start_2k.pkl', layer_matrices=index_matrices['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5445abe8-6bae-47af-86ae-9f55a561ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col2_save(input_data, layer_matrices,  stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            Prefix to use to identify which multi-dimensional array indexing \n",
    "            array we're saving (ie. first, mid, last). Similar to the naming\n",
    "            convetion we have for the individual matrix indices from \n",
    "            get_indices\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = layer_matrices\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    idx = np.ravel_multi_index(([0], d, i, j), input_padded.shape)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cbd50eb-0183-4356-9f27-394122bb4529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not on NERSC?\n"
     ]
    }
   ],
   "source": [
    "idx_start = im2col2_save(input_data=samp, layer_matrices=index_matrices['start'])\n",
    "idx_mid = im2col2_save(input_data=out0, layer_matrices=index_matrices['mid'])\n",
    "idx_last = im2col2_save(input_data=conv19, layer_matrices=index_matrices['last'])\n",
    "\n",
    "im2col_layer_dict = {'start': idx_start, 'mid':idx_mid, 'last': idx_last}\n",
    "\n",
    "sl.NERSC_save(name='im2col_layer_dict_2k.pkl', data=im2col_layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d58c5d85-83bc-4f4f-89ef-805c2042c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2col_mat = sl.NERSC_load(name='im2col_layer_dict_2k.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01d116-0abb-4382-9566-29a626571761",
   "metadata": {},
   "source": [
    "Testing the outputs of the original functions for a 2D Convolution (ie. `get_indices`, `im2col`, and `np_Conv2d`) and comparing them to the modified versions of the functions that take the saved index matrices and saved sliced matrices from `im2col2` and `np_Conv2d2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0677110d-83da-4417-9ffd-df7416c929f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = input_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols\n",
    "\n",
    "def im2col2(input_data, im2col_mat, col_prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    idx = im2col_mat[str(col_prefix)]\n",
    "    cols2 = input_padded.reshape(-1)[idx]  \n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93fcc065-514a-435b-8c29-1bbe4033d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im2col takes: 0.039900068019051105 seconds\n",
      "Im2col takes: 2.5748618410434574 seconds\n",
      "Im2col takes: 0.04051882104249671 seconds\n"
     ]
    }
   ],
   "source": [
    "cols_start = im2col2(input_data=samp,\n",
    "                     im2col_mat=im2col_layer_dict,\n",
    "                     col_prefix='start')\n",
    "\n",
    "cols_mid = im2col2(input_data=out1,\n",
    "                     im2col_mat=im2col_layer_dict,\n",
    "                     col_prefix='mid')\n",
    "\n",
    "\n",
    "cols_last = im2col2(input_data=conv19,\n",
    "                     im2col_mat=im2col_layer_dict,\n",
    "                     col_prefix='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acaae6d1-f8da-4f63-9f3f-1765db125c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_Conv2d(input_data, weights_dict, prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out\n",
    "\n",
    "def np_Conv2d2(input_data, weights_dict, prefix, im2col_mat, col_prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    \n",
    "    X_col = im2col2(input_data=input_data, im2col_mat=im2col_mat, col_prefix=str(col_prefix))\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dede1df-f307-4c6a-a3b5-dce7260ceed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.08942202798789367 seconds\n",
      "Im2col takes: 0.2713753590360284 seconds\n",
      "Conv takes: 0.5717813199735247 seconds\n",
      "Im2col takes: 0.04423292598221451 seconds\n",
      "Conv takes: 0.3409007480368018 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = np_Conv2d(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "conv2 = np_Conv2d2(input_data=samp,\n",
    "                   weights_dict=weights,\n",
    "                   prefix='layers.0.0.',\n",
    "                   im2col_mat=im2col_mat,\n",
    "                   col_prefix='start')\n",
    "\n",
    "np.allclose(conv1, conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9eee95-5771-446e-87c6-76a74228a07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
