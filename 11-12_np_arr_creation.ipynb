{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a703ad-9442-4157-9da8-4689a8258ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu, np_BatchNorm2d\n",
    "\n",
    "import time \n",
    "from collections import OrderedDict\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c016d5-a344-402b-ac2c-d4a6b79df5ce",
   "metadata": {},
   "source": [
    "**The goal of this notebook is to reduce the runtime of the numpy forward implementation of the pytorch denoising algorithm. It does this by saving the output of `get_indices` 3 times. It uses those saved indices in `im2col` via `np.ravel_multi_index()`.**\n",
    "\n",
    "This reduces the runtime considerably because we only call `get_indices` 3 times instead of however many times the model calls a `conv` layer. In our case, that is 20 times. It then further saves time by only using those 3 saved indices via `np.ravel_multi_index()` instead of calling the older version a unique time.\n",
    "\n",
    "**NOTE: This is for a 2020x2020 patch due to memory issues trying to use the full 6k by 6k image.**\n",
    "- The reason the patches are 2020 x 2020 instead of 2000x2000 is because we found that there are artifacts with the 2000x2000. If we do patchs of 2020x2020 (ie. a patch w/ a 10 pixel border) and pad the full FVC image with a 10 pixel border we're able use these larger patches, but cropping there extra 10 pixel border and not have any artifacts at all! This reduces the runtime/scale of the afterburner function, which is what we want to do.\n",
    "- If you need to re-save the any of the intermediate layer indices for the NumPy implementation of the code you'll need to reshape the image data, as well as, all the `np.reshapes` found within the subsequent code. \n",
    "    - The reason I don't do this is because I do not suspect I'll ever need to do this more than maybe once after the code is on `fpoffline`.\n",
    "        - That said I'll probably hate myself for this, but the code is pretty much all written anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a810f76-db89-45d1-949a-0b91c08d924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "# Getting path to weights file and loading in actual weights dict\n",
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "name = '2k_model_bs64_e800_ps50_Adam.pth'\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)\n",
    "\n",
    "# Reshape the data \n",
    "samp = sample[0][0][1000:3020, 1000:3020]\n",
    "samp = samp.reshape((1, 1, 2020, 2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c69c6-d734-4967-8570-e91f69171366",
   "metadata": {},
   "source": [
    "Need to call this three times and save the outputs:\n",
    "1. First for the untransformed input. (1 channel -> 64 channels)\n",
    "2. For the middle layers (64 channels -> 64 channels)\n",
    "3. For the last layer (64 channels -> 1 channel)\n",
    "\n",
    "**NOTE:** Code/Code Blog where I got this numpy im2col conversion is [here](https://hackmd.io/@machine-learning/blog-post-cnnumpy-fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64cf144a-c24f-4bc9-b00e-d46138d4d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    get_indices_start = time.perf_counter()\n",
    "\n",
    "    # Get input size\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2020 , 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 2:\n",
    "        input_data = input_data.reshape((1, 1, 2020, 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Calculations for the output H and W dimensions.\n",
    "    height_out = ((height + (2*padding) - (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "    \n",
    "    \n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(kernel_size[0]), kernel_size[1])\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(height_out), width_out)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(kernel_size[1]), kernel_size[0])\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(width_out), height_out)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(input_channels), kernel_size[0] * kernel_size[1]).reshape(-1, 1)\n",
    "    \n",
    "    get_indices_end = time.perf_counter()\n",
    "    print('get_indices takes:', get_indices_end-get_indices_start, 'seconds')\n",
    "    \n",
    "    return i, j, d\n",
    "\n",
    "def im2col(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        input_data = input_data.reshape((1, 1, 2020 , 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    elif len(input_data.shape) == 2:\n",
    "        input_data = input_data.reshape((1, 1, 2020, 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = input_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols\n",
    "\n",
    "\n",
    "def np_Conv2d(input_data, weights_dict, prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2020 , 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "    \n",
    "    elif len(input_data.shape) == 2:\n",
    "        input_data = input_data.reshape((1, 1, 2020, 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    \n",
    "    print('X_col.shape = ', X_col.shape)\n",
    "    print('w_col.shape = ', w_col.shape)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731f79d-3a7a-451f-851e-f97a70e32e57",
   "metadata": {},
   "source": [
    "Need to load `im2col` &` np_Conv2d`because we need to get the output of `np_Conv2d` for the first layer, intermediate layers, and last layer so that we have the correct shapes for the indices (via `get_indices` that will be used in `im2col` and thus `np_Conv2d`). The differences of `im2col2` and `np_conv2d2` are the versions of the functions that instead of creating the `i, j, d` index matrices it automatically loads them in thus saving ~4 seconds in the intermediate layers of the model that would call `get_indices` for every Conv layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c33e74-b418-4456-9b22-08e68e8cb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Replace the last part of the key that describes what layer it is\n",
    "# part of and replaces it with empty space\n",
    "layers_list = [x.replace('weight', '').replace('bias', '').replace('running_mean', '').replace('running_var', '').replace('num_batches_tracked', '') for x in weights.keys()]\n",
    "# Convert this list which has duplicated elements due to removing\n",
    "# identifying elements ie. for the first conv layer we had\n",
    "# layers.0.0.weight & layers.0.0.bias, but now after removing them we\n",
    "# have layers.0.0 & layers.0.0\n",
    "# The code below deletes the duplicated elements\n",
    "layers_list = list(OrderedDict.fromkeys(layers_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba931b-dd0a-42dd-a356-e461ed8fd6fd",
   "metadata": {},
   "source": [
    "We run the model through the baseline NumPy functions, so we get the correct shape of every layer. **BUT,** we only need the shape of the output from the first layer (1C -> 64C), an intermediate layer (64C->64C), and the last layer (64C->1C). We just need to instantiate the 1st, 2nd, and last layer without having to worry about the other layers of the model because those layers don't change the dimensionality of the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9ae781-f25f-4687-a6de-47766c3ef643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.09712557913735509 seconds\n",
      "Im2col takes: 0.28065531607717276 seconds\n",
      "X_col.shape =  (9, 4080400)\n",
      "w_col.shape =  (64, 9)\n",
      "Conv takes: 0.6142878120299429 seconds\n",
      "get_indices takes: 4.695406832033768 seconds\n",
      "Im2col takes: 16.266699539031833 seconds\n",
      "X_col.shape =  (576, 4080400)\n",
      "w_col.shape =  (64, 576)\n",
      "Conv takes: 18.508120679995045 seconds\n",
      "get_indices takes: 4.827232877025381 seconds\n",
      "Im2col takes: 16.416074029169977 seconds\n",
      "X_col.shape =  (576, 4080400)\n",
      "w_col.shape =  (1, 576)\n",
      "Conv takes: 16.77784837805666 seconds\n"
     ]
    }
   ],
   "source": [
    "# Creating the correct shapes/values of the intermediate arrays that are necessary\n",
    "# for creating the intermediate and final index matrices.\n",
    "#\n",
    "# These use the original functions that take a long time to process\n",
    "# (ie. the unoptimized versions)\n",
    "\n",
    "# First layer\n",
    "conv0 = np_Conv2d(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "# Second layer (ie. intermediate layer)\n",
    "conv1 = np_Conv2d(input_data=conv0, weights_dict=weights, prefix='layers.1.0.')\n",
    "# Last layer\n",
    "conv = np_Conv2d(input_data=conv1, weights_dict=weights, prefix='layers.19.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed227fa-d9a8-4873-91f4-2c43b2f23740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.09534529317170382 seconds\n",
      "get_indices takes: 4.82147181709297 seconds\n",
      "get_indices takes: 4.38091963599436 seconds\n"
     ]
    }
   ],
   "source": [
    "# Creation of the first index matrix (1 C -> 64 C) and the intermediate\n",
    "# index matrix (64 C -> 64 C).\n",
    "#\n",
    "# For the intermediate index matrix we need the shape of the input data, but\n",
    "# because the first layer transforms the shape of the input data, we need \n",
    "# to run the first layer of the model to get the correct shape of the data\n",
    "# that will be used for creating the index matrix\n",
    "\n",
    "\n",
    "# First layer\n",
    "i_start, j_start, d_start = get_indices(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "index_mat_start = (i_start, j_start, d_start)\n",
    "\n",
    "# Second layer\n",
    "i_mid, j_mid, d_mid = get_indices(input_data=conv0, weights_dict=weights, prefix='layers.1.0.')\n",
    "index_mat_mid = (i_mid, j_mid, d_mid)\n",
    "\n",
    "# Last layer\n",
    "i_last, j_last, d_last = get_indices(input_data=conv1, weights_dict=weights, prefix='layers.19.')\n",
    "index_mat_last = (i_last, j_last, d_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9141828f-81fc-416f-87b9-dca5a511a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_matrices = {'start': index_mat_start, 'mid': index_mat_mid, 'last': index_mat_last}\n",
    "# sl.NERSC_save(data=index_matrices, name='index_matrices_2k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38aab444-10e5-4811-9743-9cfa04e03fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col2_save(input_data, layer_matrices,  stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            Prefix to use to identify which multi-dimensional array indexing \n",
    "            array we're saving (ie. first, mid, last). Similar to the naming\n",
    "            convetion we have for the individual matrix indices from \n",
    "            get_indices\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2020 , 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(indput_data.shape) == 2:\n",
    "        input_data = input_data.reshape((1, 1, 2020, 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = layer_matrices\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    idx = np.ravel_multi_index(([0], d, i, j), input_padded.shape)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67be89b-a271-473b-82f5-13ce99ea4c05",
   "metadata": {},
   "source": [
    "Saving the arrays as `np.int32` instead of `np.int64` (done by default) to reduce the memory size of the index arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77168cc3-1b25-41e7-8040-41c0f4a6c8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not on NERSC?\n"
     ]
    }
   ],
   "source": [
    "idx_start = im2col2_save(input_data=samp, layer_matrices=index_matrices['start'])\n",
    "idx_start = idx_start.astype(np.int32)\n",
    "idx_mid = im2col2_save(input_data=conv0, layer_matrices=index_matrices['mid'])\n",
    "idx_mid = idx_mid.astype(np.int32)\n",
    "idx_last = im2col2_save(input_data=conv1, layer_matrices=index_matrices['last'])\n",
    "idx_last = idx_last.astype(np.int32)\n",
    "\n",
    "\n",
    "im2col_layer_dict = {'start': idx_start, 'mid':idx_mid, 'last': idx_last}\n",
    "sl.NERSC_save(name='im2col_2k_indices.pkl', data=im2col_layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495b0c43-cd5e-40fa-b909-01db864a5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col2(input_data, im2col_mat, col_prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    idx = im2col_mat[str(col_prefix)]\n",
    "    cols2 = input_padded.reshape(-1)[idx]  \n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols2\n",
    "\n",
    "def np_Conv2d2(input_data, weights_dict, prefix, im2col_mat, col_prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    \n",
    "    X_col = im2col2(input_data=input_data, im2col_mat=im2col_mat, col_prefix=str(col_prefix))\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e838578-55c8-4d7e-b7b3-85199d35678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im2col takes: 0.06225603702478111 seconds\n",
      "Conv takes: 0.3629320561885834 seconds\n"
     ]
    }
   ],
   "source": [
    "conv2 = np_Conv2d2(input_data=samp,\n",
    "                   weights_dict=weights,\n",
    "                   prefix='layers.0.0.',\n",
    "                   im2col_mat=im2col_layer_dict,\n",
    "                   col_prefix='start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0296874-0743-47e5-b56a-bf5d3435fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im2col takes: 0.0671454300172627 seconds\n",
      "Conv takes: 0.369020669022575 seconds\n",
      "Im2col takes: 3.9114704439416528 seconds\n",
      "Conv takes: 5.694785895990208 seconds\n",
      "Batch takes 0.5338732560630888 seconds\n",
      "Im2col takes: 3.9073991880286485 seconds\n",
      "Conv takes: 5.773855175124481 seconds\n",
      "Batch takes 0.5317959820386022 seconds\n",
      "Im2col takes: 3.9137064630631357 seconds\n",
      "Conv takes: 5.842254780931398 seconds\n",
      "Batch takes 0.5307894931174815 seconds\n",
      "Im2col takes: 3.909976133843884 seconds\n",
      "Conv takes: 5.806535869836807 seconds\n",
      "Batch takes 0.5313932751305401 seconds\n",
      "Im2col takes: 3.9199831520672888 seconds\n",
      "Conv takes: 5.945462896022946 seconds\n",
      "Batch takes 0.5291646278928965 seconds\n",
      "Im2col takes: 3.9153064938727766 seconds\n",
      "Conv takes: 5.970251590013504 seconds\n",
      "Batch takes 0.5310004490893334 seconds\n",
      "Im2col takes: 3.908295843983069 seconds\n",
      "Conv takes: 5.932337681995705 seconds\n",
      "Batch takes 0.5303960929159075 seconds\n",
      "Im2col takes: 3.9216194341424853 seconds\n",
      "Conv takes: 5.980398446088657 seconds\n",
      "Batch takes 0.5300258460920304 seconds\n",
      "Im2col takes: 4.030833605211228 seconds\n",
      "Conv takes: 6.088781103026122 seconds\n",
      "Batch takes 0.503147000214085 seconds\n",
      "Im2col takes: 4.038491241168231 seconds\n",
      "Conv takes: 6.077071817126125 seconds\n",
      "Batch takes 0.5168546098284423 seconds\n",
      "Im2col takes: 4.038267167983577 seconds\n",
      "Conv takes: 6.087354031158611 seconds\n",
      "Batch takes 0.5171963388565928 seconds\n",
      "Im2col takes: 4.041789590148255 seconds\n",
      "Conv takes: 5.969942163908854 seconds\n",
      "Batch takes 0.5162613561842591 seconds\n",
      "Im2col takes: 4.036629450041801 seconds\n",
      "Conv takes: 6.0621034051291645 seconds\n",
      "Batch takes 0.5193186111282557 seconds\n",
      "Im2col takes: 4.009225661167875 seconds\n",
      "Conv takes: 6.023519628914073 seconds\n",
      "Batch takes 0.5217710491269827 seconds\n",
      "Im2col takes: 4.025685057975352 seconds\n",
      "Conv takes: 6.026742654154077 seconds\n",
      "Batch takes 0.5198949018958956 seconds\n",
      "Im2col takes: 4.021508134901524 seconds\n",
      "Conv takes: 6.025063106091693 seconds\n",
      "Batch takes 0.5228942548856139 seconds\n",
      "Im2col takes: 4.005649077007547 seconds\n",
      "Conv takes: 6.08897304488346 seconds\n",
      "Batch takes 0.5214444932062179 seconds\n",
      "Im2col takes: 4.0095622160006315 seconds\n",
      "Conv takes: 5.957462006015703 seconds\n",
      "Batch takes 0.5129600518848747 seconds\n",
      "Im2col takes: 3.968377009034157 seconds\n",
      "Conv takes: 4.2929438930004835 seconds\n"
     ]
    }
   ],
   "source": [
    "output = np_Conv2d2(input_data=samp,\n",
    "                   weights_dict=weights,\n",
    "                   prefix=layers_list[0],\n",
    "                   im2col_mat=im2col_layer_dict,\n",
    "                   col_prefix='start')\n",
    "output = relu(output)\n",
    "\n",
    "# Layer 2 - Layer 19\n",
    "for i in range(len(layers_list)-2):\n",
    "\n",
    "    if layers_list[i+1].endswith('0.'):\n",
    "        output = np_Conv2d2(input_data=output,\n",
    "                           weights_dict=weights,\n",
    "                           prefix=layers_list[i+1],\n",
    "                           im2col_mat=im2col_layer_dict,\n",
    "                           col_prefix='mid')\n",
    "\n",
    "    elif layers_list[i+1].endswith('1.'):\n",
    "\n",
    "        output = np_BatchNorm2d(x=output, \n",
    "                                weights_dict=weights,\n",
    "                                prefix=layers_list[i+1])\n",
    "        output = relu(output)\n",
    "\n",
    "# Layer 20 (last layer)\n",
    "output1 = np_Conv2d2(input_data=output,\n",
    "                   weights_dict=weights,\n",
    "                   prefix=layers_list[-1],\n",
    "                   im2col_mat=im2col_layer_dict,\n",
    "                   col_prefix='last')\n",
    "\n",
    "resid_img = samp - output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84189bb2-fd11-4d18-bd47-277c0664e6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
