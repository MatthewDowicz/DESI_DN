{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a703ad-9442-4157-9da8-4689a8258ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import PT_files.save_load as sl\n",
    "from DnCNN_NP.layers  import relu, np_BatchNorm2d\n",
    "\n",
    "import time \n",
    "from collections import OrderedDict\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c016d5-a344-402b-ac2c-d4a6b79df5ce",
   "metadata": {},
   "source": [
    "**The goal of this notebook is to reduce the runtime of the numpy forward implementation of the pytorch denoising algorithm. It does this by saving the output of `get_indices` 3 times. It uses those saved indices in `im2col` via `np.ravel_multi_index()`.**\n",
    "\n",
    "This reduces the runtime considerably because we only call `get_indices` 3 times instead of however many times the model calls a `conv` layer. In our case, that is 20 times. It then further saves time by only using those 3 saved indices via `np.ravel_multi_index()` instead of calling the older version a unique time.\n",
    "\n",
    "**NOTE: This is for a 2020x2020 patch due to memory issues trying to use the full 6k by 6k image.**\n",
    "- The reason the patches are 2020 x 2020 instead of 2000x2000 is because we found that there are artifacts with the 2000x2000. If we do patchs of 2020x2020 (ie. a patch w/ a 10 pixel border) and pad the full FVC image with a 10 pixel border we're able use these larger patches, but cropping there extra 10 pixel border and not have any artifacts at all! This reduces the runtime/scale of the afterburner function, which is what we want to do.\n",
    "- If you need to re-save the any of the intermediate layer indices for the NumPy implementation of the code you'll need to reshape the image data, as well as, all the `np.reshapes` found within the subsequent code. \n",
    "    - The reason I don't do this is because I do not suspect I'll ever need to do this more than maybe once after the code is on `fpoffline`.\n",
    "        - That said I'll probably hate myself for this, but the code is pretty much all written anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a810f76-db89-45d1-949a-0b91c08d924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test set= (108, 1, 6000, 6000)\n"
     ]
    }
   ],
   "source": [
    "# Getting path to weights file and loading in actual weights dict\n",
    "PATH = pathlib.Path(os.getenv('PSCRATCH'))\n",
    "DATA = PATH / 'DESI_dn' /'Model_params'\n",
    "assert DATA.exists()\n",
    "name = '2k_model_bs64_e800_ps50_Adam.pth'\n",
    "weights = torch.load(str(DATA / name))\n",
    "\n",
    "\n",
    "#Load the actual data that we're working on & print the shape of this data\n",
    "test_data = sl.NERSC_load('test_data_40%_6000.npy')\n",
    "sample = test_data[0]\n",
    "print('Shape of test set=', sample.shape)\n",
    "\n",
    "# Reshape the data \n",
    "samp = sample[0][0][1000:3020, 1000:3020]\n",
    "samp = samp.reshape((1, 1, 2020, 2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c69c6-d734-4967-8570-e91f69171366",
   "metadata": {},
   "source": [
    "Need to call this three times and save the outputs:\n",
    "1. First for the untransformed input. (1 channel -> 64 channels)\n",
    "2. For the middle layers (64 channels -> 64 channels)\n",
    "3. For the last layer (64 channels -> 1 channel)\n",
    "\n",
    "**NOTE:** Code/Code Blog where I got this numpy im2col conversion is [here](https://hackmd.io/@machine-learning/blog-post-cnnumpy-fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64cf144a-c24f-4bc9-b00e-d46138d4d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    get_indices_start = time.perf_counter()\n",
    "\n",
    "    # Get input size\n",
    "    \n",
    "    # Checking to see if a single sample or a batch of samples is given.\n",
    "    # If batch take the batch_size, in_channels, H, and W\n",
    "    # If single sample is given reshape so the values above can be calculated\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2020 , 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 2:\n",
    "        input_data = input_data.reshape((1, 1, 2020, 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Load the weights and biases needed for a convolution\n",
    "    # then take off gpu memory, move to CPU memory,\n",
    "    # and lastly transform to numpy\n",
    "    weight = weights_dict[str(prefix) + 'weight']\n",
    "    weight = weight.detach().cpu().numpy()\n",
    "    \n",
    "    bias = weights_dict[str(prefix) + 'bias']\n",
    "    bias = bias.detach().cpu().numpy()\n",
    "    \n",
    "    # Calculate the kernel size and output channels from\n",
    "    # the loaded weights from above\n",
    "    kernel_size = weight[0][0].shape\n",
    "    output_channels = len(weight)\n",
    "    \n",
    "    # Calculations for the output H and W dimensions.\n",
    "    height_out = ((height + (2*padding) - (kernel_size[0] - 1) - 1) / stride) + 1\n",
    "    height_out = int(height_out)\n",
    "    width_out = ((width + (2*padding) - (kernel_size[1] - 1) - 1) / stride) + 1\n",
    "    width_out = int(width_out)\n",
    "    \n",
    "    \n",
    "    # ----Compute matrix of index i----\n",
    "\n",
    "    # Level 1 vector.\n",
    "    level1 = np.repeat(np.arange(kernel_size[0]), kernel_size[1])\n",
    "    # Duplicate for the other channels.\n",
    "    level1 = np.tile(level1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each level.\n",
    "    everyLevels = stride * np.repeat(np.arange(height_out), width_out)\n",
    "    # Create matrix of index i at every levels for each channel.\n",
    "    i = level1.reshape(-1, 1) + everyLevels.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index j----\n",
    "    \n",
    "    # Slide 1 vector.\n",
    "    slide1 = np.tile(np.arange(kernel_size[1]), kernel_size[0])\n",
    "    # Duplicate for the other channels.\n",
    "    slide1 = np.tile(slide1, input_channels)\n",
    "    # Create a vector with an increase by 1 at each slide.\n",
    "    everySlides = stride * np.tile(np.arange(width_out), height_out)\n",
    "    # Create matrix of index j at every slides for each channel.\n",
    "    j = slide1.reshape(-1, 1) + everySlides.reshape(1, -1)\n",
    "    \n",
    "    # ----Compute matrix of index d----\n",
    "\n",
    "    # This is to mark delimitation for each channel\n",
    "    # during multi-dimensional arrays indexing.\n",
    "    d = np.repeat(np.arange(input_channels), kernel_size[0] * kernel_size[1]).reshape(-1, 1)\n",
    "    \n",
    "    get_indices_end = time.perf_counter()\n",
    "    print('get_indices takes:', get_indices_end-get_indices_start, 'seconds')\n",
    "    \n",
    "    return i, j, d\n",
    "\n",
    "def im2col(input_data, weights_dict, prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        input_data = input_data.reshape((1, 1, 2020 , 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    elif len(input_data.shape) == 2:\n",
    "        input_data = input_data.reshape((1, 1, 2020, 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = get_indices(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    cols = input_padded[:, d, i, j]\n",
    "    cols = np.concatenate(cols, axis=-1)\n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols\n",
    "\n",
    "\n",
    "def np_Conv2d(input_data, weights_dict, prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2020 , 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "    \n",
    "    elif len(input_data.shape) == 2:\n",
    "        input_data = input_data.reshape((1, 1, 2020, 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    X_col = im2col(input_data=input_data, weights_dict=weights_dict, prefix=prefix)\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    \n",
    "    print('X_col.shape = ', X_col.shape)\n",
    "    print('w_col.shape = ', w_col.shape)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731f79d-3a7a-451f-851e-f97a70e32e57",
   "metadata": {},
   "source": [
    "Need to load `im2col` &` np_Conv2d`because we need to get the output of `np_Conv2d` for the first layer, intermediate layers, and last layer so that we have the correct shapes for the indices (via `get_indices` that will be used in `im2col` and thus `np_Conv2d`). The differences of `im2col2` and `np_conv2d2` are the versions of the functions that instead of creating the `i, j, d` index matrices it automatically loads them in thus saving ~4 seconds in the intermediate layers of the model that would call `get_indices` for every Conv layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c33e74-b418-4456-9b22-08e68e8cb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Replace the last part of the key that describes what layer it is\n",
    "# part of and replaces it with empty space\n",
    "layers_list = [x.replace('weight', '').replace('bias', '').replace('running_mean', '').replace('running_var', '').replace('num_batches_tracked', '') for x in weights.keys()]\n",
    "# Convert this list which has duplicated elements due to removing\n",
    "# identifying elements ie. for the first conv layer we had\n",
    "# layers.0.0.weight & layers.0.0.bias, but now after removing them we\n",
    "# have layers.0.0 & layers.0.0\n",
    "# The code below deletes the duplicated elements\n",
    "layers_list = list(OrderedDict.fromkeys(layers_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba931b-dd0a-42dd-a356-e461ed8fd6fd",
   "metadata": {},
   "source": [
    "We run the model through the baseline NumPy functions, so we get the correct shape of every layer. **BUT,** we only need the shape of the output from the first layer (1C -> 64C), an intermediate layer (64C->64C), and the last layer (64C->1C). We just need to instantiate the 1st, 2nd, and last layer without having to worry about the other layers of the model because those layers don't change the dimensionality of the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9ae781-f25f-4687-a6de-47766c3ef643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.09659373899921775 seconds\n",
      "Im2col takes: 0.2856571649899706 seconds\n",
      "X_col.shape =  (9, 4080400)\n",
      "w_col.shape =  (64, 9)\n",
      "Conv takes: 0.6021221099654213 seconds\n",
      "get_indices takes: 4.660267080063932 seconds\n",
      "Im2col takes: 16.41375806601718 seconds\n",
      "X_col.shape =  (576, 4080400)\n",
      "w_col.shape =  (64, 576)\n",
      "Conv takes: 18.258207763079554 seconds\n",
      "get_indices takes: 4.613854181021452 seconds\n",
      "Im2col takes: 16.43305515300017 seconds\n",
      "X_col.shape =  (576, 4080400)\n",
      "w_col.shape =  (1, 576)\n",
      "Conv takes: 16.80849543097429 seconds\n"
     ]
    }
   ],
   "source": [
    "# Creating the correct shapes/values of the intermediate arrays that are necessary\n",
    "# for creating the intermediate and final index matrices.\n",
    "#\n",
    "# These use the original functions that take a long time to process\n",
    "# (ie. the unoptimized versions)\n",
    "\n",
    "# First layer\n",
    "conv0 = np_Conv2d(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "# Second layer (ie. intermediate layer)\n",
    "conv1 = np_Conv2d(input_data=conv0, weights_dict=weights, prefix='layers.1.0.')\n",
    "# Last layer\n",
    "conv = np_Conv2d(input_data=conv1, weights_dict=weights, prefix='layers.19.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed227fa-d9a8-4873-91f4-2c43b2f23740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_indices takes: 0.10023234796244651 seconds\n",
      "get_indices takes: 4.670275000971742 seconds\n",
      "get_indices takes: 4.4229605389991775 seconds\n"
     ]
    }
   ],
   "source": [
    "# Creation of the first index matrix (1 C -> 64 C) and the intermediate\n",
    "# index matrix (64 C -> 64 C).\n",
    "#\n",
    "# For the intermediate index matrix we need the shape of the input data, but\n",
    "# because the first layer transforms the shape of the input data, we need \n",
    "# to run the first layer of the model to get the correct shape of the data\n",
    "# that will be used for creating the index matrix\n",
    "\n",
    "\n",
    "# First layer\n",
    "i_start, j_start, d_start = get_indices(input_data=samp, weights_dict=weights, prefix='layers.0.0.')\n",
    "index_mat_start = (i_start, j_start, d_start)\n",
    "\n",
    "# Second layer\n",
    "i_mid, j_mid, d_mid = get_indices(input_data=conv0, weights_dict=weights, prefix='layers.1.0.')\n",
    "index_mat_mid = (i_mid, j_mid, d_mid)\n",
    "\n",
    "# Last layer\n",
    "i_last, j_last, d_last = get_indices(input_data=conv1, weights_dict=weights, prefix='layers.19.')\n",
    "index_mat_last = (i_last, j_last, d_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9141828f-81fc-416f-87b9-dca5a511a0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not on NERSC?\n"
     ]
    }
   ],
   "source": [
    "index_matrices = {'start': index_mat_start, 'mid': index_mat_mid, 'last': index_mat_last}\n",
    "sl.NERSC_save(data=index_matrices, name='index_matrices_2k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38aab444-10e5-4811-9743-9cfa04e03fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col2_save(input_data, layer_matrices,  stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            Prefix to use to identify which multi-dimensional array indexing \n",
    "            array we're saving (ie. first, mid, last). Similar to the naming\n",
    "            convetion we have for the individual matrix indices from \n",
    "            get_indices\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2020 , 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(indput_data.shape) == 2:\n",
    "        input_data = input_data.reshape((1, 1, 2020, 2020))\n",
    "        batch_size, input_channels, height, width = input_data.shape\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    i, j, d = layer_matrices\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    idx = np.ravel_multi_index(([0], d, i, j), input_padded.shape)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77168cc3-1b25-41e7-8040-41c0f4a6c8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not on NERSC?\n"
     ]
    }
   ],
   "source": [
    "idx_start = im2col2_save(input_data=samp, layer_matrices=index_matrices['start'])\n",
    "idx_mid = im2col2_save(input_data=conv0, layer_matrices=index_matrices['mid'])\n",
    "idx_last = im2col2_save(input_data=conv1, layer_matrices=index_matrices['last'])\n",
    "\n",
    "im2col_layer_dict = {'start': idx_start, 'mid':idx_mid, 'last': idx_last}\n",
    "sl.NERSC_save(name='im2col_layer_dict_2k.pkl', data=im2col_layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495b0c43-cd5e-40fa-b909-01db864a5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col2(input_data, im2col_mat, col_prefix, stride=1, padding=1):\n",
    "    \"\"\"\n",
    "        Transforms our input image into a matrix.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data: nd.array\n",
    "            The input image(s)\n",
    "        weights_dict: OrderedDict\n",
    "            Dictionary containing the PyTorch trained weights for every \n",
    "            layer of the model\n",
    "        prefix: str\n",
    "            The prefix that picks out the specific layer's weights to be used\n",
    "            E.g. prefix='layers.0.0.' would be the first layers convolutional\n",
    "            weights and bias's\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cols: output matrix.\n",
    "    \"\"\"\n",
    "    im2col_start = time.perf_counter()\n",
    "\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "    # Padding\n",
    "    input_padded = np.pad(input_data, ((0,0), (0,0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    # Multi-dimensional arrays indexing.\n",
    "    idx = im2col_mat[str(col_prefix)]\n",
    "    cols2 = input_padded.reshape(-1)[idx]  \n",
    "    \n",
    "    im2col_end = time.perf_counter()\n",
    "    print('Im2col takes:', im2col_end-im2col_start, 'seconds')\n",
    "    \n",
    "    return cols2\n",
    "\n",
    "def np_Conv2d2(input_data, weights_dict, prefix, im2col_mat, col_prefix):\n",
    "    \"\"\"\n",
    "        Performs a forward convolution.\n",
    "\n",
    "        Parameters:\n",
    "        - X : Last conv layer of shape (m, n_C_prev, n_H_prev, n_W_prev).\n",
    "        Returns:\n",
    "        - out: previous layer convolved.\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_start = time.perf_counter()\n",
    "    if len(input_data.shape) == 4:\n",
    "    \n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "        \n",
    "    elif len(input_data.shape) == 3:\n",
    "        \n",
    "        input_data = input_data.reshape((1, 1, 2000 , 2000))\n",
    "        batch_size, input_channels, height, width = input_data.shape # (N, Cin, Hin, Win)\n",
    "\n",
    "\n",
    "    output_channels = len(weights_dict[str(prefix) + 'weight']) # num_of_filters\n",
    "    height_out = int((height + 2 * 1 - 3)/ 1) + 1\n",
    "    width_out = int((width + 2 * 1 - 3)/ 1) + 1\n",
    "\n",
    "    \n",
    "    X_col = im2col2(input_data=input_data, im2col_mat=im2col_mat, col_prefix=str(col_prefix))\n",
    "    w_col = weights_dict[str(prefix) + 'weight'].detach().cpu().numpy().reshape((output_channels, -1))\n",
    "    b_col = weights_dict[str(prefix) + 'bias'].detach().cpu().numpy().reshape(-1, 1)\n",
    "    # Perform matrix multiplication.\n",
    "    out = w_col @ X_col + b_col\n",
    "    # Reshape back matrix to image.\n",
    "    out = np.array(np.hsplit(out, batch_size)).reshape((batch_size, output_channels, height_out, width_out))\n",
    "    \n",
    "    conv_end = time.perf_counter()\n",
    "    print('Conv takes:', conv_end-conv_start, 'seconds')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e838578-55c8-4d7e-b7b3-85199d35678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im2col takes: 0.0429197900230065 seconds\n",
      "Conv takes: 0.38779085397254676 seconds\n"
     ]
    }
   ],
   "source": [
    "conv2 = np_Conv2d2(input_data=samp,\n",
    "                   weights_dict=weights,\n",
    "                   prefix='layers.0.0.',\n",
    "                   im2col_mat=im2col_layer_dict,\n",
    "                   col_prefix='start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0296874-0743-47e5-b56a-bf5d3435fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im2col takes: 0.04880527697969228 seconds\n",
      "Conv takes: 0.42318778403569013 seconds\n",
      "Im2col takes: 2.645732757053338 seconds\n",
      "Conv takes: 5.040720434044488 seconds\n",
      "Batch takes 0.5323864190140739 seconds\n",
      "Im2col takes: 2.6158414180390537 seconds\n",
      "Conv takes: 5.025758278905414 seconds\n",
      "Batch takes 0.5327074381057173 seconds\n",
      "Im2col takes: 2.6307908199960366 seconds\n",
      "Conv takes: 5.069815273978747 seconds\n",
      "Batch takes 0.5286191729828715 seconds\n",
      "Im2col takes: 2.722166082006879 seconds\n",
      "Conv takes: 5.145924172014929 seconds\n",
      "Batch takes 0.5325645220000297 seconds\n",
      "Im2col takes: 2.6249124839669093 seconds\n",
      "Conv takes: 4.995972759905271 seconds\n",
      "Batch takes 0.5311846339609474 seconds\n",
      "Im2col takes: 2.6260801900643855 seconds\n",
      "Conv takes: 4.9808753239922225 seconds\n",
      "Batch takes 0.5295711780199781 seconds\n",
      "Im2col takes: 2.6232870860258117 seconds\n",
      "Conv takes: 5.086467436980456 seconds\n",
      "Batch takes 0.5281398349907249 seconds\n",
      "Im2col takes: 2.630186290014535 seconds\n",
      "Conv takes: 5.089139567920938 seconds\n",
      "Batch takes 0.5275058910483494 seconds\n",
      "Im2col takes: 2.6317049630451947 seconds\n",
      "Conv takes: 5.148452855995856 seconds\n",
      "Batch takes 0.5313246350269765 seconds\n",
      "Im2col takes: 2.6247653600294143 seconds\n",
      "Conv takes: 5.125845485017635 seconds\n",
      "Batch takes 0.5328614129684865 seconds\n",
      "Im2col takes: 2.6281853950349614 seconds\n",
      "Conv takes: 5.114960013073869 seconds\n",
      "Batch takes 0.5255025209626183 seconds\n",
      "Im2col takes: 2.62333747302182 seconds\n",
      "Conv takes: 5.101103191962466 seconds\n",
      "Batch takes 0.556193022057414 seconds\n",
      "Im2col takes: 2.691899773082696 seconds\n",
      "Conv takes: 5.2131535180378705 seconds\n",
      "Batch takes 0.5427391590783373 seconds\n",
      "Im2col takes: 2.7043707870179787 seconds\n",
      "Conv takes: 5.3054967349162325 seconds\n",
      "Batch takes 0.5408238300587982 seconds\n",
      "Im2col takes: 2.7191105040255934 seconds\n",
      "Conv takes: 5.178385301027447 seconds\n",
      "Batch takes 0.5466781909344718 seconds\n",
      "Im2col takes: 2.68384240497835 seconds\n",
      "Conv takes: 5.122269583051093 seconds\n",
      "Batch takes 0.5455046539427713 seconds\n",
      "Im2col takes: 2.6845121800433844 seconds\n",
      "Conv takes: 5.209396910038777 seconds\n",
      "Batch takes 0.5455189819913357 seconds\n",
      "Im2col takes: 2.68474110099487 seconds\n",
      "Conv takes: 5.2032695669913664 seconds\n",
      "Batch takes 0.5451985829276964 seconds\n",
      "Im2col takes: 2.6733479290269315 seconds\n",
      "Conv takes: 3.0193553890567273 seconds\n"
     ]
    }
   ],
   "source": [
    "output = np_Conv2d2(input_data=samp,\n",
    "                   weights_dict=weights,\n",
    "                   prefix=layers_list[0],\n",
    "                   im2col_mat=im2col_layer_dict,\n",
    "                   col_prefix='start')\n",
    "output = relu(output)\n",
    "\n",
    "# Layer 2 - Layer 19\n",
    "for i in range(len(layers_list)-2):\n",
    "\n",
    "    if layers_list[i+1].endswith('0.'):\n",
    "        output = np_Conv2d2(input_data=output,\n",
    "                           weights_dict=weights,\n",
    "                           prefix=layers_list[i+1],\n",
    "                           im2col_mat=im2col_layer_dict,\n",
    "                           col_prefix='mid')\n",
    "\n",
    "    elif layers_list[i+1].endswith('1.'):\n",
    "\n",
    "        output = np_BatchNorm2d(x=output, \n",
    "                                weights_dict=weights,\n",
    "                                prefix=layers_list[i+1])\n",
    "        output = relu(output)\n",
    "\n",
    "# Layer 20 (last layer)\n",
    "output1 = np_Conv2d2(input_data=output,\n",
    "                   weights_dict=weights,\n",
    "                   prefix=layers_list[-1],\n",
    "                   im2col_mat=im2col_layer_dict,\n",
    "                   col_prefix='last')\n",
    "\n",
    "resid_img = samp - output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84189bb2-fd11-4d18-bd47-277c0664e6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
